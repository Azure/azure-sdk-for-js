/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { BaseResource, CloudError, AzureServiceClientOptions } from "@azure/ms-rest-azure-js";
import * as msRest from "@azure/ms-rest-js";

export { BaseResource, CloudError };

/**
 * The Usage Names.
 */
export interface UsageName {
  /**
   * The name of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly value?: string;
  /**
   * The localized name of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly localizedValue?: string;
}

/**
 * Describes Batch AI Resource Usage.
 */
export interface Usage {
  /**
   * An enum describing the unit of usage measurement. Possible values include: 'Count'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly unit?: UsageUnit;
  /**
   * The current usage of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly currentValue?: number;
  /**
   * The maximum permitted usage of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly limit?: number;
  /**
   * The name of the type of usage.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: UsageName;
}

/**
 * Settings for user account that gets created on each on the nodes of a cluster.
 */
export interface UserAccountSettings {
  /**
   * User name. Name of the administrator user account which can be used to SSH to nodes.
   */
  adminUserName: string;
  /**
   * SSH public key. SSH public key of the administrator user account.
   */
  adminUserSshPublicKey?: string;
  /**
   * Password. Password of the administrator user account.
   */
  adminUserPassword?: string;
}

/**
 * SSH configuration.
 */
export interface SshConfiguration {
  /**
   * Allowed public IPs. List of source IP ranges to allow SSH connection from. The default value
   * is '*' (all source IPs are allowed). Maximum number of IP ranges that can be specified is 400.
   */
  publicIPsToAllow?: string[];
  /**
   * User account settings. Settings for administrator user account to be created on a node. The
   * account can be used to establish SSH connection to the node.
   */
  userAccountSettings: UserAccountSettings;
}

/**
 * Data disks settings.
 */
export interface DataDisks {
  /**
   * Disk size in GB. Disk size in GB for the blank data disks.
   */
  diskSizeInGB: number;
  /**
   * Caching type. Caching type for the disks. Available values are none (default), readonly,
   * readwrite. Caching type can be set only for VM sizes supporting premium storage. Possible
   * values include: 'none', 'readonly', 'readwrite'. Default value: 'none'.
   */
  cachingType?: CachingType;
  /**
   * Number of data disks. Number of data disks attached to the File Server. If multiple disks
   * attached, they will be configured in RAID level 0.
   */
  diskCount: number;
  /**
   * Storage account type. Type of storage account to be used on the disk. Possible values are:
   * Standard_LRS or Premium_LRS. Premium storage account type can only be used with VM sizes
   * supporting premium storage. Possible values include: 'Standard_LRS', 'Premium_LRS'
   */
  storageAccountType: StorageAccountType;
}

/**
 * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
 */
export interface ResourceId extends BaseResource {
  /**
   * The ID of the resource
   */
  id: string;
}

/**
 * File Server mount Information.
 */
export interface MountSettings {
  /**
   * Mount Point. Path where the data disks are mounted on the File Server.
   */
  mountPoint?: string;
  /**
   * Public IP. Public IP address of the File Server which can be used to SSH to the node from
   * outside of the subnet.
   */
  fileServerPublicIP?: string;
  /**
   * Internal IP. Internal IP address of the File Server which can be used to access the File
   * Server from within the subnet.
   */
  fileServerInternalIP?: string;
}

/**
 * A definition of an Azure proxy resource.
 */
export interface ProxyResource extends BaseResource {
  /**
   * The ID of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly id?: string;
  /**
   * The name of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: string;
  /**
   * The type of the resource.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly type?: string;
}

/**
 * File Server information.
 */
export interface FileServer extends ProxyResource {
  /**
   * VM size. VM size of the File Server.
   */
  vmSize?: string;
  /**
   * SSH configuration. SSH configuration for accessing the File Server node.
   */
  sshConfiguration?: SshConfiguration;
  /**
   * Data disks configuration. Information about disks attached to File Server VM.
   */
  dataDisks?: DataDisks;
  /**
   * Subnet. File Server virtual network subnet resource ID.
   */
  subnet?: ResourceId;
  /**
   * Mount settings. File Server mount settings.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly mountSettings?: MountSettings;
  /**
   * Provisioning State Transition time. Time when the provisioning state was changed.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningStateTransitionTime?: Date;
  /**
   * Creation time. Time when the FileServer was created.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly creationTime?: Date;
  /**
   * Provisioning state. Provisioning state of the File Server. Possible values: creating - The
   * File Server is getting created; updating - The File Server creation has been accepted and it
   * is getting updated; deleting - The user has requested that the File Server be deleted, and it
   * is in the process of being deleted; failed - The File Server creation has failed with the
   * specified error code. Details about the error code are specified in the message field;
   * succeeded - The File Server creation has succeeded. Possible values include: 'creating',
   * 'updating', 'deleting', 'succeeded', 'failed'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningState?: FileServerProvisioningState;
}

/**
 * Key Vault Secret reference.
 */
export interface KeyVaultSecretReference {
  /**
   * Key Vault resource identifier. Fully qualified resource identifier of the Key Vault.
   */
  sourceVault: ResourceId;
  /**
   * Secret URL. The URL referencing a secret in the Key Vault.
   */
  secretUrl: string;
}

/**
 * File Server creation parameters.
 */
export interface FileServerCreateParameters {
  /**
   * VM size. The size of the virtual machine for the File Server. For information about available
   * VM sizes from the Virtual Machines Marketplace, see Sizes for Virtual Machines (Linux).
   */
  vmSize: string;
  /**
   * SSH configuration. SSH configuration for the File Server node.
   */
  sshConfiguration: SshConfiguration;
  /**
   * Data disks. Settings for the data disks which will be created for the File Server.
   */
  dataDisks: DataDisks;
  /**
   * Subnet identifier. Identifier of an existing virtual network subnet to put the File Server in.
   * If not provided, a new virtual network and subnet will be created.
   */
  subnet?: ResourceId;
}

/**
 * Manual scale settings for the cluster.
 */
export interface ManualScaleSettings {
  /**
   * Target node count. The desired number of compute nodes in the Cluster. Default is 0. Default
   * value: 0.
   */
  targetNodeCount: number;
  /**
   * Node deallocation options. An action to be performed when the cluster size is decreasing. The
   * default value is requeue. Possible values include: 'requeue', 'terminate',
   * 'waitforjobcompletion'. Default value: 'requeue'.
   */
  nodeDeallocationOption?: DeallocationOption;
}

/**
 * Auto-scale settings for the cluster. The system automatically scales the cluster up and down
 * (within minimumNodeCount and maximumNodeCount) based on the number of queued and running jobs
 * assigned to the cluster.
 */
export interface AutoScaleSettings {
  /**
   * Minimum node count. The minimum number of compute nodes the Batch AI service will try to
   * allocate for the cluster. Note, the actual number of nodes can be less than the specified
   * value if the subscription has not enough quota to fulfill the request.
   */
  minimumNodeCount: number;
  /**
   * Maximum node count. The maximum number of compute nodes the cluster can have.
   */
  maximumNodeCount: number;
  /**
   * Initial node count. The number of compute nodes to allocate on cluster creation. Note that
   * this value is used only during cluster creation. Default: 0. Default value: 0.
   */
  initialNodeCount?: number;
}

/**
 * At least one of manual or autoScale settings must be specified. Only one of manual or autoScale
 * settings can be specified. If autoScale settings are specified, the system automatically scales
 * the cluster up and down (within the supplied limits) based on the pending jobs on the cluster.
 */
export interface ScaleSettings {
  /**
   * Manual scale settings. Manual scale settings for the cluster.
   */
  manual?: ManualScaleSettings;
  /**
   * Auto-scale settings. Auto-scale settings for the cluster.
   */
  autoScale?: AutoScaleSettings;
}

/**
 * The OS image reference.
 */
export interface ImageReference {
  /**
   * Publisher. Publisher of the image.
   */
  publisher: string;
  /**
   * Offer. Offer of the image.
   */
  offer: string;
  /**
   * SKU. SKU of the image.
   */
  sku: string;
  /**
   * Version. Version of the image.
   */
  version?: string;
  /**
   * Custom VM image resource ID. The ARM resource identifier of the virtual machine image for the
   * compute nodes. This is of the form
   * /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Compute/images/{imageName}.
   * The virtual machine image must be in the same region and subscription as the cluster. For
   * information about the firewall settings for the Batch node agent to communicate with the Batch
   * service see
   * https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
   * Note, you need to provide publisher, offer and sku of the base OS image of which the custom
   * image has been derived from.
   */
  virtualMachineImageId?: string;
}

/**
 * VM configuration.
 */
export interface VirtualMachineConfiguration {
  /**
   * Image reference. OS image reference for cluster nodes.
   */
  imageReference?: ImageReference;
}

/**
 * An environment variable definition.
 */
export interface EnvironmentVariable {
  /**
   * Name. The name of the environment variable.
   */
  name: string;
  /**
   * Value. The value of the environment variable.
   */
  value: string;
}

/**
 * An environment variable with secret value definition.
 */
export interface EnvironmentVariableWithSecretValue {
  /**
   * Name. The name of the environment variable to store the secret value.
   */
  name: string;
  /**
   * Value. The value of the environment variable. This value will never be reported back by Batch
   * AI.
   */
  value?: string;
  /**
   * KeyVault secret reference. KeyVault store and secret which contains the value for the
   * environment variable. One of value or valueSecretReference must be provided.
   */
  valueSecretReference?: KeyVaultSecretReference;
}

/**
 * Specifies a setup task which can be used to customize the compute nodes of the cluster.
 */
export interface SetupTask {
  /**
   * Command line. The command line to be executed on each cluster's node after it being allocated
   * or rebooted. The command is executed in a bash subshell as a root.
   */
  commandLine: string;
  /**
   * Environment variables. A collection of user defined environment variables to be set for setup
   * task.
   */
  environmentVariables?: EnvironmentVariable[];
  /**
   * Secrets. A collection of user defined environment variables with secret values to be set for
   * the setup task. Server will never report values of these variables back.
   */
  secrets?: EnvironmentVariableWithSecretValue[];
  /**
   * Output path prefix. The prefix of a path where the Batch AI service will upload the stdout,
   * stderr and execution log of the setup task.
   */
  stdOutErrPathPrefix: string;
  /**
   * Output path suffix. A path segment appended by Batch AI to stdOutErrPathPrefix to form a path
   * where stdout, stderr and execution log of the setup task will be uploaded. Batch AI creates
   * the setup task output directories under an unique path to avoid conflicts between different
   * clusters. The full path can be obtained by concatenation of stdOutErrPathPrefix and
   * stdOutErrPathSuffix.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly stdOutErrPathSuffix?: string;
}

/**
 * Azure storage account credentials.
 */
export interface AzureStorageCredentialsInfo {
  /**
   * Account key. Storage account key. One of accountKey or accountKeySecretReference must be
   * specified.
   */
  accountKey?: string;
  /**
   * Account key secret reference. Information about KeyVault secret storing the storage account
   * key. One of accountKey or accountKeySecretReference must be specified.
   */
  accountKeySecretReference?: KeyVaultSecretReference;
}

/**
 * Azure File Share mounting configuration.
 */
export interface AzureFileShareReference {
  /**
   * Account name. Name of the Azure storage account.
   */
  accountName: string;
  /**
   * Azure File URL. URL to access the Azure File.
   */
  azureFileUrl: string;
  /**
   * Credentials. Information about the Azure storage credentials.
   */
  credentials: AzureStorageCredentialsInfo;
  /**
   * Relative mount path. The relative path on the compute node where the Azure File share will be
   * mounted. Note that all cluster level file shares will be mounted under $AZ_BATCHAI_MOUNT_ROOT
   * location and all job level file shares will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   */
  relativeMountPath: string;
  /**
   * File mode. File mode for files on the mounted file share. Default value: 0777. Default value:
   * '0777'.
   */
  fileMode?: string;
  /**
   * Directory mode. File mode for directories on the mounted file share. Default value: 0777.
   * Default value: '0777'.
   */
  directoryMode?: string;
}

/**
 * Azure Blob Storage Container mounting configuration.
 */
export interface AzureBlobFileSystemReference {
  /**
   * Account name. Name of the Azure storage account.
   */
  accountName: string;
  /**
   * Container name. Name of the Azure Blob Storage container to mount on the cluster.
   */
  containerName: string;
  /**
   * Credentials. Information about the Azure storage credentials.
   */
  credentials: AzureStorageCredentialsInfo;
  /**
   * Relative mount path. The relative path on the compute node where the Azure File container will
   * be mounted. Note that all cluster level containers will be mounted under
   * $AZ_BATCHAI_MOUNT_ROOT location and all job level containers will be mounted under
   * $AZ_BATCHAI_JOB_MOUNT_ROOT.
   */
  relativeMountPath: string;
  /**
   * Mount options. Mount options for mounting blobfuse file system.
   */
  mountOptions?: string;
}

/**
 * File Server mounting configuration.
 */
export interface FileServerReference {
  /**
   * File server. Resource ID of the existing File Server to be mounted.
   */
  fileServer: ResourceId;
  /**
   * Source directory. File Server directory that needs to be mounted. If this property is not
   * specified, the entire File Server will be mounted.
   */
  sourceDirectory?: string;
  /**
   * Relative mount path. The relative path on the compute node where the File Server will be
   * mounted. Note that all cluster level file servers will be mounted under $AZ_BATCHAI_MOUNT_ROOT
   * location and all job level file servers will be mounted under $AZ_BATCHAI_JOB_MOUNT_ROOT.
   */
  relativeMountPath: string;
  /**
   * Mount options. Mount options to be passed to mount command.
   */
  mountOptions?: string;
}

/**
 * Unmanaged file system mounting configuration.
 */
export interface UnmanagedFileSystemReference {
  /**
   * Mount command. Mount command line. Note, Batch AI will append mount path to the command on its
   * own.
   */
  mountCommand: string;
  /**
   * Relative mount path. The relative path on the compute node where the unmanaged file system
   * will be mounted. Note that all cluster level unmanaged file systems will be mounted under
   * $AZ_BATCHAI_MOUNT_ROOT location and all job level unmanaged file systems will be mounted under
   * $AZ_BATCHAI_JOB_MOUNT_ROOT.
   */
  relativeMountPath: string;
}

/**
 * Details of volumes to mount on the cluster.
 */
export interface MountVolumes {
  /**
   * Azure File Shares. A collection of Azure File Shares that are to be mounted to the cluster
   * nodes.
   */
  azureFileShares?: AzureFileShareReference[];
  /**
   * Azure Blob file systems. A collection of Azure Blob Containers that are to be mounted to the
   * cluster nodes.
   */
  azureBlobFileSystems?: AzureBlobFileSystemReference[];
  /**
   * File Servers. A collection of Batch AI File Servers that are to be mounted to the cluster
   * nodes.
   */
  fileServers?: FileServerReference[];
  /**
   * Unmanaged file systems. A collection of unmanaged file systems that are to be mounted to the
   * cluster nodes.
   */
  unmanagedFileSystems?: UnmanagedFileSystemReference[];
}

/**
 * Azure Application Insights information for performance counters reporting.
 */
export interface AppInsightsReference {
  /**
   * Component ID. Azure Application Insights component resource ID.
   */
  component: ResourceId;
  /**
   * Instrumentation Key. Value of the Azure Application Insights instrumentation key.
   */
  instrumentationKey?: string;
  /**
   * Instrumentation key KeyVault Secret reference. KeyVault Store and Secret which contains Azure
   * Application Insights instrumentation key. One of instrumentationKey or
   * instrumentationKeySecretReference must be specified.
   */
  instrumentationKeySecretReference?: KeyVaultSecretReference;
}

/**
 * Performance counters reporting settings.
 */
export interface PerformanceCountersSettings {
  /**
   * Azure Application Insights reference. Azure Application Insights information for performance
   * counters reporting. If provided, Batch AI will upload node performance counters to the
   * corresponding Azure Application Insights account.
   */
  appInsightsReference: AppInsightsReference;
}

/**
 * Node setup settings.
 */
export interface NodeSetup {
  /**
   * Setup task. Setup task to run on cluster nodes when nodes got created or rebooted. The setup
   * task code needs to be idempotent. Generally the setup task is used to download static data
   * that is required for all jobs that run on the cluster VMs and/or to download/install software.
   */
  setupTask?: SetupTask;
  /**
   * Mount volumes. Mount volumes to be available to setup task and all jobs executing on the
   * cluster. The volumes will be mounted at location specified by $AZ_BATCHAI_MOUNT_ROOT
   * environment variable.
   */
  mountVolumes?: MountVolumes;
  /**
   * Performance counters settings. Settings for performance counters collecting and uploading.
   */
  performanceCountersSettings?: PerformanceCountersSettings;
}

/**
 * Counts of various compute node states on the cluster.
 */
export interface NodeStateCounts {
  /**
   * Idle node count. Number of compute nodes in idle state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly idleNodeCount?: number;
  /**
   * Running node count. Number of compute nodes which are running jobs.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly runningNodeCount?: number;
  /**
   * Preparing node count. Number of compute nodes which are being prepared.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly preparingNodeCount?: number;
  /**
   * Unusable node count. Number of compute nodes which are in unusable state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly unusableNodeCount?: number;
  /**
   * Leaving node count. Number of compute nodes which are leaving the cluster.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly leavingNodeCount?: number;
}

/**
 * Cluster creation operation.
 */
export interface ClusterCreateParameters {
  /**
   * VM size. The size of the virtual machines in the cluster. All nodes in a cluster have the same
   * VM size. For information about available VM sizes for clusters using images from the Virtual
   * Machines Marketplace see Sizes for Virtual Machines (Linux). Batch AI service supports all
   * Azure VM sizes except STANDARD_A0 and those with premium storage (STANDARD_GS, STANDARD_DS,
   * and STANDARD_DSV2 series).
   */
  vmSize: string;
  /**
   * VM priority. VM priority. Allowed values are: dedicated (default) and lowpriority. Possible
   * values include: 'dedicated', 'lowpriority'. Default value: 'dedicated'.
   */
  vmPriority?: VmPriority;
  /**
   * Scale settings. Scale settings for the cluster. Batch AI service supports manual and auto
   * scale clusters.
   */
  scaleSettings?: ScaleSettings;
  /**
   * VM configuration. OS image configuration for cluster nodes. All nodes in a cluster have the
   * same OS image.
   */
  virtualMachineConfiguration?: VirtualMachineConfiguration;
  /**
   * Node setup. Setup to be performed on each compute node in the cluster.
   */
  nodeSetup?: NodeSetup;
  /**
   * User account settings. Settings for an administrator user account that will be created on each
   * compute node in the cluster.
   */
  userAccountSettings: UserAccountSettings;
  /**
   * Subnet. Existing virtual network subnet to put the cluster nodes in. Note, if a File Server
   * mount configured in node setup, the File Server's subnet will be used automatically.
   */
  subnet?: ResourceId;
}

/**
 * Cluster update parameters.
 */
export interface ClusterUpdateParameters {
  /**
   * Scale settings. Desired scale settings for the cluster. Batch AI service supports manual and
   * auto scale clusters.
   */
  scaleSettings?: ScaleSettings;
}

/**
 * Name-value pair.
 */
export interface NameValuePair {
  /**
   * Name. The name in the name-value pair.
   */
  name?: string;
  /**
   * Value. The value in the name-value pair.
   */
  value?: string;
}

/**
 * An error response from the Batch AI service.
 */
export interface BatchAIError {
  /**
   * An identifier of the error. Codes are invariant and are intended to be consumed
   * programmatically.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly code?: string;
  /**
   * A message describing the error, intended to be suitable for display in a user interface.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly message?: string;
  /**
   * A list of additional details about the error.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly details?: NameValuePair[];
}

/**
 * Information about a Cluster.
 */
export interface Cluster extends ProxyResource {
  /**
   * VM size. The size of the virtual machines in the cluster. All nodes in a cluster have the same
   * VM size.
   */
  vmSize?: string;
  /**
   * VM priority. VM priority of cluster nodes. Possible values include: 'dedicated',
   * 'lowpriority'. Default value: 'dedicated'.
   */
  vmPriority?: VmPriority;
  /**
   * Scale settings. Scale settings of the cluster.
   */
  scaleSettings?: ScaleSettings;
  /**
   * VM configuration. Virtual machine configuration (OS image) of the compute nodes. All nodes in
   * a cluster have the same OS image configuration.
   */
  virtualMachineConfiguration?: VirtualMachineConfiguration;
  /**
   * Node setup. Setup (mount file systems, performance counters settings and custom setup task) to
   * be performed on each compute node in the cluster.
   */
  nodeSetup?: NodeSetup;
  /**
   * User account settings. Administrator user account settings which can be used to SSH to compute
   * nodes.
   */
  userAccountSettings?: UserAccountSettings;
  /**
   * Subnet. Virtual network subnet resource ID the cluster nodes belong to.
   */
  subnet?: ResourceId;
  /**
   * Creation time. The time when the cluster was created.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly creationTime?: Date;
  /**
   * Provisioning state. Provisioning state of the cluster. Possible value are: creating -
   * Specifies that the cluster is being created. succeeded - Specifies that the cluster has been
   * created successfully. failed - Specifies that the cluster creation has failed. deleting -
   * Specifies that the cluster is being deleted. Possible values include: 'creating', 'succeeded',
   * 'failed', 'deleting'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningState?: ProvisioningState;
  /**
   * Provisioning State Transition time. Time when the provisioning state was changed.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningStateTransitionTime?: Date;
  /**
   * Allocation state. Allocation state of the cluster. Possible values are: steady - Indicates
   * that the cluster is not resizing. There are no changes to the number of compute nodes in the
   * cluster in progress. A cluster enters this state when it is created and when no operations are
   * being performed on the cluster to change the number of compute nodes. resizing - Indicates
   * that the cluster is resizing; that is, compute nodes are being added to or removed from the
   * cluster. Possible values include: 'steady', 'resizing'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly allocationState?: AllocationState;
  /**
   * Allocation state transition time. The time at which the cluster entered its current allocation
   * state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly allocationStateTransitionTime?: Date;
  /**
   * Errors. Collection of errors encountered by various compute nodes during node setup.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly errors?: BatchAIError[];
  /**
   * Current node count. The number of compute nodes currently assigned to the cluster.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly currentNodeCount?: number;
  /**
   * Node state counts. Counts of various node states on the cluster.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nodeStateCounts?: NodeStateCounts;
}

/**
 * Credentials to access a container image in a private repository.
 */
export interface PrivateRegistryCredentials {
  /**
   * User name. User name to login to the repository.
   */
  username: string;
  /**
   * Password. User password to login to the docker repository. One of password or
   * passwordSecretReference must be specified.
   */
  password?: string;
  /**
   * Password secret reference. KeyVault Secret storing the password. Users can store their secrets
   * in Azure KeyVault and pass it to the Batch AI service to integrate with KeyVault. One of
   * password or passwordSecretReference must be specified.
   */
  passwordSecretReference?: KeyVaultSecretReference;
}

/**
 * Information about docker image for the job.
 */
export interface ImageSourceRegistry {
  /**
   * Server URL. URL for image repository.
   */
  serverUrl?: string;
  /**
   * Image. The name of the image in the image repository.
   */
  image: string;
  /**
   * Credentials. Credentials to access the private docker repository.
   */
  credentials?: PrivateRegistryCredentials;
}

/**
 * Docker container settings.
 */
export interface ContainerSettings {
  /**
   * Image source registry. Information about docker image and docker registry to download the
   * container from.
   */
  imageSourceRegistry: ImageSourceRegistry;
  /**
   * /dev/shm size. Size of /dev/shm. Please refer to docker documentation for supported argument
   * formats.
   */
  shmSize?: string;
}

/**
 * CNTK (aka Microsoft Cognitive Toolkit) job settings.
 */
export interface CNTKsettings {
  /**
   * Language type. The language to use for launching CNTK (aka Microsoft Cognitive Toolkit) job.
   * Valid values are 'BrainScript' or 'Python'.
   */
  languageType?: string;
  /**
   * Config file path. Specifies the path of the BrainScript config file. This property can be
   * specified only if the languageType is 'BrainScript'.
   */
  configFilePath?: string;
  /**
   * Python script file path. Python script to execute. This property can be specified only if the
   * languageType is 'Python'.
   */
  pythonScriptFilePath?: string;
  /**
   * Python interpreter path. The path to the Python interpreter. This property can be specified
   * only if the languageType is 'Python'.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the python script or
   * cntk executable.
   */
  commandLineArgs?: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
}

/**
 * pyTorch job settings.
 */
export interface PyTorchSettings {
  /**
   * Python script file path. The python script to execute.
   */
  pythonScriptFilePath: string;
  /**
   * Python interpreter path. The path to the Python interpreter.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the python script.
   */
  commandLineArgs?: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
  /**
   * Communication backend. Type of the communication backend for distributed jobs. Valid values
   * are 'TCP', 'Gloo' or 'MPI'. Not required for non-distributed jobs.
   */
  communicationBackend?: string;
}

/**
 * TensorFlow job settings.
 */
export interface TensorFlowSettings {
  /**
   * Python script file path. The python script to execute.
   */
  pythonScriptFilePath: string;
  /**
   * Python interpreter path. The path to the Python interpreter.
   */
  pythonInterpreterPath?: string;
  /**
   * Master command line arguments. Command line arguments that need to be passed to the python
   * script for the master task.
   */
  masterCommandLineArgs?: string;
  /**
   * Worker command line arguments. Command line arguments that need to be passed to the python
   * script for the worker task. Optional for single process jobs.
   */
  workerCommandLineArgs?: string;
  /**
   * Parameter server command line arguments. Command line arguments that need to be passed to the
   * python script for the parameter server. Optional for single process jobs.
   */
  parameterServerCommandLineArgs?: string;
  /**
   * Worker count. The number of worker tasks. If specified, the value must be less than or equal
   * to (nodeCount * numberOfGPUs per VM). If not specified, the default value is equal to
   * nodeCount. This property can be specified only for distributed TensorFlow training.
   */
  workerCount?: number;
  /**
   * Parameter server count. The number of parameter server tasks. If specified, the value must be
   * less than or equal to nodeCount. If not specified, the default value is equal to 1 for
   * distributed TensorFlow training. This property can be specified only for distributed
   * TensorFlow training.
   */
  parameterServerCount?: number;
}

/**
 * Caffe job settings.
 */
export interface CaffeSettings {
  /**
   * Config file path. Path of the config file for the job. This property cannot be specified if
   * pythonScriptFilePath is specified.
   */
  configFilePath?: string;
  /**
   * Python script file path. Python script to execute. This property cannot be specified if
   * configFilePath is specified.
   */
  pythonScriptFilePath?: string;
  /**
   * Python interpreter path. The path to the Python interpreter. The property can be specified
   * only if the pythonScriptFilePath is specified.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the Caffe job.
   */
  commandLineArgs?: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
}

/**
 * Caffe2 job settings.
 */
export interface Caffe2Settings {
  /**
   * Python script file path. The python script to execute.
   */
  pythonScriptFilePath: string;
  /**
   * Python interpreter path. The path to the Python interpreter.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the python script.
   */
  commandLineArgs?: string;
}

/**
 * Chainer job settings.
 */
export interface ChainerSettings {
  /**
   * Python script file path. The python script to execute.
   */
  pythonScriptFilePath: string;
  /**
   * Python interpreter path. The path to the Python interpreter.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the python script.
   */
  commandLineArgs?: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
}

/**
 * Custom tool kit job settings.
 */
export interface CustomToolkitSettings {
  /**
   * Command line. The command line to execute on the master node.
   */
  commandLine?: string;
}

/**
 * Custom MPI job settings.
 */
export interface CustomMpiSettings {
  /**
   * Command line. The command line to be executed by mpi runtime on each compute node.
   */
  commandLine: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
}

/**
 * Specifies the settings for Horovod job.
 */
export interface HorovodSettings {
  /**
   * Python script file path. The python script to execute.
   */
  pythonScriptFilePath: string;
  /**
   * Python interpreter path. The path to the Python interpreter.
   */
  pythonInterpreterPath?: string;
  /**
   * Command line arguments. Command line arguments that need to be passed to the python script.
   */
  commandLineArgs?: string;
  /**
   * Process count. Number of processes to launch for the job execution. The default value for this
   * property is equal to nodeCount property
   */
  processCount?: number;
}

/**
 * Job preparation settings.
 */
export interface JobPreparation {
  /**
   * Command line. The command line to execute. If containerSettings is specified on the job, this
   * commandLine will be executed in the same container as job. Otherwise it will be executed on
   * the node.
   */
  commandLine: string;
}

/**
 * Input directory for the job.
 */
export interface InputDirectory {
  /**
   * ID. The ID for the input directory. The job can use AZ_BATCHAI_INPUT_<id> environment variable
   * to find the directory path, where <id> is the value of id attribute.
   */
  id: string;
  /**
   * Path. The path to the input directory.
   */
  path: string;
}

/**
 * Output directory for the job.
 */
export interface OutputDirectory {
  /**
   * ID. The ID of the output directory. The job can use AZ_BATCHAI_OUTPUT_<id> environment
   * variable to find the directory path, where <id> is the value of id attribute.
   */
  id: string;
  /**
   * Path prefix. The prefix path where the output directory will be created. Note, this is an
   * absolute path to prefix. E.g. $AZ_BATCHAI_MOUNT_ROOT/MyNFS/MyLogs. The full path to the output
   * directory by combining pathPrefix, jobOutputDirectoryPathSegment (reported by get job) and
   * pathSuffix.
   */
  pathPrefix: string;
  /**
   * Path suffix. The suffix path where the output directory will be created. E.g. models. You can
   * find the full path to the output directory by combining pathPrefix,
   * jobOutputDirectoryPathSegment (reported by get job) and pathSuffix.
   */
  pathSuffix?: string;
}

/**
 * Constraints associated with the Job.
 */
export interface JobBasePropertiesConstraints {
  /**
   * Max wall clock time. Max time the job can run. Default value: 1 week. Default value:
   * '7.00:00:00'.
   */
  maxWallClockTime?: string;
}

/**
 * Job creation parameters.
 */
export interface JobCreateParameters {
  /**
   * Scheduling priority. Scheduling priority associated with the job. Possible values: low,
   * normal, high. Possible values include: 'low', 'normal', 'high'. Default value: 'normal'.
   */
  schedulingPriority?: JobPriority;
  /**
   * Cluster. Resource ID of the cluster on which this job will run.
   */
  cluster: ResourceId;
  /**
   * Mount volumes. Information on mount volumes to be used by the job. These volumes will be
   * mounted before the job execution and will be unmounted after the job completion. The volumes
   * will be mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
   */
  mountVolumes?: MountVolumes;
  /**
   * Node count. Number of compute nodes to run the job on. The job will be gang scheduled on that
   * many compute nodes.
   */
  nodeCount: number;
  /**
   * Container settings. Docker container settings for the job. If not provided, the job will run
   * directly on the node.
   */
  containerSettings?: ContainerSettings;
  /**
   * CNTK settings. Settings for CNTK (aka Microsoft Cognitive Toolkit) job.
   */
  cntkSettings?: CNTKsettings;
  /**
   * pyTorch settings. Settings for pyTorch job.
   */
  pyTorchSettings?: PyTorchSettings;
  /**
   * TensorFlow settings. Settings for Tensor Flow job.
   */
  tensorFlowSettings?: TensorFlowSettings;
  /**
   * Caffe settings. Settings for Caffe job.
   */
  caffeSettings?: CaffeSettings;
  /**
   * Caffe2 settings. Settings for Caffe2 job.
   */
  caffe2Settings?: Caffe2Settings;
  /**
   * Chainer settings. Settings for Chainer job.
   */
  chainerSettings?: ChainerSettings;
  /**
   * Custom tool kit job. Settings for custom tool kit job.
   */
  customToolkitSettings?: CustomToolkitSettings;
  /**
   * Custom MPI settings. Settings for custom MPI job.
   */
  customMpiSettings?: CustomMpiSettings;
  /**
   * Horovod settings. Settings for Horovod job.
   */
  horovodSettings?: HorovodSettings;
  /**
   * Job preparation. A command line to be executed on each node allocated for the job before tool
   * kit is launched.
   */
  jobPreparation?: JobPreparation;
  /**
   * Standard output path prefix. The path where the Batch AI service will store stdout, stderror
   * and execution log of the job.
   */
  stdOutErrPathPrefix: string;
  /**
   * Input directories. A list of input directories for the job.
   */
  inputDirectories?: InputDirectory[];
  /**
   * Output directories. A list of output directories for the job.
   */
  outputDirectories?: OutputDirectory[];
  /**
   * Environment variables. A list of user defined environment variables which will be setup for
   * the job.
   */
  environmentVariables?: EnvironmentVariable[];
  /**
   * Secrets. A list of user defined environment variables with secret values which will be setup
   * for the job. Server will never report values of these variables back.
   */
  secrets?: EnvironmentVariableWithSecretValue[];
  /**
   * Constraints associated with the Job.
   */
  constraints?: JobBasePropertiesConstraints;
}

/**
 * Constraints associated with the Job.
 */
export interface JobPropertiesConstraints {
  /**
   * Max wall clock time. Max time the job can run. Default value: 1 week. Default value:
   * '7.00:00:00'.
   */
  maxWallClockTime?: string;
}

/**
 * Information about the execution of a job.
 */
export interface JobPropertiesExecutionInfo {
  /**
   * Start time. The time at which the job started running. 'Running' corresponds to the running
   * state. If the job has been restarted or retried, this is the most recent time at which the job
   * started running. This property is present only for job that are in the running or completed
   * state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly startTime?: Date;
  /**
   * End time. The time at which the job completed. This property is only returned if the job is in
   * completed state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly endTime?: Date;
  /**
   * Exit code. The exit code of the job. This property is only returned if the job is in completed
   * state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly exitCode?: number;
  /**
   * Errors. A collection of errors encountered by the service during job execution.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly errors?: BatchAIError[];
}

/**
 * Information about a Job.
 */
export interface Job extends ProxyResource {
  /**
   * Scheduling priority. Scheduling priority associated with the job. Possible values include:
   * 'low', 'normal', 'high'. Default value: 'normal'.
   */
  schedulingPriority?: JobPriority;
  /**
   * Cluster. Resource ID of the cluster associated with the job.
   */
  cluster?: ResourceId;
  /**
   * Mount volumes. Collection of mount volumes available to the job during execution. These
   * volumes are mounted before the job execution and unmounted after the job completion. The
   * volumes are mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
   */
  mountVolumes?: MountVolumes;
  /**
   * Number of compute nodes to run the job on. The job will be gang scheduled on that many compute
   * nodes
   */
  nodeCount?: number;
  /**
   * If provided the job will run in the specified container. If the container was downloaded as
   * part of cluster setup then the same container image will be used. If not provided, the job
   * will run on the VM.
   */
  containerSettings?: ContainerSettings;
  /**
   * The toolkit type of this job. Possible values are: cntk, tensorflow, caffe, caffe2, chainer,
   * pytorch, custom, custommpi, horovod. Possible values include: 'cntk', 'tensorflow', 'caffe',
   * 'caffe2', 'chainer', 'horovod', 'custommpi', 'custom'
   */
  toolType?: ToolType;
  /**
   * Specifies the settings for CNTK (aka Microsoft Cognitive Toolkit) job.
   */
  cntkSettings?: CNTKsettings;
  /**
   * Specifies the settings for pyTorch job.
   */
  pyTorchSettings?: PyTorchSettings;
  /**
   * Specifies the settings for Tensor Flow job.
   */
  tensorFlowSettings?: TensorFlowSettings;
  /**
   * Specifies the settings for Caffe job.
   */
  caffeSettings?: CaffeSettings;
  /**
   * Specifies the settings for Caffe2 job.
   */
  caffe2Settings?: Caffe2Settings;
  /**
   * Specifies the settings for Chainer job.
   */
  chainerSettings?: ChainerSettings;
  /**
   * Specifies the settings for custom tool kit job.
   */
  customToolkitSettings?: CustomToolkitSettings;
  /**
   * Specifies the settings for custom MPI job.
   */
  customMpiSettings?: CustomMpiSettings;
  /**
   * Specifies the settings for Horovod job.
   */
  horovodSettings?: HorovodSettings;
  /**
   * Specifies the actions to be performed before tool kit is launched. The specified actions will
   * run on all the nodes that are part of the job
   */
  jobPreparation?: JobPreparation;
  /**
   * Output directory path segment. A segment of job's output directories path created by Batch AI.
   * Batch AI creates job's output directories under an unique path to avoid conflicts between
   * jobs. This value contains a path segment generated by Batch AI to make the path unique and can
   * be used to find the output directory on the node or mounted filesystem.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly jobOutputDirectoryPathSegment?: string;
  /**
   * Standard output directory path prefix. The path where the Batch AI service stores stdout,
   * stderror and execution log of the job.
   */
  stdOutErrPathPrefix?: string;
  /**
   * Input directories. A list of input directories for the job.
   */
  inputDirectories?: InputDirectory[];
  /**
   * Output directories. A list of output directories for the job.
   */
  outputDirectories?: OutputDirectory[];
  /**
   * Environment variables. A collection of user defined environment variables to be setup for the
   * job.
   */
  environmentVariables?: EnvironmentVariable[];
  /**
   * Secrets. A collection of user defined environment variables with secret values to be setup for
   * the job. Server will never report values of these variables back.
   */
  secrets?: EnvironmentVariableWithSecretValue[];
  /**
   * Constraints associated with the Job.
   */
  constraints?: JobPropertiesConstraints;
  /**
   * Creation time. The creation time of the job.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly creationTime?: Date;
  /**
   * Provisioning state. The provisioned state of the Batch AI job. Possible values include:
   * 'creating', 'succeeded', 'failed', 'deleting'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningState?: ProvisioningState;
  /**
   * Provisioning state transition time. The time at which the job entered its current provisioning
   * state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningStateTransitionTime?: Date;
  /**
   * Execution state. The current state of the job. Possible values are: queued - The job is queued
   * and able to run. A job enters this state when it is created, or when it is awaiting a retry
   * after a failed run. running - The job is running on a compute cluster. This includes job-level
   * preparation such as downloading resource files or set up container specified on the job - it
   * does not necessarily mean that the job command line has started executing. terminating - The
   * job is terminated by the user, the terminate operation is in progress. succeeded - The job has
   * completed running successfully and exited with exit code 0. failed - The job has finished
   * unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is
   * also marked as failed if an error occurred launching the job. Possible values include:
   * 'queued', 'running', 'terminating', 'succeeded', 'failed'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly executionState?: ExecutionState;
  /**
   * Execution state transition time. The time at which the job entered its current execution
   * state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly executionStateTransitionTime?: Date;
  /**
   * Information about the execution of a job.
   */
  executionInfo?: JobPropertiesExecutionInfo;
}

/**
 * Login details to SSH to a compute node in cluster.
 */
export interface RemoteLoginInformation {
  /**
   * Node ID. ID of the compute node.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nodeId?: string;
  /**
   * IP address. Public IP address of the compute node.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly ipAddress?: string;
  /**
   * Port. SSH port number of the node.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly port?: number;
}

/**
 * Properties of the file or directory.
 */
export interface File {
  /**
   * Name. Name of the file.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: string;
  /**
   * File type. Type of the file. Possible values are file and directory. Possible values include:
   * 'file', 'directory'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly fileType?: FileType;
  /**
   * Download URL. URL to download the corresponding file. The downloadUrl is not returned for
   * directories.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly downloadUrl?: string;
  /**
   * Last modified time. The time at which the file was last modified.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly lastModified?: Date;
  /**
   * Content length. The file of the size.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly contentLength?: number;
}

/**
 * A definition of an Azure resource.
 */
export interface Resource extends BaseResource {
  /**
   * The ID of the resource
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly id?: string;
  /**
   * The name of the resource
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: string;
  /**
   * The type of the resource
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly type?: string;
  /**
   * The location of the resource
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly location?: string;
  /**
   * The tags of the resource
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly tags?: { [propertyName: string]: string };
}

/**
 * The object that describes the operation.
 */
export interface OperationDisplay {
  /**
   * Friendly name of the resource provider. **NOTE: This property will not be serialized. It can
   * only be populated by the server.**
   */
  readonly provider?: string;
  /**
   * The operation type. For example: read, write, delete, or listKeys/action
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly operation?: string;
  /**
   * The resource type on which the operation is performed. **NOTE: This property will not be
   * serialized. It can only be populated by the server.**
   */
  readonly resource?: string;
  /**
   * The friendly name of the operation. **NOTE: This property will not be serialized. It can only
   * be populated by the server.**
   */
  readonly description?: string;
}

/**
 * Details of a REST API operation
 * @summary A REST API operation.
 */
export interface Operation {
  /**
   * The operation name. This is of the format {provider}/{resource}/{operation}
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: string;
  /**
   * The object that describes the operation.
   */
  display?: OperationDisplay;
  /**
   * The intended executor of the operation. **NOTE: This property will not be serialized. It can
   * only be populated by the server.**
   */
  readonly origin?: string;
  /**
   * Properties of the operation.
   */
  properties?: any;
}

/**
 * Batch AI Workspace information.
 */
export interface Workspace extends Resource {
  /**
   * Creation time. Time when the Workspace was created.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly creationTime?: Date;
  /**
   * Provisioning state. The provisioned state of the Workspace. Possible values include:
   * 'creating', 'succeeded', 'failed', 'deleting'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningState?: ProvisioningState;
  /**
   * Provisioning state transition time. The time at which the workspace entered its current
   * provisioning state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningStateTransitionTime?: Date;
}

/**
 * Workspace creation parameters.
 */
export interface WorkspaceCreateParameters {
  /**
   * Location. The region in which to create the Workspace.
   */
  location: string;
  /**
   * Tags. The user specified tags associated with the Workspace.
   */
  tags?: { [propertyName: string]: string };
}

/**
 * Workspace update parameters.
 */
export interface WorkspaceUpdateParameters {
  /**
   * Tags. The user specified tags associated with the Workspace.
   */
  tags?: { [propertyName: string]: string };
}

/**
 * Experiment information.
 */
export interface Experiment extends ProxyResource {
  /**
   * Creation time. Time when the Experiment was created.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly creationTime?: Date;
  /**
   * Provisioning state. The provisioned state of the experiment. Possible values include:
   * 'creating', 'succeeded', 'failed', 'deleting'
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningState?: ProvisioningState;
  /**
   * Provisioning state transition time. The time at which the experiment entered its current
   * provisioning state.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly provisioningStateTransitionTime?: Date;
}

/**
 * Additional parameters for list operation.
 */
export interface WorkspacesListOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listByResourceGroup operation.
 */
export interface WorkspacesListByResourceGroupOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listByWorkspace operation.
 */
export interface ExperimentsListByWorkspaceOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listByExperiment operation.
 */
export interface JobsListByExperimentOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listOutputFiles operation.
 */
export interface JobsListOutputFilesOptions {
  /**
   * Id of the job output directory. This is the OutputDirectory-->id parameter that is given by
   * the user during Create Job.
   */
  outputdirectoryid: string;
  /**
   * The path to the directory. Default value: '.'.
   */
  directory?: string;
  /**
   * The number of minutes after which the download link will expire. Default value: 60.
   */
  linkexpiryinminutes?: number;
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listByWorkspace operation.
 */
export interface FileServersListByWorkspaceOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Additional parameters for listByWorkspace operation.
 */
export interface ClustersListByWorkspaceOptions {
  /**
   * The maximum number of items to return in the response. A maximum of 1000 files can be
   * returned. Default value: 1000.
   */
  maxResults?: number;
}

/**
 * Optional Parameters.
 */
export interface WorkspacesListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  workspacesListOptions?: WorkspacesListOptions;
}

/**
 * Optional Parameters.
 */
export interface WorkspacesListByResourceGroupOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  workspacesListByResourceGroupOptions?: WorkspacesListByResourceGroupOptions;
}

/**
 * Optional Parameters.
 */
export interface WorkspacesUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Tags. The user specified tags associated with the Workspace.
   */
  tags?: { [propertyName: string]: string };
}

/**
 * Optional Parameters.
 */
export interface ExperimentsListByWorkspaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  experimentsListByWorkspaceOptions?: ExperimentsListByWorkspaceOptions;
}

/**
 * Optional Parameters.
 */
export interface JobsListByExperimentOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  jobsListByExperimentOptions?: JobsListByExperimentOptions;
}

/**
 * Optional Parameters.
 */
export interface FileServersListByWorkspaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  fileServersListByWorkspaceOptions?: FileServersListByWorkspaceOptions;
}

/**
 * Optional Parameters.
 */
export interface ClustersUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Scale settings. Desired scale settings for the cluster. Batch AI service supports manual and
   * auto scale clusters.
   */
  scaleSettings?: ScaleSettings;
}

/**
 * Optional Parameters.
 */
export interface ClustersListByWorkspaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Additional parameters for the operation
   */
  clustersListByWorkspaceOptions?: ClustersListByWorkspaceOptions;
}

/**
 * An interface representing BatchAIManagementClientOptions.
 */
export interface BatchAIManagementClientOptions extends AzureServiceClientOptions {
  baseUri?: string;
}

/**
 * @interface
 * Contains the list of all operations supported by BatchAI resource provider
 * @summary Result of the request to list REST API operations. It contains a list of operations and
 * a URL nextLink to get the next set of results.
 * @extends Array<Operation>
 */
export interface OperationListResult extends Array<Operation> {
  /**
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * The List Usages operation response.
 * @extends Array<Usage>
 */
export interface ListUsagesResult extends Array<Usage> {
  /**
   * The URI to fetch the next page of compute resource usage information. Call ListNext() with
   * this to fetch the next page of compute resource usage information.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List operation.
 * @extends Array<Workspace>
 */
export interface WorkspaceListResult extends Array<Workspace> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List operation.
 * @extends Array<Experiment>
 */
export interface ExperimentListResult extends Array<Experiment> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List operation.
 * @extends Array<Job>
 */
export interface JobListResult extends Array<Job> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List operation.
 * @extends Array<File>
 */
export interface FileListResult extends Array<File> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List operation.
 * @extends Array<RemoteLoginInformation>
 */
export interface RemoteLoginInformationListResult extends Array<RemoteLoginInformation> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the File Server List operation.
 * @extends Array<FileServer>
 */
export interface FileServerListResult extends Array<FileServer> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * @interface
 * Values returned by the List Clusters operation.
 * @extends Array<Cluster>
 */
export interface ClusterListResult extends Array<Cluster> {
  /**
   * The continuation token.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly nextLink?: string;
}

/**
 * Defines values for UsageUnit.
 * Possible values include: 'Count'
 * @readonly
 * @enum {string}
 */
export type UsageUnit = 'Count';

/**
 * Defines values for CachingType.
 * Possible values include: 'none', 'readonly', 'readwrite'
 * @readonly
 * @enum {string}
 */
export type CachingType = 'none' | 'readonly' | 'readwrite';

/**
 * Defines values for StorageAccountType.
 * Possible values include: 'Standard_LRS', 'Premium_LRS'
 * @readonly
 * @enum {string}
 */
export type StorageAccountType = 'Standard_LRS' | 'Premium_LRS';

/**
 * Defines values for FileServerProvisioningState.
 * Possible values include: 'creating', 'updating', 'deleting', 'succeeded', 'failed'
 * @readonly
 * @enum {string}
 */
export type FileServerProvisioningState = 'creating' | 'updating' | 'deleting' | 'succeeded' | 'failed';

/**
 * Defines values for VmPriority.
 * Possible values include: 'dedicated', 'lowpriority'
 * @readonly
 * @enum {string}
 */
export type VmPriority = 'dedicated' | 'lowpriority';

/**
 * Defines values for DeallocationOption.
 * Possible values include: 'requeue', 'terminate', 'waitforjobcompletion'
 * @readonly
 * @enum {string}
 */
export type DeallocationOption = 'requeue' | 'terminate' | 'waitforjobcompletion';

/**
 * Defines values for ProvisioningState.
 * Possible values include: 'creating', 'succeeded', 'failed', 'deleting'
 * @readonly
 * @enum {string}
 */
export type ProvisioningState = 'creating' | 'succeeded' | 'failed' | 'deleting';

/**
 * Defines values for AllocationState.
 * Possible values include: 'steady', 'resizing'
 * @readonly
 * @enum {string}
 */
export type AllocationState = 'steady' | 'resizing';

/**
 * Defines values for JobPriority.
 * Possible values include: 'low', 'normal', 'high'
 * @readonly
 * @enum {string}
 */
export type JobPriority = 'low' | 'normal' | 'high';

/**
 * Defines values for ToolType.
 * Possible values include: 'cntk', 'tensorflow', 'caffe', 'caffe2', 'chainer', 'horovod',
 * 'custommpi', 'custom'
 * @readonly
 * @enum {string}
 */
export type ToolType = 'cntk' | 'tensorflow' | 'caffe' | 'caffe2' | 'chainer' | 'horovod' | 'custommpi' | 'custom';

/**
 * Defines values for ExecutionState.
 * Possible values include: 'queued', 'running', 'terminating', 'succeeded', 'failed'
 * @readonly
 * @enum {string}
 */
export type ExecutionState = 'queued' | 'running' | 'terminating' | 'succeeded' | 'failed';

/**
 * Defines values for FileType.
 * Possible values include: 'file', 'directory'
 * @readonly
 * @enum {string}
 */
export type FileType = 'file' | 'directory';

/**
 * Contains response data for the list operation.
 */
export type OperationsListResponse = OperationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: OperationListResult;
    };
};

/**
 * Contains response data for the listNext operation.
 */
export type OperationsListNextResponse = OperationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: OperationListResult;
    };
};

/**
 * Contains response data for the list operation.
 */
export type UsagesListResponse = ListUsagesResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ListUsagesResult;
    };
};

/**
 * Contains response data for the listNext operation.
 */
export type UsagesListNextResponse = ListUsagesResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ListUsagesResult;
    };
};

/**
 * Contains response data for the list operation.
 */
export type WorkspacesListResponse = WorkspaceListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: WorkspaceListResult;
    };
};

/**
 * Contains response data for the listByResourceGroup operation.
 */
export type WorkspacesListByResourceGroupResponse = WorkspaceListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: WorkspaceListResult;
    };
};

/**
 * Contains response data for the create operation.
 */
export type WorkspacesCreateResponse = Workspace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Workspace;
    };
};

/**
 * Contains response data for the update operation.
 */
export type WorkspacesUpdateResponse = Workspace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Workspace;
    };
};

/**
 * Contains response data for the get operation.
 */
export type WorkspacesGetResponse = Workspace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Workspace;
    };
};

/**
 * Contains response data for the beginCreate operation.
 */
export type WorkspacesBeginCreateResponse = Workspace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Workspace;
    };
};

/**
 * Contains response data for the listNext operation.
 */
export type WorkspacesListNextResponse = WorkspaceListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: WorkspaceListResult;
    };
};

/**
 * Contains response data for the listByResourceGroupNext operation.
 */
export type WorkspacesListByResourceGroupNextResponse = WorkspaceListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: WorkspaceListResult;
    };
};

/**
 * Contains response data for the listByWorkspace operation.
 */
export type ExperimentsListByWorkspaceResponse = ExperimentListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ExperimentListResult;
    };
};

/**
 * Contains response data for the create operation.
 */
export type ExperimentsCreateResponse = Experiment & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Experiment;
    };
};

/**
 * Contains response data for the get operation.
 */
export type ExperimentsGetResponse = Experiment & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Experiment;
    };
};

/**
 * Contains response data for the beginCreate operation.
 */
export type ExperimentsBeginCreateResponse = Experiment & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Experiment;
    };
};

/**
 * Contains response data for the listByWorkspaceNext operation.
 */
export type ExperimentsListByWorkspaceNextResponse = ExperimentListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ExperimentListResult;
    };
};

/**
 * Contains response data for the listByExperiment operation.
 */
export type JobsListByExperimentResponse = JobListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: JobListResult;
    };
};

/**
 * Contains response data for the create operation.
 */
export type JobsCreateResponse = Job & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Job;
    };
};

/**
 * Contains response data for the get operation.
 */
export type JobsGetResponse = Job & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Job;
    };
};

/**
 * Contains response data for the listOutputFiles operation.
 */
export type JobsListOutputFilesResponse = FileListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileListResult;
    };
};

/**
 * Contains response data for the listRemoteLoginInformation operation.
 */
export type JobsListRemoteLoginInformationResponse = RemoteLoginInformationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: RemoteLoginInformationListResult;
    };
};

/**
 * Contains response data for the beginCreate operation.
 */
export type JobsBeginCreateResponse = Job & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Job;
    };
};

/**
 * Contains response data for the listByExperimentNext operation.
 */
export type JobsListByExperimentNextResponse = JobListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: JobListResult;
    };
};

/**
 * Contains response data for the listOutputFilesNext operation.
 */
export type JobsListOutputFilesNextResponse = FileListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileListResult;
    };
};

/**
 * Contains response data for the listRemoteLoginInformationNext operation.
 */
export type JobsListRemoteLoginInformationNextResponse = RemoteLoginInformationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: RemoteLoginInformationListResult;
    };
};

/**
 * Contains response data for the create operation.
 */
export type FileServersCreateResponse = FileServer & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileServer;
    };
};

/**
 * Contains response data for the listByWorkspace operation.
 */
export type FileServersListByWorkspaceResponse = FileServerListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileServerListResult;
    };
};

/**
 * Contains response data for the beginCreate operation.
 */
export type FileServersBeginCreateResponse = FileServer & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileServer;
    };
};

/**
 * Contains response data for the listByWorkspaceNext operation.
 */
export type FileServersListByWorkspaceNextResponse = FileServerListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FileServerListResult;
    };
};

/**
 * Contains response data for the create operation.
 */
export type ClustersCreateResponse = Cluster & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Cluster;
    };
};

/**
 * Contains response data for the update operation.
 */
export type ClustersUpdateResponse = Cluster & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Cluster;
    };
};

/**
 * Contains response data for the get operation.
 */
export type ClustersGetResponse = Cluster & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Cluster;
    };
};

/**
 * Contains response data for the listRemoteLoginInformation operation.
 */
export type ClustersListRemoteLoginInformationResponse = RemoteLoginInformationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: RemoteLoginInformationListResult;
    };
};

/**
 * Contains response data for the listByWorkspace operation.
 */
export type ClustersListByWorkspaceResponse = ClusterListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ClusterListResult;
    };
};

/**
 * Contains response data for the beginCreate operation.
 */
export type ClustersBeginCreateResponse = Cluster & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Cluster;
    };
};

/**
 * Contains response data for the listRemoteLoginInformationNext operation.
 */
export type ClustersListRemoteLoginInformationNextResponse = RemoteLoginInformationListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: RemoteLoginInformationListResult;
    };
};

/**
 * Contains response data for the listByWorkspaceNext operation.
 */
export type ClustersListByWorkspaceNextResponse = ClusterListResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ClusterListResult;
    };
};
