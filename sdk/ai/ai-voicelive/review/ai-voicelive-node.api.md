## API Report File for "@azure/ai-voicelive"

> Do not edit this file. It is a report generated by [API Extractor](https://api-extractor.com/).

```ts

import type { AbortSignalLike } from '@azure/abort-controller';
import type { TokenCredential } from '@azure/core-auth';

// @public
export interface AgentConfig {
    agentId: string;
    description?: string;
    name: string;
    threadId: string;
    type: "agent";
}

// @public
export interface Animation {
    modelName?: string;
    outputs?: AnimationOutputType[];
}

// @public
export type AnimationOutputType = string;

// @public (undocumented)
export interface AnimationStreamChunk {
    // (undocumented)
    frameIndex?: number;
    // (undocumented)
    frames?: number[][] | string;
    // (undocumented)
    responseId: string;
    // (undocumented)
    timestamp: number;
    // (undocumented)
    type: 'animation';
}

// @public
export interface AssistantMessageItem extends MessageItem {
    // (undocumented)
    role: "assistant";
}

// @public (undocumented)
export interface AsyncIterableWithPages<T> extends AsyncIterable<T> {
    // (undocumented)
    byPage(settings?: {
        maxPageSize?: number;
    }): AsyncIterableIterator<PagedResult<T>>;
}

// @public (undocumented)
export interface AudioChunk {
    // (undocumented)
    data: ArrayBuffer;
    // (undocumented)
    duration: number;
    // (undocumented)
    format: AudioFormat;
    // (undocumented)
    timestamp: number;
}

// @public
export interface AudioEchoCancellation {
    type: "server_echo_cancellation";
}

// @public (undocumented)
export interface AudioFormat {
    // (undocumented)
    bitDepth: number;
    // (undocumented)
    channels: number;
    // (undocumented)
    encoding: 'pcm' | 'opus' | 'aac';
    // (undocumented)
    sampleRate: number;
}

// @public
export interface AudioInputTranscriptionOptions {
    customSpeech?: Record<string, string>;
    language?: string;
    model: string;
    phraseList?: string[];
}

// @public
export interface AudioNoiseReduction {
    type: string;
}

// @public (undocumented)
export interface AudioProcessingOptions {
    echoCancellation?: boolean;
    gain?: number;
    noiseReduction?: boolean;
    targetFormat?: AudioFormat;
}

// @public
export class AudioProcessor {
    audioToBase64(chunk: AudioChunk): string;
    base64ToAudio(base64: string, format: AudioFormat): AudioChunk;
    get defaultFormat(): AudioFormat;
    processIncomingAudio(data: ArrayBuffer, format: AudioFormat, options?: AudioProcessingOptions): AudioChunk;
}

// @public (undocumented)
export interface AudioStreamChunk {
    // (undocumented)
    data: ArrayBuffer;
    // (undocumented)
    format?: string;
    // (undocumented)
    itemId?: string;
    // (undocumented)
    responseId: string;
    // (undocumented)
    timestamp: number;
    // (undocumented)
    type: 'audio';
}

// @public (undocumented)
export interface AudioStreamOptions extends SendEventOptions {
    turnId?: string;
}

// @public
export type AudioTimestampType = string;

// @public
export interface AvatarConfig {
    character: string;
    customized: boolean;
    iceServers?: IceServer[];
    style?: string;
    video?: VideoParams;
}

// @public (undocumented)
export interface AvatarConfiguration {
    id: string;
    name?: string;
    settings?: Record<string, any>;
}

// @public (undocumented)
export interface AvatarEventHandlers {
    // (undocumented)
    onAvatarStateChange?: (state: AvatarState) => void;
    // (undocumented)
    onBlendshapeUpdate?: (blendshapes: Record<string, number>) => void;
    // (undocumented)
    onConnectionStatusChange?: (status: AvatarState['connectionStatus']) => void;
    // (undocumented)
    onVisemeUpdate?: (visemes: Array<{
        id: string;
        weight: number;
    }>) => void;
}

// @public (undocumented)
export interface AvatarFrame {
    // (undocumented)
    blendshapes: Record<string, number>;
    // (undocumented)
    timestamp: number;
    // (undocumented)
    visemes: Array<{
        id: string;
        weight: number;
    }>;
}

// @public
export class AvatarManager {
    constructor(_eventEmitter: EnhancedVoiceLiveEventEmitter, _videoProcessor: VideoProcessor);
    get connectionStatus(): AvatarState['connectionStatus'];
    createCurrentAvatarFrame(): AvatarFrame;
    get currentState(): AvatarState;
    getActiveVisemes(targetTime: number): Array<{
        id: string;
        weight: number;
    }>;
    getInterpolatedAvatarFrame(targetTime: number): AvatarFrame;
    getInterpolatedBlendshapes(targetTime: number): Record<string, number>;
    handleAvatarConnecting(_event: ServerEventSessionAvatarConnecting): void;
    handleBlendshapeUpdate(event: ServerEventResponseAnimationBlendshapeDelta): void;
    handleVisemeUpdate(event: ServerEventResponseAnimationVisemeDelta): void;
    setAvatarConfig(config: AvatarConfiguration): void;
    setEventHandlers(handlers: AvatarEventHandlers): void;
}

// @public (undocumented)
export interface AvatarState {
    // (undocumented)
    config?: AvatarConfiguration;
    // (undocumented)
    connectionStatus: 'disconnected' | 'connecting' | 'connected' | 'error';
    // (undocumented)
    currentBlendshapes: Record<string, number>;
    // (undocumented)
    currentVisemes: Array<{
        id: string;
        weight: number;
        timestamp: number;
    }>;
    // (undocumented)
    isConnected: boolean;
    // (undocumented)
    lastUpdate: number;
}

// @public
export interface AzureCustomVoice extends AzureVoice {
    // (undocumented)
    customLexiconUrl?: string;
    endpointId: string;
    // (undocumented)
    locale?: string;
    name: string;
    // (undocumented)
    pitch?: string;
    // (undocumented)
    preferLocales?: string[];
    // (undocumented)
    rate?: string;
    // (undocumented)
    style?: string;
    temperature?: number;
    // (undocumented)
    type: "azure-custom";
    // (undocumented)
    volume?: string;
}

// @public
export interface AzurePersonalVoice extends AzureVoice {
    model: PersonalVoiceModels;
    name: string;
    temperature?: number;
    // (undocumented)
    type: "azure-personal";
}

// @public
export interface AzureSemanticDetection extends EouDetection {
    // (undocumented)
    model: "semantic_detection_v1";
    thresholdLevel?: EouThresholdLevel;
    timeoutMs?: number;
}

// @public
export interface AzureSemanticDetectionEn extends EouDetection {
    // (undocumented)
    model: "semantic_detection_v1_en";
    thresholdLevel?: EouThresholdLevel;
    timeoutMs?: number;
}

// @public
export interface AzureSemanticDetectionMultilingual extends EouDetection {
    // (undocumented)
    model: "semantic_detection_v1_multilingual";
    thresholdLevel?: EouThresholdLevel;
    timeoutMs?: number;
}

// @public
export interface AzureSemanticVad extends TurnDetection {
    // (undocumented)
    autoTruncate?: boolean;
    // (undocumented)
    createResponse?: boolean;
    // (undocumented)
    endOfUtteranceDetection?: EouDetectionUnion;
    // (undocumented)
    interruptResponse?: boolean;
    // (undocumented)
    languages?: string[];
    // (undocumented)
    prefixPaddingMs?: number;
    // (undocumented)
    removeFillerWords?: boolean;
    // (undocumented)
    silenceDurationMs?: number;
    // (undocumented)
    speechDurationMs?: number;
    // (undocumented)
    threshold?: number;
    // (undocumented)
    type: "azure_semantic_vad";
}

// @public
export interface AzureSemanticVadEn extends TurnDetection {
    // (undocumented)
    autoTruncate?: boolean;
    // (undocumented)
    createResponse?: boolean;
    // (undocumented)
    endOfUtteranceDetection?: EouDetectionUnion;
    // (undocumented)
    interruptResponse?: boolean;
    // (undocumented)
    prefixPaddingMs?: number;
    // (undocumented)
    removeFillerWords?: boolean;
    // (undocumented)
    silenceDurationMs?: number;
    // (undocumented)
    speechDurationMs?: number;
    // (undocumented)
    threshold?: number;
    // (undocumented)
    type: "azure_semantic_vad_en";
}

// @public
export interface AzureSemanticVadMultilingual extends TurnDetection {
    // (undocumented)
    autoTruncate?: boolean;
    // (undocumented)
    createResponse?: boolean;
    // (undocumented)
    endOfUtteranceDetection?: EouDetectionUnion;
    // (undocumented)
    interruptResponse?: boolean;
    // (undocumented)
    languages?: string[];
    // (undocumented)
    prefixPaddingMs?: number;
    // (undocumented)
    removeFillerWords?: boolean;
    // (undocumented)
    silenceDurationMs?: number;
    // (undocumented)
    speechDurationMs?: number;
    // (undocumented)
    threshold?: number;
    // (undocumented)
    type: "azure_semantic_vad_multilingual";
}

// @public
export interface AzureStandardVoice extends AzureVoice {
    // (undocumented)
    customLexiconUrl?: string;
    // (undocumented)
    locale?: string;
    name: string;
    // (undocumented)
    pitch?: string;
    // (undocumented)
    preferLocales?: string[];
    // (undocumented)
    rate?: string;
    // (undocumented)
    style?: string;
    temperature?: number;
    // (undocumented)
    type: "azure-standard";
    // (undocumented)
    volume?: string;
}

// @public
export interface AzureVoice {
    type: AzureVoiceType;
}

// @public
export type AzureVoiceType = string;

// @public
export type AzureVoiceUnion = AzureCustomVoice | AzureStandardVoice | AzurePersonalVoice | AzureVoice;

// @public
export interface Background {
    color?: string;
    imageUrl?: string;
}

// @public (undocumented)
export interface BlendshapeConfig {
    defaults: Record<string, number>;
    ranges: Record<string, {
        min: number;
        max: number;
    }>;
}

// @public (undocumented)
export interface BlendshapeFrame {
    // (undocumented)
    data: Record<string, number>;
    // (undocumented)
    frameIndex: number;
    // (undocumented)
    timestamp: number;
}

// @public
export interface CachedTokenDetails {
    audioTokens: number;
    textTokens: number;
}

// @public
export interface ClientEvent {
    // (undocumented)
    eventId?: string;
    type: ClientEventType;
}

// @public
export interface ClientEventConversationItemCreate extends ClientEvent {
    eventId?: string;
    // (undocumented)
    item?: ConversationRequestItemUnion;
    previousItemId?: string;
    type: "conversation.item.create";
}

// @public
export interface ClientEventConversationItemDelete extends ClientEvent {
    itemId: string;
    type: "conversation.item.delete";
}

// @public
export interface ClientEventConversationItemRetrieve extends ClientEvent {
    itemId: string;
    type: "conversation.item.retrieve";
}

// @public
export interface ClientEventConversationItemTruncate extends ClientEvent {
    audioEndMs: number;
    contentIndex: number;
    itemId: string;
    type: "conversation.item.truncate";
}

// @public
export interface ClientEventInputAudioBufferAppend extends ClientEvent {
    audio: string;
    type: "input_audio_buffer.append";
}

// @public
export interface ClientEventInputAudioBufferClear extends ClientEvent {
    type: "input_audio_buffer.clear";
}

// @public
export interface ClientEventInputAudioBufferCommit extends ClientEvent {
    type: "input_audio_buffer.commit";
}

// @public
export interface ClientEventInputAudioClear extends ClientEvent {
    type: "input_audio.clear";
}

// @public
export interface ClientEventInputAudioTurnAppend extends ClientEvent {
    audio: string;
    turnId: string;
    type: "input_audio.turn.append";
}

// @public
export interface ClientEventInputAudioTurnCancel extends ClientEvent {
    turnId: string;
    type: "input_audio.turn.cancel";
}

// @public
export interface ClientEventInputAudioTurnEnd extends ClientEvent {
    turnId: string;
    type: "input_audio.turn.end";
}

// @public
export interface ClientEventInputAudioTurnStart extends ClientEvent {
    turnId: string;
    type: "input_audio.turn.start";
}

// @public
export interface ClientEventResponseCancel extends ClientEvent {
    responseId?: string;
    type: "response.cancel";
}

// @public
export interface ClientEventResponseCreate extends ClientEvent {
    additionalInstructions?: string;
    // (undocumented)
    response?: ResponseCreateParams;
    type: "response.create";
}

// @public
export interface ClientEventSessionAvatarConnect extends ClientEvent {
    clientSdp: string;
    type: "session.avatar.connect";
}

// @public
export interface ClientEventSessionUpdate extends ClientEvent {
    // (undocumented)
    session: RequestSession;
    type: "session.update";
}

// @public
export type ClientEventType = string;

// @public
export type ClientEventUnion = ClientEventSessionUpdate | ClientEventSessionAvatarConnect | ClientEventInputAudioTurnStart | ClientEventInputAudioTurnAppend | ClientEventInputAudioTurnEnd | ClientEventInputAudioTurnCancel | ClientEventInputAudioClear | ClientEventInputAudioBufferAppend | ClientEventInputAudioBufferCommit | ClientEventInputAudioBufferClear | ClientEventConversationItemCreate | ClientEventConversationItemTruncate | ClientEventConversationItemDelete | ClientEventResponseCreate | ClientEventResponseCancel | ClientEventConversationItemRetrieve | ClientEvent;

// @public
export interface ConnectedEventArgs {
    // (undocumented)
    connectionId: string;
    // (undocumented)
    sessionId?: string;
    // (undocumented)
    timestamp: Date;
}

// @public
export enum ConnectionState {
    // (undocumented)
    Connected = "connected",
    // (undocumented)
    Connecting = "connecting",
    // (undocumented)
    Disconnected = "disconnected",
    // (undocumented)
    Disconnecting = "disconnecting",
    // (undocumented)
    Reconnecting = "reconnecting"
}

// @public (undocumented)
export interface ConnectOptions {
    abortSignal?: AbortSignalLike;
    timeoutMs?: number;
}

// @public
export interface ContentPart {
    // (undocumented)
    type: ContentPartType;
}

// @public
export type ContentPartType = string;

// @public
export type ContentPartUnion = RequestTextContentPart | RequestAudioContentPart | ResponseTextContentPart | ResponseAudioContentPart | ContentPart;

// @public (undocumented)
export interface ConversationHistoryOptions {
    itemType?: string;
    maxPageSize?: number;
    participantIds?: string[];
    startFromId?: string;
}

// @public
export interface ConversationItemBase {
}

// @public
export interface ConversationRequestItem {
    // (undocumented)
    id?: string;
    // (undocumented)
    type: ItemType;
}

// @public
export type ConversationRequestItemUnion = MessageItemUnion | FunctionCallItem | FunctionCallOutputItem | ConversationRequestItem;

// @public (undocumented)
export interface DisconnectedEventArgs {
    // (undocumented)
    code: number;
    // (undocumented)
    reason: string;
    // (undocumented)
    timestamp: Date;
    // (undocumented)
    wasClean: boolean;
}

// @public
export class EnhancedVoiceLiveEventEmitter extends VoiceLiveEventEmitter {
    createEventStream<K extends keyof VoiceLiveEventMap>(event: K, options?: EventStreamOptions): AsyncIterableIterator<VoiceLiveEventMap[K]>;
    createFilteredEventStream<K extends keyof VoiceLiveEventMap>(event: K, filter: EventFilter<VoiceLiveEventMap[K]>, options?: EventStreamOptions): AsyncIterableIterator<VoiceLiveEventMap[K]>;
    createTransformedEventStream<K extends keyof VoiceLiveEventMap, TOutput>(event: K, transform: EventTransform<VoiceLiveEventMap[K], TOutput>, options?: EventStreamOptions): AsyncIterableIterator<TOutput>;
    waitForEvent<K extends keyof VoiceLiveEventMap>(event: K, filter?: EventFilter<VoiceLiveEventMap[K]>, timeoutMs?: number): Promise<VoiceLiveEventMap[K]>;
    waitForEvents<K extends keyof VoiceLiveEventMap>(events: K[], timeoutMs?: number): Promise<{
        [P in K]: VoiceLiveEventMap[P];
    }>;
}

// @public
export interface EouDetection {
    // (undocumented)
    model: string;
}

// @public
export type EouDetectionUnion = AzureSemanticDetection | AzureSemanticDetectionEn | AzureSemanticDetectionMultilingual | EouDetection;

// @public
export type EouThresholdLevel = string;

// @public (undocumented)
export interface ErrorEventArgs {
    // (undocumented)
    context: string;
    // (undocumented)
    error: Error;
    // (undocumented)
    recoverable: boolean;
    // (undocumented)
    timestamp: Date;
}

// @public
export interface ErrorResponse {
    error: VoiceLiveErrorDetails;
}

// @public (undocumented)
export interface EventFilter<T> {
    // (undocumented)
    (event: T): boolean;
}

// @public
export type EventListener<T> = (args: T) => void;

// @public (undocumented)
export interface EventStreamOptions {
    abortSignal?: AbortSignal;
    bufferSize?: number;
    filter?: EventFilter<any>;
    timeoutMs?: number;
}

// @public (undocumented)
export interface EventTransform<TInput, TOutput> {
    // (undocumented)
    (event: TInput): TOutput;
}

// @public
export interface FunctionCallItem extends ConversationRequestItem {
    // (undocumented)
    arguments: string;
    // (undocumented)
    callId: string;
    // (undocumented)
    name: string;
    // (undocumented)
    status?: ItemParamStatus;
    // (undocumented)
    type: "function_call";
}

// @public
export interface FunctionCallOutputItem extends ConversationRequestItem {
    // (undocumented)
    callId: string;
    // (undocumented)
    output: string;
    // (undocumented)
    status?: ItemParamStatus;
    // (undocumented)
    type: "function_call_output";
}

// @public
export interface FunctionTool extends Tool {
    // (undocumented)
    description?: string;
    // (undocumented)
    name: string;
    // (undocumented)
    parameters?: any;
    // (undocumented)
    type: "function";
}

// @public
export interface IceServer {
    credential?: string;
    urls: string[];
    username?: string;
}

// @public
export interface InputAudioContentPart extends MessageContentPart {
    // (undocumented)
    audio: string;
    // (undocumented)
    transcript?: string;
    // (undocumented)
    type: "input_audio";
}

// @public
export type InputAudioFormat = string;

// @public
export interface InputTextContentPart extends MessageContentPart {
    // (undocumented)
    text: string;
    // (undocumented)
    type: "input_text";
}

// @public
export interface InputTokenDetails {
    audioTokens: number;
    cachedTokens: number;
    cachedTokensDetails: CachedTokenDetails;
    textTokens: number;
}

// @public
export type ItemParamStatus = string;

// @public
export type ItemType = string;

// @public
export enum KnownAnimationOutputType {
    Blendshapes = "blendshapes",
    VisemeId = "viseme_id"
}

// @public
export enum KnownAudioTimestampType {
    Word = "word"
}

// @public
export enum KnownAzureVoiceType {
    AzureCustom = "azure-custom",
    AzurePersonal = "azure-personal",
    AzureStandard = "azure-standard"
}

// @public
export enum KnownClientEventType {
    ConversationItemCreate = "conversation.item.create",
    ConversationItemDelete = "conversation.item.delete",
    ConversationItemRetrieve = "conversation.item.retrieve",
    ConversationItemTruncate = "conversation.item.truncate",
    InputAudioBufferAppend = "input_audio_buffer.append",
    InputAudioBufferClear = "input_audio_buffer.clear",
    InputAudioBufferCommit = "input_audio_buffer.commit",
    InputAudioClear = "input_audio.clear",
    InputAudioTurnAppend = "input_audio.turn.append",
    InputAudioTurnCancel = "input_audio.turn.cancel",
    InputAudioTurnEnd = "input_audio.turn.end",
    InputAudioTurnStart = "input_audio.turn.start",
    ResponseCancel = "response.cancel",
    ResponseCreate = "response.create",
    SessionAvatarConnect = "session.avatar.connect",
    SessionUpdate = "session.update"
}

// @public
export enum KnownContentPartType {
    Audio = "audio",
    InputAudio = "input_audio",
    InputText = "input_text",
    Text = "text"
}

// @public
export enum KnownEouThresholdLevel {
    Default = "default",
    High = "high",
    Low = "low",
    Medium = "medium"
}

// @public
export enum KnownInputAudioFormat {
    G711Alaw = "g711_alaw",
    G711Ulaw = "g711_ulaw",
    Pcm16 = "pcm16"
}

// @public
export enum KnownItemParamStatus {
    Completed = "completed",
    Incomplete = "incomplete"
}

// @public
export enum KnownItemType {
    FunctionCall = "function_call",
    FunctionCallOutput = "function_call_output",
    Message = "message"
}

// @public
export enum KnownMessageRole {
    Assistant = "assistant",
    System = "system",
    User = "user"
}

// @public
export enum KnownModality {
    Animation = "animation",
    Audio = "audio",
    Avatar = "avatar",
    Text = "text"
}

// @public
export enum KnownOAIVoice {
    Alloy = "alloy",
    Ash = "ash",
    Ballad = "ballad",
    Coral = "coral",
    Echo = "echo",
    Sage = "sage",
    Shimmer = "shimmer",
    Verse = "verse"
}

// @public
export enum KnownOutputAudioFormat {
    G711Alaw = "g711_alaw",
    G711Ulaw = "g711_ulaw",
    Pcm16 = "pcm16",
    Pcm1616000Hz = "pcm16-16000hz",
    Pcm168000Hz = "pcm16-8000hz"
}

// @public
export enum KnownPersonalVoiceModels {
    DragonLatestNeural = "DragonLatestNeural",
    PhoenixLatestNeural = "PhoenixLatestNeural",
    PhoenixV2Neural = "PhoenixV2Neural"
}

// @public
export enum KnownResponseItemStatus {
    Completed = "completed",
    Incomplete = "incomplete",
    InProgress = "in_progress"
}

// @public
export enum KnownResponseStatus {
    Cancelled = "cancelled",
    Completed = "completed",
    Failed = "failed",
    Incomplete = "incomplete",
    InProgress = "in_progress"
}

// @public
export enum KnownServerEventType {
    ConversationItemCreated = "conversation.item.created",
    ConversationItemDeleted = "conversation.item.deleted",
    ConversationItemInputAudioTranscriptionCompleted = "conversation.item.input_audio_transcription.completed",
    ConversationItemInputAudioTranscriptionDelta = "conversation.item.input_audio_transcription.delta",
    ConversationItemInputAudioTranscriptionFailed = "conversation.item.input_audio_transcription.failed",
    ConversationItemRetrieved = "conversation.item.retrieved",
    ConversationItemTruncated = "conversation.item.truncated",
    Error = "error",
    InputAudioBufferCleared = "input_audio_buffer.cleared",
    InputAudioBufferCommitted = "input_audio_buffer.committed",
    InputAudioBufferSpeechStarted = "input_audio_buffer.speech_started",
    InputAudioBufferSpeechStopped = "input_audio_buffer.speech_stopped",
    ResponseAnimationBlendshapesDelta = "response.animation_blendshapes.delta",
    ResponseAnimationBlendshapesDone = "response.animation_blendshapes.done",
    ResponseAnimationVisemeDelta = "response.animation_viseme.delta",
    ResponseAnimationVisemeDone = "response.animation_viseme.done",
    ResponseAudioDelta = "response.audio.delta",
    ResponseAudioDone = "response.audio.done",
    ResponseAudioTimestampDelta = "response.audio_timestamp.delta",
    ResponseAudioTimestampDone = "response.audio_timestamp.done",
    ResponseAudioTranscriptDelta = "response.audio_transcript.delta",
    ResponseAudioTranscriptDone = "response.audio_transcript.done",
    ResponseContentPartAdded = "response.content_part.added",
    ResponseContentPartDone = "response.content_part.done",
    ResponseCreated = "response.created",
    ResponseDone = "response.done",
    ResponseFunctionCallArgumentsDelta = "response.function_call_arguments.delta",
    ResponseFunctionCallArgumentsDone = "response.function_call_arguments.done",
    ResponseOutputItemAdded = "response.output_item.added",
    ResponseOutputItemDone = "response.output_item.done",
    ResponseTextDelta = "response.text.delta",
    ResponseTextDone = "response.text.done",
    SessionAvatarConnecting = "session.avatar.connecting",
    SessionCreated = "session.created",
    SessionUpdated = "session.updated"
}

// @public
export enum KnownToolChoiceLiteral {
    Auto = "auto",
    None = "none",
    Required = "required"
}

// @public
export enum KnownToolType {
    Function = "function"
}

// @public
export enum KnownTurnDetectionType {
    AzureSemanticVad = "azure_semantic_vad",
    AzureSemanticVadEn = "azure_semantic_vad_en",
    AzureSemanticVadMultilingual = "azure_semantic_vad_multilingual",
    ServerVad = "server_vad"
}

// @public
export interface LogProbProperties {
    bytes: number[];
    logprob: number;
    token: string;
}

// @public
export interface MessageContentPart {
    type: ContentPartType;
}

// @public
export type MessageContentPartUnion = InputTextContentPart | InputAudioContentPart | OutputTextContentPart | MessageContentPart;

// @public
export interface MessageItem extends ConversationRequestItem {
    content: MessageContentPartUnion[];
    role: MessageRole;
    status?: ItemParamStatus;
    type: "message";
}

// @public
export type MessageItemUnion = SystemMessageItem | UserMessageItem | AssistantMessageItem | MessageItem;

// @public
export type MessageRole = string;

// @public
export type Modality = string;

// @public
export type OAIVoice = string;

// @public
export interface OpenAIVoice {
    name: OAIVoice;
    type: "openai";
}

// @public
export type OutputAudioFormat = string;

// @public
export interface OutputTextContentPart extends MessageContentPart {
    text: string;
    type: "text";
}

// @public
export interface OutputTokenDetails {
    audioTokens: number;
    textTokens: number;
}

// @public (undocumented)
export interface PagedResult<T> {
    // (undocumented)
    hasMore: boolean;
    // (undocumented)
    items: T[];
    // (undocumented)
    nextPageId?: string;
}

// @public
export type PersonalVoiceModels = string;

// @public (undocumented)
export interface RawMessageEventArgs {
    // (undocumented)
    data: string | ArrayBuffer;
    // (undocumented)
    timestamp: Date;
}

// @public (undocumented)
export interface RawSentEventArgs {
    // (undocumented)
    data: string | ArrayBuffer;
    // (undocumented)
    timestamp: Date;
}

// @public (undocumented)
export interface ReconnectedEventArgs {
    // (undocumented)
    attempt: number;
    // (undocumented)
    connectionId: string;
    // (undocumented)
    timestamp: Date;
}

// @public (undocumented)
export interface ReconnectingEventArgs {
    // (undocumented)
    attempt: number;
    // (undocumented)
    delayMs: number;
    // (undocumented)
    maxAttempts: number;
    // (undocumented)
    timestamp: Date;
}

// @public
export interface RequestAudioContentPart extends ContentPart {
    // (undocumented)
    transcript?: string;
    // (undocumented)
    type: "input_audio";
}

// @public
export interface RequestSession {
    animation?: Animation;
    avatar?: AvatarConfig;
    inputAudioEchoCancellation?: AudioEchoCancellation;
    inputAudioFormat?: InputAudioFormat;
    inputAudioNoiseReduction?: AudioNoiseReduction;
    inputAudioSamplingRate?: number;
    inputAudioTranscription?: AudioInputTranscriptionOptions;
    instructions?: string;
    maxResponseOutputTokens?: number | "inf";
    modalities?: Modality[];
    model?: string;
    outputAudioFormat?: OutputAudioFormat;
    outputAudioTimestampTypes?: AudioTimestampType[];
    temperature?: number;
    toolChoice?: ToolChoice;
    tools?: ToolUnion[];
    turnDetection?: TurnDetectionUnion;
    voice?: Voice;
}

// @public
export interface RequestTextContentPart extends ContentPart {
    // (undocumented)
    text?: string;
    // (undocumented)
    type: "input_text";
}

// @public
interface Response_2 {
    conversationId?: string;
    id?: string;
    maxOutputTokens?: number | "inf";
    modalities?: Modality[];
    object?: "realtime.response";
    output?: ResponseItemUnion[];
    outputAudioFormat?: OutputAudioFormat;
    status?: ResponseStatus;
    statusDetails?: ResponseStatusDetailsUnion;
    temperature?: number;
    usage?: TokenUsage;
    voice?: Voice;
}
export { Response_2 as Response }

// @public
export interface ResponseAudioContentPart extends ContentPart {
    // (undocumented)
    transcript?: string;
    // (undocumented)
    type: "audio";
}

// @public
export interface ResponseCancelledDetails extends ResponseStatusDetails {
    // (undocumented)
    reason: string;
    // (undocumented)
    type: "cancelled";
}

// @public
export interface ResponseCreateParams {
    appendInputItems?: ConversationRequestItemUnion[];
    cancelPrevious?: boolean;
    commit?: boolean;
    inputItems?: ConversationRequestItemUnion[];
    instructions?: string;
    maxOutputTokens?: number | "inf";
    modalities?: Modality[];
    outputAudioFormat?: OutputAudioFormat;
    temperature?: number;
    toolChoice?: string;
    tools?: ToolUnion[];
    voice?: Voice;
}

// @public
export interface ResponseFailedDetails extends ResponseStatusDetails {
    // (undocumented)
    error: any;
    // (undocumented)
    type: "failed";
}

// @public
export interface ResponseFunctionCallItem extends ResponseItem {
    // (undocumented)
    arguments: string;
    // (undocumented)
    callId: string;
    // (undocumented)
    name: string;
    // (undocumented)
    status: ResponseItemStatus;
    // (undocumented)
    type: "function_call";
}

// @public
export interface ResponseFunctionCallOutputItem extends ResponseItem {
    // (undocumented)
    callId: string;
    // (undocumented)
    output: string;
    // (undocumented)
    type: "function_call_output";
}

// @public
export interface ResponseIncompleteDetails extends ResponseStatusDetails {
    // (undocumented)
    reason: string;
    // (undocumented)
    type: "incomplete";
}

// @public
export interface ResponseItem {
    // (undocumented)
    id?: string;
    // (undocumented)
    object?: "realtime.item";
    // (undocumented)
    type: ItemType;
}

// @public
export type ResponseItemStatus = string;

// @public
export type ResponseItemUnion = ResponseMessageItem | ResponseFunctionCallItem | ResponseFunctionCallOutputItem | ResponseItem;

// @public
export interface ResponseMessageItem extends ResponseItem {
    // (undocumented)
    content: ContentPartUnion[];
    // (undocumented)
    role: MessageRole;
    // (undocumented)
    status: ResponseItemStatus;
    // (undocumented)
    type: "message";
}

// @public
export interface ResponseSession {
    agent?: AgentConfig;
    animation?: Animation;
    avatar?: AvatarConfig;
    id?: string;
    inputAudioEchoCancellation?: AudioEchoCancellation;
    inputAudioFormat?: InputAudioFormat;
    inputAudioNoiseReduction?: AudioNoiseReduction;
    inputAudioSamplingRate?: number;
    inputAudioTranscription?: AudioInputTranscriptionOptions;
    instructions?: string;
    maxResponseOutputTokens?: number | "inf";
    modalities?: Modality[];
    model?: string;
    outputAudioFormat?: OutputAudioFormat;
    outputAudioTimestampTypes?: AudioTimestampType[];
    temperature?: number;
    toolChoice?: ToolChoice;
    tools?: ToolUnion[];
    turnDetection?: TurnDetectionUnion;
    voice?: Voice;
}

// @public
export type ResponseStatus = string;

// @public
export interface ResponseStatusDetails {
    // (undocumented)
    type: ResponseStatus;
}

// @public
export type ResponseStatusDetailsUnion = ResponseCancelledDetails | ResponseIncompleteDetails | ResponseFailedDetails | ResponseStatusDetails;

// @public
export class ResponseStreamer {
    constructor(_eventEmitter: EnhancedVoiceLiveEventEmitter);
    createAnimationStream(responseId?: string): AsyncIterableIterator<AnimationStreamChunk>;
    createAudioStream(responseId?: string): AsyncIterableIterator<AudioStreamChunk>;
    createResponseStream(options?: StreamingOptions): AsyncIterableIterator<StreamChunk>;
    createTextStream(responseId?: string): AsyncIterableIterator<TextStreamChunk>;
}

// @public
export interface ResponseTextContentPart extends ContentPart {
    // (undocumented)
    text?: string;
    // (undocumented)
    type: "text";
}

// @public (undocumented)
export interface SendEventOptions {
    abortSignal?: AbortSignalLike;
    timeoutMs?: number;
}

// @public
export interface ServerEvent {
    // (undocumented)
    eventId?: string;
    type: ServerEventType;
}

// @public
export interface ServerEventConversationItemCreated extends ServerEvent {
    // (undocumented)
    item?: ResponseItemUnion;
    previousItemId?: string;
    type: "conversation.item.created";
}

// @public
export interface ServerEventConversationItemDeleted extends ServerEvent {
    // (undocumented)
    eventId?: string;
    itemId: string;
    type: "conversation.item.deleted";
}

// @public
export interface ServerEventConversationItemInputAudioTranscriptionCompleted extends ServerEvent {
    contentIndex: number;
    itemId: string;
    transcript: string;
    type: "conversation.item.input_audio_transcription.completed";
}

// @public
export interface ServerEventConversationItemInputAudioTranscriptionDelta extends ServerEvent {
    contentIndex?: number;
    delta?: string;
    itemId: string;
    logprobs?: LogProbProperties[];
    type: "conversation.item.input_audio_transcription.delta";
}

// @public
export interface ServerEventConversationItemInputAudioTranscriptionFailed extends ServerEvent {
    contentIndex: number;
    error: VoiceLiveErrorDetails;
    itemId: string;
    type: "conversation.item.input_audio_transcription.failed";
}

// @public
export interface ServerEventConversationItemRetrieved extends ServerEvent {
    // (undocumented)
    eventId?: string;
    // (undocumented)
    item?: ResponseItemUnion;
    type: "conversation.item.retrieved";
}

// @public
export interface ServerEventConversationItemTruncated extends ServerEvent {
    audioEndMs: number;
    contentIndex: number;
    // (undocumented)
    eventId?: string;
    itemId: string;
    type: "conversation.item.truncated";
}

// @public
export interface ServerEventError extends ServerEvent {
    error: ServerEventErrorDetails;
    type: "error";
}

// @public
export interface ServerEventErrorDetails {
    code?: string;
    eventId?: string;
    message: string;
    param?: string;
    type: string;
}

// @public
export interface ServerEventInputAudioBufferCleared extends ServerEvent {
    type: "input_audio_buffer.cleared";
}

// @public
export interface ServerEventInputAudioBufferCommitted extends ServerEvent {
    itemId: string;
    previousItemId?: string;
    type: "input_audio_buffer.committed";
}

// @public
export interface ServerEventInputAudioBufferSpeechStarted extends ServerEvent {
    audioStartMs: number;
    itemId: string;
    type: "input_audio_buffer.speech_started";
}

// @public
export interface ServerEventInputAudioBufferSpeechStopped extends ServerEvent {
    audioEndMs: number;
    itemId: string;
    type: "input_audio_buffer.speech_stopped";
}

// @public
export interface ServerEventResponseAnimationBlendshapeDelta extends ServerEvent {
    // (undocumented)
    contentIndex: number;
    // (undocumented)
    frameIndex: number;
    // (undocumented)
    frames: number[][] | string;
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    type: "response.animation_blendshapes.delta";
}

// @public
export interface ServerEventResponseAnimationBlendshapeDone extends ServerEvent {
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    type: "response.animation_blendshapes.done";
}

// @public
export interface ServerEventResponseAnimationVisemeDelta extends ServerEvent {
    // (undocumented)
    audioOffsetMs: number;
    // (undocumented)
    contentIndex: number;
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    type: "response.animation_viseme.delta";
    // (undocumented)
    visemeId: number;
}

// @public
export interface ServerEventResponseAnimationVisemeDone extends ServerEvent {
    // (undocumented)
    contentIndex: number;
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    type: "response.animation_viseme.done";
}

// @public
export interface ServerEventResponseAudioDelta extends ServerEvent {
    contentIndex: number;
    delta: Uint8Array;
    itemId: string;
    outputIndex: number;
    responseId: string;
    type: "response.audio.delta";
}

// @public
export interface ServerEventResponseAudioDone extends ServerEvent {
    contentIndex: number;
    itemId: string;
    outputIndex: number;
    responseId: string;
    type: "response.audio.done";
}

// @public
export interface ServerEventResponseAudioTimestampDelta extends ServerEvent {
    // (undocumented)
    audioDurationMs: number;
    // (undocumented)
    audioOffsetMs: number;
    // (undocumented)
    contentIndex: number;
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    text: string;
    // (undocumented)
    timestampType: "word";
    // (undocumented)
    type: "response.audio_timestamp.delta";
}

// @public
export interface ServerEventResponseAudioTimestampDone extends ServerEvent {
    // (undocumented)
    contentIndex: number;
    // (undocumented)
    itemId: string;
    // (undocumented)
    outputIndex: number;
    // (undocumented)
    responseId: string;
    // (undocumented)
    type: "response.audio_timestamp.done";
}

// @public
export interface ServerEventResponseAudioTranscriptDelta extends ServerEvent {
    contentIndex: number;
    delta: string;
    itemId: string;
    outputIndex: number;
    responseId: string;
    type: "response.audio_transcript.delta";
}

// @public
export interface ServerEventResponseAudioTranscriptDone extends ServerEvent {
    contentIndex: number;
    itemId: string;
    outputIndex: number;
    responseId: string;
    transcript: string;
    type: "response.audio_transcript.done";
}

// @public
export interface ServerEventResponseContentPartAdded extends ServerEvent {
    contentIndex: number;
    itemId: string;
    outputIndex: number;
    part: ContentPartUnion;
    responseId: string;
    type: "response.content_part.added";
}

// @public
export interface ServerEventResponseContentPartDone extends ServerEvent {
    contentIndex: number;
    itemId: string;
    outputIndex: number;
    part: ContentPartUnion;
    responseId: string;
    type: "response.content_part.done";
}

// @public
export interface ServerEventResponseCreated extends ServerEvent {
    // (undocumented)
    response: Response_2;
    type: "response.created";
}

// @public
export interface ServerEventResponseDone extends ServerEvent {
    // (undocumented)
    response: Response_2;
    type: "response.done";
}

// @public
export interface ServerEventResponseFunctionCallArgumentsDelta extends ServerEvent {
    callId: string;
    delta: string;
    itemId: string;
    outputIndex: number;
    responseId: string;
    type: "response.function_call_arguments.delta";
}

// @public
export interface ServerEventResponseFunctionCallArgumentsDone extends ServerEvent {
    arguments: string;
    callId: string;
    itemId: string;
    name: string;
    outputIndex: number;
    responseId: string;
    type: "response.function_call_arguments.done";
}

// @public
export interface ServerEventResponseOutputItemAdded extends ServerEvent {
    // (undocumented)
    item?: ResponseItemUnion;
    outputIndex: number;
    responseId: string;
    type: "response.output_item.added";
}

// @public
export interface ServerEventResponseOutputItemDone extends ServerEvent {
    // (undocumented)
    item?: ResponseItemUnion;
    outputIndex: number;
    responseId: string;
    type: "response.output_item.done";
}

// @public
export interface ServerEventResponseTextDelta extends ServerEvent {
    contentIndex: number;
    delta: string;
    itemId: string;
    outputIndex: number;
    responseId: string;
    type: "response.text.delta";
}

// @public
export interface ServerEventResponseTextDone extends ServerEvent {
    contentIndex: number;
    itemId: string;
    outputIndex: number;
    responseId: string;
    text: string;
    type: "response.text.done";
}

// @public
export interface ServerEventSessionAvatarConnecting extends ServerEvent {
    serverSdp: string;
    type: "session.avatar.connecting";
}

// @public
export interface ServerEventSessionCreated extends ServerEvent {
    // (undocumented)
    session: ResponseSession;
    type: "session.created";
}

// @public
export interface ServerEventSessionUpdated extends ServerEvent {
    // (undocumented)
    session: ResponseSession;
    type: "session.updated";
}

// @public
export type ServerEventType = string;

// @public
export type ServerEventUnion = ServerEventError | ServerEventSessionCreated | ServerEventSessionUpdated | ServerEventSessionAvatarConnecting | ServerEventInputAudioBufferCommitted | ServerEventInputAudioBufferCleared | ServerEventInputAudioBufferSpeechStarted | ServerEventInputAudioBufferSpeechStopped | ServerEventConversationItemCreated | ServerEventConversationItemInputAudioTranscriptionCompleted | ServerEventConversationItemInputAudioTranscriptionFailed | ServerEventConversationItemTruncated | ServerEventConversationItemDeleted | ServerEventResponseCreated | ServerEventResponseDone | ServerEventResponseOutputItemAdded | ServerEventResponseOutputItemDone | ServerEventResponseContentPartAdded | ServerEventResponseContentPartDone | ServerEventResponseTextDelta | ServerEventResponseTextDone | ServerEventResponseAudioTranscriptDelta | ServerEventResponseAudioTranscriptDone | ServerEventResponseAudioDelta | ServerEventResponseAudioDone | ServerEventResponseAnimationBlendshapeDelta | ServerEventResponseAnimationBlendshapeDone | ServerEventResponseAudioTimestampDelta | ServerEventResponseAudioTimestampDone | ServerEventResponseAnimationVisemeDelta | ServerEventResponseAnimationVisemeDone | ServerEventConversationItemInputAudioTranscriptionDelta | ServerEventConversationItemRetrieved | ServerEventResponseFunctionCallArgumentsDelta | ServerEventResponseFunctionCallArgumentsDone | ServerEvent;

// @public
export interface ServerVad extends TurnDetection {
    // (undocumented)
    autoTruncate?: boolean;
    // (undocumented)
    createResponse?: boolean;
    // (undocumented)
    endOfUtteranceDetection?: EouDetectionUnion;
    // (undocumented)
    interruptResponse?: boolean;
    // (undocumented)
    prefixPaddingMs?: number;
    // (undocumented)
    silenceDurationMs?: number;
    // (undocumented)
    threshold?: number;
    // (undocumented)
    type: "server_vad";
}

// @public
export interface SessionBase {
}

// @public (undocumented)
export type StreamChunk = TextStreamChunk | AudioStreamChunk | AnimationStreamChunk;

// @public (undocumented)
export interface StreamingOptions {
    abortSignal?: AbortSignal;
    audioBufferSize?: number;
    includeAnimation?: boolean;
    includeAudio?: boolean;
    includeText?: boolean;
    targetLatencyMs?: number;
}

// @public (undocumented)
export interface StreamingTextOptions {
    bufferChunks?: boolean;
    chunkTimeoutMs?: number;
    responseId?: string;
}

// @public
export interface SystemMessageItem extends MessageItem {
    // (undocumented)
    role: "system";
}

// @public (undocumented)
export interface TextStreamChunk {
    // (undocumented)
    delta: string;
    // (undocumented)
    itemId?: string;
    // (undocumented)
    responseId: string;
    // (undocumented)
    timestamp: number;
    // (undocumented)
    type: 'text';
}

// @public
export interface TokenUsage {
    inputTokenDetails: InputTokenDetails;
    inputTokens: number;
    outputTokenDetails: OutputTokenDetails;
    outputTokens: number;
    totalTokens: number;
}

// @public
export interface Tool {
    // (undocumented)
    type: ToolType;
}

// @public
export type ToolChoice = ToolChoiceLiteral | ToolChoiceObjectUnion;

// @public
export interface ToolChoiceFunctionObject extends ToolChoiceObject {
    // (undocumented)
    name: string;
    // (undocumented)
    type: "function";
}

// @public
export type ToolChoiceLiteral = string;

// @public
export interface ToolChoiceObject {
    // (undocumented)
    type: ToolType;
}

// @public
export type ToolChoiceObjectUnion = ToolChoiceFunctionObject | ToolChoiceObject;

// @public
export type ToolType = string;

// @public
export type ToolUnion = FunctionTool | Tool;

// @public
export interface TurnDetection {
    // (undocumented)
    type: TurnDetectionType;
}

// @public
export type TurnDetectionType = string;

// @public
export type TurnDetectionUnion = ServerVad | AzureSemanticVad | AzureSemanticVadEn | AzureSemanticVadMultilingual | TurnDetection;

// @public (undocumented)
export interface TurnOptions extends SendEventOptions {
    turnId?: string;
}

// @public
export interface UserMessageItem extends MessageItem {
    // (undocumented)
    role: "user";
}

// @public
export interface VideoCrop {
    bottomRight: number[];
    topLeft: number[];
}

// @public (undocumented)
export interface VideoFrame {
    // (undocumented)
    data: ArrayBuffer;
    // (undocumented)
    format: 'rgba' | 'rgb' | 'yuv420p';
    // (undocumented)
    height: number;
    // (undocumented)
    timestamp: number;
    // (undocumented)
    width: number;
}

// @public
export interface VideoParams {
    background?: Background;
    bitrate?: number;
    codec?: "h264";
    crop?: VideoCrop;
    gopSize?: number;
    resolution?: VideoResolution;
}

// @public
export class VideoProcessor {
    base64ToFrame(base64: string, width: number, height: number, format: VideoFrame['format']): VideoFrame;
    frameToBase64(frame: VideoFrame): string;
    interpolateAvatarFrames(frameA: AvatarFrame, frameB: AvatarFrame, factor: number): AvatarFrame;
    processAvatarFrame(blendshapes: any, visemes: any, timestamp: number): AvatarFrame;
    validateAvatarFrame(frame: AvatarFrame): {
        isValid: boolean;
        errors: string[];
    };
}

// @public
export interface VideoResolution {
    height: number;
    width: number;
}

// @public (undocumented)
export interface VisemeConfig {
    defaultWeights: Record<string, number>;
    supportedVisemes: string[];
}

// @public (undocumented)
export interface VisemeFrame {
    // (undocumented)
    data: Array<{
        id: string;
        weight: number;
    }>;
    // (undocumented)
    timestamp: number;
}

// @public
export type Voice = OAIVoice | OpenAIVoice | AzureVoiceUnion;

// @public
export class VoiceLiveAsyncIterators {
    constructor(_eventEmitter: EnhancedVoiceLiveEventEmitter);
    listConversationHistory(options?: ConversationHistoryOptions): AsyncIterableWithPages<any>;
    streamAnimation(responseId?: string): AsyncIterableIterator<{
        frames?: number[][] | string;
        frameIndex?: number;
        timestamp: number;
    }>;
    streamAudio(responseId?: string): AsyncIterableIterator<ArrayBuffer>;
    streamResponse(responseId: string): AsyncIterableIterator<{
        type: 'text' | 'audio' | 'animation';
        data: any;
        timestamp: number;
    }>;
    streamText(options?: StreamingTextOptions): AsyncIterableIterator<string>;
}

// @public
export class VoiceLiveAuthenticationError extends VoiceLiveConnectionError {
    constructor(message: string, code: string, cause?: Error);
}

// @public
export class VoiceLiveClient {
    constructor(endpoint: string, credential: TokenCredential, options?: VoiceLiveClientOptions);
    // (undocumented)
    get activeTurnId(): string | undefined;
    addConversationItem(item: ConversationRequestItem, options?: SendEventOptions): Promise<void>;
    get asyncIterators(): VoiceLiveAsyncIterators;
    get audioProcessor(): AudioProcessor;
    get avatarManager(): AvatarManager;
    connect(options?: ConnectOptions): Promise<void>;
    // (undocumented)
    get connectionState(): ConnectionState;
    disconnect(): Promise<void>;
    endAudioTurn(turnId?: string, options?: SendEventOptions): Promise<void>;
    get events(): EnhancedVoiceLiveEventEmitter;
    // (undocumented)
    get isConnected(): boolean;
    sendAudio(audioData: ArrayBuffer | Uint8Array, options?: AudioStreamOptions): Promise<void>;
    sendEvent(event: ClientEventUnion, options?: SendEventOptions): Promise<void>;
    // (undocumented)
    get sessionId(): string | undefined;
    startAudioTurn(options?: TurnOptions): Promise<string>;
    get streaming(): ResponseStreamer;
    updateSession(session: RequestSession, options?: SendEventOptions): Promise<void>;
    get videoProcessor(): VideoProcessor;
    waitForEvent<K extends keyof VoiceLiveEventMap>(event: K, filter?: (eventData: VoiceLiveEventMap[K]) => boolean, timeoutMs?: number): Promise<VoiceLiveEventMap[K]>;
}

// @public (undocumented)
export interface VoiceLiveClientOptions {
    apiVersion?: string;
    autoReconnect?: boolean;
    connectionTimeoutMs?: number;
    enableDebugLogging?: boolean;
    maxReconnectAttempts?: number;
    reconnectDelayMs?: number;
}

// @public
export class VoiceLiveConnectionError extends Error {
    constructor(message: string, code: string, context?: string, recoverable?: boolean, cause?: Error);
    readonly cause?: Error;
    readonly code: string;
    readonly context: string;
    readonly recoverable: boolean;
    readonly timestamp: Date;
    toJSON(): Record<string, any>;
}

// @public
export class VoiceLiveError extends VoiceLiveConnectionError {
    constructor(message: string, code: string, context?: string, recoverable?: boolean, cause?: Error);
}

// @public
export class VoiceLiveErrorClassifier {
    static classifyConnectionError(error: any): VoiceLiveConnectionError;
    static classifyProtocolError(error: Error, messageType: string, _messageData?: any): VoiceLiveProtocolError;
    static classifyWebSocketClose(code: number, reason: string): VoiceLiveConnectionError;
}

// @public
export enum VoiceLiveErrorCodes {
    // (undocumented)
    ALREADY_CONNECTED = "ALREADY_CONNECTED",
    // (undocumented)
    AUTHENTICATION_FAILED = "AUTHENTICATION_FAILED",
    // (undocumented)
    BUFFER_OVERFLOW = "BUFFER_OVERFLOW",
    // (undocumented)
    CONNECTION_FAILED = "CONNECTION_FAILED",
    // (undocumented)
    CONNECTION_LOST = "CONNECTION_LOST",
    // (undocumented)
    CONNECTION_TIMEOUT = "CONNECTION_TIMEOUT",
    // (undocumented)
    FORBIDDEN = "FORBIDDEN",
    // (undocumented)
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS",
    // (undocumented)
    INVALID_MESSAGE = "INVALID_MESSAGE",
    // (undocumented)
    INVALID_STATE = "INVALID_STATE",
    // (undocumented)
    MESSAGE_TOO_LARGE = "MESSAGE_TOO_LARGE",
    // (undocumented)
    NOT_CONNECTED = "NOT_CONNECTED",
    // (undocumented)
    OPERATION_CANCELLED = "OPERATION_CANCELLED",
    // (undocumented)
    PROTOCOL_ERROR = "PROTOCOL_ERROR",
    // (undocumented)
    UNAUTHORIZED = "UNAUTHORIZED",
    // (undocumented)
    WEBSOCKET_ERROR = "WEBSOCKET_ERROR"
}

// @public
export interface VoiceLiveErrorDetails {
    code?: string;
    eventId?: string;
    message: string;
    param?: string;
    type?: string;
}

// @public
export class VoiceLiveEventEmitter {
    emit<K extends keyof VoiceLiveEventMap>(event: K, args: VoiceLiveEventMap[K]): void;
    emitConnected(connectionId: string, sessionId?: string): void;
    // (undocumented)
    emitDisconnected(code: number, reason: string, wasClean: boolean): void;
    // (undocumented)
    emitError(error: Error, context: string, recoverable: boolean): void;
    // (undocumented)
    emitRawMessage(data: string | ArrayBuffer): void;
    // (undocumented)
    emitRawSent(data: string | ArrayBuffer): void;
    // (undocumented)
    emitReconnected(connectionId: string, attempt: number): void;
    // (undocumented)
    emitReconnecting(attempt: number, maxAttempts: number, delayMs: number): void;
    emitServerEvent(event: ServerEventUnion): void;
    eventNames(): Array<keyof VoiceLiveEventMap>;
    listenerCount(event: keyof VoiceLiveEventMap): number;
    off<K extends keyof VoiceLiveEventMap>(event: K, listener: EventListener<VoiceLiveEventMap[K]>): void;
    on<K extends keyof VoiceLiveEventMap>(event: K, listener: EventListener<VoiceLiveEventMap[K]>): void;
    once<K extends keyof VoiceLiveEventMap>(event: K, listener: EventListener<VoiceLiveEventMap[K]>): void;
    removeAllListeners(event?: keyof VoiceLiveEventMap): void;
}

// @public
export interface VoiceLiveEventMap {
    // (undocumented)
    'raw.message': RawMessageEventArgs;
    // (undocumented)
    'raw.sent': RawSentEventArgs;
    // (undocumented)
    'server.conversation.item.created': ServerEventConversationItemCreated;
    // (undocumented)
    'server.conversation.item.deleted': ServerEventConversationItemDeleted;
    // (undocumented)
    'server.conversation.item.input_audio_transcription.completed': ServerEventConversationItemInputAudioTranscriptionCompleted;
    // (undocumented)
    'server.conversation.item.input_audio_transcription.delta': ServerEventConversationItemInputAudioTranscriptionDelta;
    // (undocumented)
    'server.conversation.item.input_audio_transcription.failed': ServerEventConversationItemInputAudioTranscriptionFailed;
    // (undocumented)
    'server.conversation.item.retrieved': ServerEventConversationItemRetrieved;
    // (undocumented)
    'server.conversation.item.truncated': ServerEventConversationItemTruncated;
    // (undocumented)
    'server.error': ServerEventError;
    // (undocumented)
    'server.input_audio_buffer.cleared': ServerEventInputAudioBufferCleared;
    // (undocumented)
    'server.input_audio_buffer.committed': ServerEventInputAudioBufferCommitted;
    // (undocumented)
    'server.input_audio_buffer.speech_started': ServerEventInputAudioBufferSpeechStarted;
    // (undocumented)
    'server.input_audio_buffer.speech_stopped': ServerEventInputAudioBufferSpeechStopped;
    // (undocumented)
    'server.response.animation.blendshape.delta': ServerEventResponseAnimationBlendshapeDelta;
    // (undocumented)
    'server.response.animation.blendshape.done': ServerEventResponseAnimationBlendshapeDone;
    // (undocumented)
    'server.response.animation.viseme.delta': ServerEventResponseAnimationVisemeDelta;
    // (undocumented)
    'server.response.animation.viseme.done': ServerEventResponseAnimationVisemeDone;
    // (undocumented)
    'server.response.audio.delta': ServerEventResponseAudioDelta;
    // (undocumented)
    'server.response.audio.done': ServerEventResponseAudioDone;
    // (undocumented)
    'server.response.audio.timestamp.delta': ServerEventResponseAudioTimestampDelta;
    // (undocumented)
    'server.response.audio.timestamp.done': ServerEventResponseAudioTimestampDone;
    // (undocumented)
    'server.response.audio_transcript.delta': ServerEventResponseAudioTranscriptDelta;
    // (undocumented)
    'server.response.audio_transcript.done': ServerEventResponseAudioTranscriptDone;
    // (undocumented)
    'server.response.content_part.added': ServerEventResponseContentPartAdded;
    // (undocumented)
    'server.response.content_part.done': ServerEventResponseContentPartDone;
    // (undocumented)
    'server.response.created': ServerEventResponseCreated;
    // (undocumented)
    'server.response.done': ServerEventResponseDone;
    // (undocumented)
    'server.response.function_call_arguments.delta': ServerEventResponseFunctionCallArgumentsDelta;
    // (undocumented)
    'server.response.function_call_arguments.done': ServerEventResponseFunctionCallArgumentsDone;
    // (undocumented)
    'server.response.output_item.added': ServerEventResponseOutputItemAdded;
    // (undocumented)
    'server.response.output_item.done': ServerEventResponseOutputItemDone;
    // (undocumented)
    'server.response.text.delta': ServerEventResponseTextDelta;
    // (undocumented)
    'server.response.text.done': ServerEventResponseTextDone;
    // (undocumented)
    'server.session.avatar.connecting': ServerEventSessionAvatarConnecting;
    // (undocumented)
    'server.session.created': ServerEventSessionCreated;
    // (undocumented)
    'server.session.updated': ServerEventSessionUpdated;
    // (undocumented)
    'connected': ConnectedEventArgs;
    // (undocumented)
    'disconnected': DisconnectedEventArgs;
    // (undocumented)
    'error': ErrorEventArgs;
    // (undocumented)
    'reconnected': ReconnectedEventArgs;
    // (undocumented)
    'reconnecting': ReconnectingEventArgs;
}

// @public
export class VoiceLiveProtocolError extends VoiceLiveConnectionError {
    constructor(message: string, code: string, cause?: Error);
}

// (No @packageDocumentation comment for this package)

```
