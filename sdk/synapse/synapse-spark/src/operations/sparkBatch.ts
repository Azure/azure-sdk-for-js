/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { createSpan } from "../tracing";
import { SparkBatch } from "../operationsInterfaces";
import * as coreClient from "@azure/core-client";
import * as coreTracing from "@azure/core-tracing";
import * as Mappers from "../models/mappers";
import * as Parameters from "../models/parameters";
import { SparkClientContext } from "../sparkClientContext";
import {
  SparkBatchGetSparkBatchJobsOptionalParams,
  SparkBatchGetSparkBatchJobsResponse,
  SparkBatchJobOptions,
  SparkBatchCreateSparkBatchJobOptionalParams,
  SparkBatchCreateSparkBatchJobResponse,
  SparkBatchGetSparkBatchJobOptionalParams,
  SparkBatchGetSparkBatchJobResponse,
  SparkBatchCancelSparkBatchJobOptionalParams
} from "../models";

/** Class containing SparkBatch operations. */
export class SparkBatchImpl implements SparkBatch {
  private readonly client: SparkClientContext;

  /**
   * Initialize a new instance of the class SparkBatch class.
   * @param client Reference to the service client
   */
  constructor(client: SparkClientContext) {
    this.client = client;
  }

  /**
   * List all spark batch jobs which are running under a particular spark pool.
   * @param options The options parameters.
   */
  async getSparkBatchJobs(
    options?: SparkBatchGetSparkBatchJobsOptionalParams
  ): Promise<SparkBatchGetSparkBatchJobsResponse> {
    const { span } = createSpan("SparkClient-getSparkBatchJobs", options || {});
    try {
      const result = await this.client.sendOperationRequest(
        { options },
        getSparkBatchJobsOperationSpec
      );
      return result as SparkBatchGetSparkBatchJobsResponse;
    } catch (error: any) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }

  /**
   * Create new spark batch job.
   * @param sparkBatchJobOptions Livy compatible batch job request payload.
   * @param options The options parameters.
   */
  async createSparkBatchJob(
    sparkBatchJobOptions: SparkBatchJobOptions,
    options?: SparkBatchCreateSparkBatchJobOptionalParams
  ): Promise<SparkBatchCreateSparkBatchJobResponse> {
    const { span } = createSpan(
      "SparkClient-createSparkBatchJob",
      options || {}
    );
    try {
      const result = await this.client.sendOperationRequest(
        { sparkBatchJobOptions, options },
        createSparkBatchJobOperationSpec
      );
      return result as SparkBatchCreateSparkBatchJobResponse;
    } catch (error: any) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }

  /**
   * Gets a single spark batch job.
   * @param batchId Identifier for the batch job.
   * @param options The options parameters.
   */
  async getSparkBatchJob(
    batchId: number,
    options?: SparkBatchGetSparkBatchJobOptionalParams
  ): Promise<SparkBatchGetSparkBatchJobResponse> {
    const { span } = createSpan("SparkClient-getSparkBatchJob", options || {});
    try {
      const result = await this.client.sendOperationRequest(
        { batchId, options },
        getSparkBatchJobOperationSpec
      );
      return result as SparkBatchGetSparkBatchJobResponse;
    } catch (error: any) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }

  /**
   * Cancels a running spark batch job.
   * @param batchId Identifier for the batch job.
   * @param options The options parameters.
   */
  async cancelSparkBatchJob(
    batchId: number,
    options?: SparkBatchCancelSparkBatchJobOptionalParams
  ): Promise<void> {
    const { span } = createSpan(
      "SparkClient-cancelSparkBatchJob",
      options || {}
    );
    try {
      const result = await this.client.sendOperationRequest(
        { batchId, options },
        cancelSparkBatchJobOperationSpec
      );
      return result as void;
    } catch (error: any) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }
}
// Operation Specifications
const serializer = coreClient.createSerializer(Mappers, /* isXml */ false);

const getSparkBatchJobsOperationSpec: coreClient.OperationSpec = {
  path: "/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.SparkBatchJobCollection
    }
  },
  queryParameters: [Parameters.fromParam, Parameters.size, Parameters.detailed],
  urlParameters: [
    Parameters.endpoint,
    Parameters.livyApiVersion,
    Parameters.sparkPoolName
  ],
  headerParameters: [Parameters.accept],
  serializer
};
const createSparkBatchJobOperationSpec: coreClient.OperationSpec = {
  path: "/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches",
  httpMethod: "POST",
  responses: {
    200: {
      bodyMapper: Mappers.SparkBatchJob
    }
  },
  requestBody: Parameters.sparkBatchJobOptions,
  queryParameters: [Parameters.detailed],
  urlParameters: [
    Parameters.endpoint,
    Parameters.livyApiVersion,
    Parameters.sparkPoolName
  ],
  headerParameters: [Parameters.accept, Parameters.contentType],
  mediaType: "json",
  serializer
};
const getSparkBatchJobOperationSpec: coreClient.OperationSpec = {
  path:
    "/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches/{batchId}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.SparkBatchJob
    }
  },
  queryParameters: [Parameters.detailed],
  urlParameters: [
    Parameters.endpoint,
    Parameters.livyApiVersion,
    Parameters.sparkPoolName,
    Parameters.batchId
  ],
  headerParameters: [Parameters.accept],
  serializer
};
const cancelSparkBatchJobOperationSpec: coreClient.OperationSpec = {
  path:
    "/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}/batches/{batchId}",
  httpMethod: "DELETE",
  responses: { 200: {} },
  urlParameters: [
    Parameters.endpoint,
    Parameters.livyApiVersion,
    Parameters.sparkPoolName,
    Parameters.batchId
  ],
  serializer
};
