/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */
import { __asyncDelegator, __asyncGenerator, __asyncValues, __await } from "tslib";
import { tracingClient } from "../tracing.js";
import { setContinuationToken } from "../pagingHelper.js";
import * as coreClient from "@azure/core-client";
import * as Mappers from "../models/mappers.js";
import * as Parameters from "../models/parameters.js";
import { createHttpPoller } from "@azure/core-lro";
import { createLroSpec } from "../lroImpl.js";
// Operation Specifications
const serializer = coreClient.createSerializer(Mappers, /* isXml */ false);
const getSparkJobDefinitionsByWorkspaceOperationSpec = {
    path: "/sparkJobDefinitions",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.SparkJobDefinitionsListResponse,
        },
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint],
    headerParameters: [Parameters.accept],
    serializer,
};
const createOrUpdateSparkJobDefinitionOperationSpec = {
    path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
    httpMethod: "PUT",
    responses: {
        200: {
            bodyMapper: Mappers.SparkJobDefinitionResource,
        },
        201: {
            bodyMapper: Mappers.SparkJobDefinitionResource,
        },
        202: {
            bodyMapper: Mappers.SparkJobDefinitionResource,
        },
        204: {
            bodyMapper: Mappers.SparkJobDefinitionResource,
        },
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    requestBody: Parameters.sparkJobDefinition,
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
    headerParameters: [Parameters.accept, Parameters.contentType, Parameters.ifMatch],
    mediaType: "json",
    serializer,
};
const getSparkJobDefinitionOperationSpec = {
    path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.SparkJobDefinitionResource,
        },
        304: {},
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
    headerParameters: [Parameters.accept, Parameters.ifNoneMatch],
    serializer,
};
const deleteSparkJobDefinitionOperationSpec = {
    path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
    httpMethod: "DELETE",
    responses: {
        200: {},
        201: {},
        202: {},
        204: {},
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
    headerParameters: [Parameters.accept],
    serializer,
};
const executeSparkJobDefinitionOperationSpec = {
    path: "/sparkJobDefinitions/{sparkJobDefinitionName}/execute",
    httpMethod: "POST",
    responses: {
        200: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        201: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        202: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        204: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
    headerParameters: [Parameters.accept],
    serializer,
};
const renameSparkJobDefinitionOperationSpec = {
    path: "/sparkJobDefinitions/{sparkJobDefinitionName}/rename",
    httpMethod: "POST",
    responses: {
        200: {},
        201: {},
        202: {},
        204: {},
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    requestBody: Parameters.request,
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
    headerParameters: [Parameters.accept, Parameters.contentType],
    mediaType: "json",
    serializer,
};
const debugSparkJobDefinitionOperationSpec = {
    path: "/debugSparkJobDefinition",
    httpMethod: "POST",
    responses: {
        200: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        201: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        202: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        204: {
            bodyMapper: Mappers.SparkBatchJob,
        },
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    requestBody: Parameters.sparkJobDefinitionAzureResource,
    queryParameters: [Parameters.apiVersion5],
    urlParameters: [Parameters.endpoint],
    headerParameters: [Parameters.accept, Parameters.contentType],
    mediaType: "json",
    serializer,
};
const getSparkJobDefinitionsByWorkspaceNextOperationSpec = {
    path: "{nextLink}",
    httpMethod: "GET",
    responses: {
        200: {
            bodyMapper: Mappers.SparkJobDefinitionsListResponse,
        },
        default: {
            bodyMapper: Mappers.CloudError,
        },
    },
    urlParameters: [Parameters.endpoint, Parameters.nextLink],
    headerParameters: [Parameters.accept],
    serializer,
};
/** Class containing SparkJobDefinitionOperations operations. */
export class SparkJobDefinitionOperationsImpl {
    /**
     * Initialize a new instance of the class SparkJobDefinitionOperations class.
     * @param client - Reference to the service client
     */
    // eslint-disable-next-line @azure/azure-sdk/ts-use-interface-parameters
    constructor(client) {
        this.client = client;
    }
    /**
     * Lists spark job definitions.
     * @param options - The options parameters.
     */
    listSparkJobDefinitionsByWorkspace(options) {
        const iter = this.getSparkJobDefinitionsByWorkspacePagingAll(options);
        return {
            next() {
                return iter.next();
            },
            [Symbol.asyncIterator]() {
                return this;
            },
            byPage: (settings) => {
                if (settings === null || settings === void 0 ? void 0 : settings.maxPageSize) {
                    throw new Error("maxPageSize is not supported by this operation.");
                }
                return this.getSparkJobDefinitionsByWorkspacePagingPage(options, settings);
            },
        };
    }
    getSparkJobDefinitionsByWorkspacePagingPage(options, settings) {
        return __asyncGenerator(this, arguments, function* getSparkJobDefinitionsByWorkspacePagingPage_1() {
            let result;
            let continuationToken = settings === null || settings === void 0 ? void 0 : settings.continuationToken;
            if (!continuationToken) {
                result = yield __await(this._getSparkJobDefinitionsByWorkspace(options));
                const page = result.value || [];
                continuationToken = result.nextLink;
                setContinuationToken(page, continuationToken);
                yield yield __await(page);
            }
            while (continuationToken) {
                result = yield __await(this._getSparkJobDefinitionsByWorkspaceNext(continuationToken, options));
                continuationToken = result.nextLink;
                const page = result.value || [];
                setContinuationToken(page, continuationToken);
                yield yield __await(page);
            }
        });
    }
    getSparkJobDefinitionsByWorkspacePagingAll(options) {
        return __asyncGenerator(this, arguments, function* getSparkJobDefinitionsByWorkspacePagingAll_1() {
            var _a, e_1, _b, _c;
            try {
                for (var _d = true, _e = __asyncValues(this.getSparkJobDefinitionsByWorkspacePagingPage(options)), _f; _f = yield __await(_e.next()), _a = _f.done, !_a; _d = true) {
                    _c = _f.value;
                    _d = false;
                    const page = _c;
                    yield __await(yield* __asyncDelegator(__asyncValues(page)));
                }
            }
            catch (e_1_1) { e_1 = { error: e_1_1 }; }
            finally {
                try {
                    if (!_d && !_a && (_b = _e.return)) yield __await(_b.call(_e));
                }
                finally { if (e_1) throw e_1.error; }
            }
        });
    }
    /**
     * Lists spark job definitions.
     * @param options - The options parameters.
     */
    async _getSparkJobDefinitionsByWorkspace(options) {
        return tracingClient.withSpan("ArtifactsClient._getSparkJobDefinitionsByWorkspace", options !== null && options !== void 0 ? options : {}, async (updatedOptions) => {
            return this.client.sendOperationRequest({ updatedOptions }, getSparkJobDefinitionsByWorkspaceOperationSpec);
        });
    }
    /**
     * Creates or updates a Spark Job Definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param sparkJobDefinition - Spark Job Definition resource definition.
     * @param options - The options parameters.
     */
    async beginCreateOrUpdateSparkJobDefinition(sparkJobDefinitionName, sparkJobDefinition, options) {
        const directSendOperation = async (args, spec) => {
            return tracingClient.withSpan("ArtifactsClient.beginCreateOrUpdateSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async () => {
                return this.client.sendOperationRequest(args, spec);
            });
        };
        const sendOperationFn = async (args, spec) => {
            var _a;
            let currentRawResponse = undefined;
            const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
            const callback = (rawResponse, flatResponse) => {
                currentRawResponse = rawResponse;
                providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
            };
            const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
            const flatResponse = await directSendOperation(updatedArgs, spec);
            return {
                flatResponse,
                rawResponse: {
                    statusCode: currentRawResponse.status,
                    body: currentRawResponse.parsedBody,
                    headers: currentRawResponse.headers.toJSON(),
                },
            };
        };
        const lro = createLroSpec({
            sendOperationFn,
            args: { sparkJobDefinitionName, sparkJobDefinition, options },
            spec: createOrUpdateSparkJobDefinitionOperationSpec,
        });
        const poller = await createHttpPoller(lro, {
            restoreFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
            intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs,
        });
        await poller.poll();
        return poller;
    }
    /**
     * Creates or updates a Spark Job Definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param sparkJobDefinition - Spark Job Definition resource definition.
     * @param options - The options parameters.
     */
    async beginCreateOrUpdateSparkJobDefinitionAndWait(sparkJobDefinitionName, sparkJobDefinition, options) {
        const poller = await this.beginCreateOrUpdateSparkJobDefinition(sparkJobDefinitionName, sparkJobDefinition, options);
        return poller.pollUntilDone();
    }
    /**
     * Gets a Spark Job Definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param options - The options parameters.
     */
    async getSparkJobDefinition(sparkJobDefinitionName, options) {
        return tracingClient.withSpan("ArtifactsClient.getSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async (updatedOptions) => {
            return this.client.sendOperationRequest({ sparkJobDefinitionName, updatedOptions }, getSparkJobDefinitionOperationSpec);
        });
    }
    /**
     * Deletes a Spark Job Definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param options - The options parameters.
     */
    async beginDeleteSparkJobDefinition(sparkJobDefinitionName, options) {
        const directSendOperation = async (args, spec) => {
            return tracingClient.withSpan("ArtifactsClient.beginDeleteSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async () => {
                return this.client.sendOperationRequest(args, spec);
            });
        };
        const sendOperationFn = async (args, spec) => {
            var _a;
            let currentRawResponse = undefined;
            const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
            const callback = (rawResponse, flatResponse) => {
                currentRawResponse = rawResponse;
                providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
            };
            const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
            const flatResponse = await directSendOperation(updatedArgs, spec);
            return {
                flatResponse,
                rawResponse: {
                    statusCode: currentRawResponse.status,
                    body: currentRawResponse.parsedBody,
                    headers: currentRawResponse.headers.toJSON(),
                },
            };
        };
        const lro = createLroSpec({
            sendOperationFn,
            args: { sparkJobDefinitionName, options },
            spec: deleteSparkJobDefinitionOperationSpec,
        });
        const poller = await createHttpPoller(lro, {
            restoreFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
            intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs,
        });
        await poller.poll();
        return poller;
    }
    /**
     * Deletes a Spark Job Definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param options - The options parameters.
     */
    async beginDeleteSparkJobDefinitionAndWait(sparkJobDefinitionName, options) {
        const poller = await this.beginDeleteSparkJobDefinition(sparkJobDefinitionName, options);
        return poller.pollUntilDone();
    }
    /**
     * Executes the spark job definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param options - The options parameters.
     */
    async beginExecuteSparkJobDefinition(sparkJobDefinitionName, options) {
        const directSendOperation = async (args, spec) => {
            return tracingClient.withSpan("ArtifactsClient.beginExecuteSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async () => {
                return this.client.sendOperationRequest(args, spec);
            });
        };
        const sendOperationFn = async (args, spec) => {
            var _a;
            let currentRawResponse = undefined;
            const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
            const callback = (rawResponse, flatResponse) => {
                currentRawResponse = rawResponse;
                providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
            };
            const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
            const flatResponse = await directSendOperation(updatedArgs, spec);
            return {
                flatResponse,
                rawResponse: {
                    statusCode: currentRawResponse.status,
                    body: currentRawResponse.parsedBody,
                    headers: currentRawResponse.headers.toJSON(),
                },
            };
        };
        const lro = createLroSpec({
            sendOperationFn,
            args: { sparkJobDefinitionName, options },
            spec: executeSparkJobDefinitionOperationSpec,
        });
        const poller = await createHttpPoller(lro, {
            restoreFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
            intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs,
            resourceLocationConfig: "location",
        });
        await poller.poll();
        return poller;
    }
    /**
     * Executes the spark job definition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param options - The options parameters.
     */
    async beginExecuteSparkJobDefinitionAndWait(sparkJobDefinitionName, options) {
        const poller = await this.beginExecuteSparkJobDefinition(sparkJobDefinitionName, options);
        return poller.pollUntilDone();
    }
    /**
     * Renames a sparkJobDefinition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param request - proposed new name.
     * @param options - The options parameters.
     */
    async beginRenameSparkJobDefinition(sparkJobDefinitionName, request, options) {
        const directSendOperation = async (args, spec) => {
            return tracingClient.withSpan("ArtifactsClient.beginRenameSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async () => {
                return this.client.sendOperationRequest(args, spec);
            });
        };
        const sendOperationFn = async (args, spec) => {
            var _a;
            let currentRawResponse = undefined;
            const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
            const callback = (rawResponse, flatResponse) => {
                currentRawResponse = rawResponse;
                providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
            };
            const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
            const flatResponse = await directSendOperation(updatedArgs, spec);
            return {
                flatResponse,
                rawResponse: {
                    statusCode: currentRawResponse.status,
                    body: currentRawResponse.parsedBody,
                    headers: currentRawResponse.headers.toJSON(),
                },
            };
        };
        const lro = createLroSpec({
            sendOperationFn,
            args: { sparkJobDefinitionName, request, options },
            spec: renameSparkJobDefinitionOperationSpec,
        });
        const poller = await createHttpPoller(lro, {
            restoreFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
            intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs,
        });
        await poller.poll();
        return poller;
    }
    /**
     * Renames a sparkJobDefinition.
     * @param sparkJobDefinitionName - The spark job definition name.
     * @param request - proposed new name.
     * @param options - The options parameters.
     */
    async beginRenameSparkJobDefinitionAndWait(sparkJobDefinitionName, request, options) {
        const poller = await this.beginRenameSparkJobDefinition(sparkJobDefinitionName, request, options);
        return poller.pollUntilDone();
    }
    /**
     * Debug the spark job definition.
     * @param sparkJobDefinitionAzureResource - Spark Job Definition resource definition.
     * @param options - The options parameters.
     */
    async beginDebugSparkJobDefinition(sparkJobDefinitionAzureResource, options) {
        const directSendOperation = async (args, spec) => {
            return tracingClient.withSpan("ArtifactsClient.beginDebugSparkJobDefinition", options !== null && options !== void 0 ? options : {}, async () => {
                return this.client.sendOperationRequest(args, spec);
            });
        };
        const sendOperationFn = async (args, spec) => {
            var _a;
            let currentRawResponse = undefined;
            const providedCallback = (_a = args.options) === null || _a === void 0 ? void 0 : _a.onResponse;
            const callback = (rawResponse, flatResponse) => {
                currentRawResponse = rawResponse;
                providedCallback === null || providedCallback === void 0 ? void 0 : providedCallback(rawResponse, flatResponse);
            };
            const updatedArgs = Object.assign(Object.assign({}, args), { options: Object.assign(Object.assign({}, args.options), { onResponse: callback }) });
            const flatResponse = await directSendOperation(updatedArgs, spec);
            return {
                flatResponse,
                rawResponse: {
                    statusCode: currentRawResponse.status,
                    body: currentRawResponse.parsedBody,
                    headers: currentRawResponse.headers.toJSON(),
                },
            };
        };
        const lro = createLroSpec({
            sendOperationFn,
            args: { sparkJobDefinitionAzureResource, options },
            spec: debugSparkJobDefinitionOperationSpec,
        });
        const poller = await createHttpPoller(lro, {
            restoreFrom: options === null || options === void 0 ? void 0 : options.resumeFrom,
            intervalInMs: options === null || options === void 0 ? void 0 : options.updateIntervalInMs,
            resourceLocationConfig: "location",
        });
        await poller.poll();
        return poller;
    }
    /**
     * Debug the spark job definition.
     * @param sparkJobDefinitionAzureResource - Spark Job Definition resource definition.
     * @param options - The options parameters.
     */
    async beginDebugSparkJobDefinitionAndWait(sparkJobDefinitionAzureResource, options) {
        const poller = await this.beginDebugSparkJobDefinition(sparkJobDefinitionAzureResource, options);
        return poller.pollUntilDone();
    }
    /**
     * GetSparkJobDefinitionsByWorkspaceNext
     * @param nextLink - The nextLink from the previous successful call to the
     *                 GetSparkJobDefinitionsByWorkspace method.
     * @param options - The options parameters.
     */
    async _getSparkJobDefinitionsByWorkspaceNext(nextLink, options) {
        return tracingClient.withSpan("ArtifactsClient._getSparkJobDefinitionsByWorkspaceNext", options !== null && options !== void 0 ? options : {}, async (updatedOptions) => {
            return this.client.sendOperationRequest({ nextLink, updatedOptions }, getSparkJobDefinitionsByWorkspaceNextOperationSpec);
        });
    }
}
//# sourceMappingURL=sparkJobDefinitionOperations.js.map