/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { createSpan } from "../tracing";
import "@azure/core-paging";
import { PagedAsyncIterableIterator } from "@azure/core-paging";
import { SparkJobDefinitionOperations } from "../operationsInterfaces";
import * as coreClient from "@azure/core-client";
import * as coreTracing from "@azure/core-tracing";
import * as Mappers from "../models/mappers";
import * as Parameters from "../models/parameters";
import { ArtifactsClientContext } from "../artifactsClientContext";
import { PollerLike, PollOperationState, LroEngine } from "@azure/core-lro";
import { LroImpl } from "../lroImpl";
import {
  SparkJobDefinitionResource,
  SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceNextOptionalParams,
  SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceOptionalParams,
  SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceResponse,
  SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse,
  SparkJobDefinitionOperationsGetSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsGetSparkJobDefinitionResponse,
  SparkJobDefinitionOperationsDeleteSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsExecuteSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse,
  ArtifactRenameRequest,
  SparkJobDefinitionOperationsRenameSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsDebugSparkJobDefinitionOptionalParams,
  SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse,
  SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceNextResponse
} from "../models";

/// <reference lib="esnext.asynciterable" />
/** Class representing a SparkJobDefinitionOperations. */
export class SparkJobDefinitionOperationsImpl
  implements SparkJobDefinitionOperations {
  private readonly client: ArtifactsClientContext;

  /**
   * Initialize a new instance of the class SparkJobDefinitionOperations class.
   * @param client Reference to the service client
   */
  constructor(client: ArtifactsClientContext) {
    this.client = client;
  }

  /**
   * Lists spark job definitions.
   * @param options The options parameters.
   */
  public listSparkJobDefinitionsByWorkspace(
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceOptionalParams
  ): PagedAsyncIterableIterator<SparkJobDefinitionResource> {
    const iter = this.getSparkJobDefinitionsByWorkspacePagingAll(options);
    return {
      next() {
        return iter.next();
      },
      [Symbol.asyncIterator]() {
        return this;
      },
      byPage: () => {
        return this.getSparkJobDefinitionsByWorkspacePagingPage(options);
      }
    };
  }

  private async *getSparkJobDefinitionsByWorkspacePagingPage(
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceOptionalParams
  ): AsyncIterableIterator<SparkJobDefinitionResource[]> {
    let result = await this._getSparkJobDefinitionsByWorkspace(options);
    yield result.value || [];
    let continuationToken = result.nextLink;
    while (continuationToken) {
      result = await this._getSparkJobDefinitionsByWorkspaceNext(
        continuationToken,
        options
      );
      continuationToken = result.nextLink;
      yield result.value || [];
    }
  }

  private async *getSparkJobDefinitionsByWorkspacePagingAll(
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceOptionalParams
  ): AsyncIterableIterator<SparkJobDefinitionResource> {
    for await (const page of this.getSparkJobDefinitionsByWorkspacePagingPage(
      options
    )) {
      yield* page;
    }
  }

  /**
   * Lists spark job definitions.
   * @param options The options parameters.
   */
  private async _getSparkJobDefinitionsByWorkspace(
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceOptionalParams
  ): Promise<
    SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceResponse
  > {
    const { span } = createSpan(
      "ArtifactsClient-_getSparkJobDefinitionsByWorkspace",
      options || {}
    );
    try {
      const result = await this.client.sendOperationRequest(
        { options },
        getSparkJobDefinitionsByWorkspaceOperationSpec
      );
      return result as SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceResponse;
    } catch (error) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }

  /**
   * Creates or updates a Spark Job Definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param sparkJobDefinition Spark Job Definition resource definition.
   * @param options The options parameters.
   */
  async beginCreateOrUpdateSparkJobDefinition(
    sparkJobDefinitionName: string,
    sparkJobDefinition: SparkJobDefinitionResource,
    options?: SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionOptionalParams
  ): Promise<
    PollerLike<
      PollOperationState<
        SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse
      >,
      SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse
    >
  > {
    const { span } = createSpan(
      "ArtifactsClient-beginCreateOrUpdateSparkJobDefinition",
      options || {}
    );
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ): Promise<SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse> => {
      try {
        const result = await this.client.sendOperationRequest(args, spec);
        return result as SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse;
      } catch (error) {
        span.setStatus({
          code: coreTracing.SpanStatusCode.UNSET,
          message: error.message
        });
        throw error;
      } finally {
        span.end();
      }
    };
    const sendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ) => {
      let currentRawResponse:
        | coreClient.FullOperationResponse
        | undefined = undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback
        }
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON()
        }
      };
    };

    const lro = new LroImpl(
      sendOperation,
      { sparkJobDefinitionName, sparkJobDefinition, options },
      createOrUpdateSparkJobDefinitionOperationSpec
    );
    return new LroEngine(lro, {
      resumeFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs
    });
  }

  /**
   * Creates or updates a Spark Job Definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param sparkJobDefinition Spark Job Definition resource definition.
   * @param options The options parameters.
   */
  async beginCreateOrUpdateSparkJobDefinitionAndWait(
    sparkJobDefinitionName: string,
    sparkJobDefinition: SparkJobDefinitionResource,
    options?: SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionOptionalParams
  ): Promise<
    SparkJobDefinitionOperationsCreateOrUpdateSparkJobDefinitionResponse
  > {
    const poller = await this.beginCreateOrUpdateSparkJobDefinition(
      sparkJobDefinitionName,
      sparkJobDefinition,
      options
    );
    return poller.pollUntilDone();
  }

  /**
   * Gets a Spark Job Definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param options The options parameters.
   */
  async getSparkJobDefinition(
    sparkJobDefinitionName: string,
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionOptionalParams
  ): Promise<SparkJobDefinitionOperationsGetSparkJobDefinitionResponse> {
    const { span } = createSpan(
      "ArtifactsClient-getSparkJobDefinition",
      options || {}
    );
    try {
      const result = await this.client.sendOperationRequest(
        { sparkJobDefinitionName, options },
        getSparkJobDefinitionOperationSpec
      );
      return result as SparkJobDefinitionOperationsGetSparkJobDefinitionResponse;
    } catch (error) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }

  /**
   * Deletes a Spark Job Definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param options The options parameters.
   */
  async beginDeleteSparkJobDefinition(
    sparkJobDefinitionName: string,
    options?: SparkJobDefinitionOperationsDeleteSparkJobDefinitionOptionalParams
  ): Promise<PollerLike<PollOperationState<void>, void>> {
    const { span } = createSpan(
      "ArtifactsClient-beginDeleteSparkJobDefinition",
      options || {}
    );
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ): Promise<void> => {
      try {
        const result = await this.client.sendOperationRequest(args, spec);
        return result as void;
      } catch (error) {
        span.setStatus({
          code: coreTracing.SpanStatusCode.UNSET,
          message: error.message
        });
        throw error;
      } finally {
        span.end();
      }
    };
    const sendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ) => {
      let currentRawResponse:
        | coreClient.FullOperationResponse
        | undefined = undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback
        }
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON()
        }
      };
    };

    const lro = new LroImpl(
      sendOperation,
      { sparkJobDefinitionName, options },
      deleteSparkJobDefinitionOperationSpec
    );
    return new LroEngine(lro, {
      resumeFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs
    });
  }

  /**
   * Deletes a Spark Job Definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param options The options parameters.
   */
  async beginDeleteSparkJobDefinitionAndWait(
    sparkJobDefinitionName: string,
    options?: SparkJobDefinitionOperationsDeleteSparkJobDefinitionOptionalParams
  ): Promise<void> {
    const poller = await this.beginDeleteSparkJobDefinition(
      sparkJobDefinitionName,
      options
    );
    return poller.pollUntilDone();
  }

  /**
   * Executes the spark job definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param options The options parameters.
   */
  async beginExecuteSparkJobDefinition(
    sparkJobDefinitionName: string,
    options?: SparkJobDefinitionOperationsExecuteSparkJobDefinitionOptionalParams
  ): Promise<
    PollerLike<
      PollOperationState<
        SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse
      >,
      SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse
    >
  > {
    const { span } = createSpan(
      "ArtifactsClient-beginExecuteSparkJobDefinition",
      options || {}
    );
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ): Promise<SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse> => {
      try {
        const result = await this.client.sendOperationRequest(args, spec);
        return result as SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse;
      } catch (error) {
        span.setStatus({
          code: coreTracing.SpanStatusCode.UNSET,
          message: error.message
        });
        throw error;
      } finally {
        span.end();
      }
    };
    const sendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ) => {
      let currentRawResponse:
        | coreClient.FullOperationResponse
        | undefined = undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback
        }
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON()
        }
      };
    };

    const lro = new LroImpl(
      sendOperation,
      { sparkJobDefinitionName, options },
      executeSparkJobDefinitionOperationSpec
    );
    return new LroEngine(lro, {
      resumeFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs,
      lroResourceLocationConfig: "location"
    });
  }

  /**
   * Executes the spark job definition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param options The options parameters.
   */
  async beginExecuteSparkJobDefinitionAndWait(
    sparkJobDefinitionName: string,
    options?: SparkJobDefinitionOperationsExecuteSparkJobDefinitionOptionalParams
  ): Promise<SparkJobDefinitionOperationsExecuteSparkJobDefinitionResponse> {
    const poller = await this.beginExecuteSparkJobDefinition(
      sparkJobDefinitionName,
      options
    );
    return poller.pollUntilDone();
  }

  /**
   * Renames a sparkJobDefinition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param request proposed new name.
   * @param options The options parameters.
   */
  async beginRenameSparkJobDefinition(
    sparkJobDefinitionName: string,
    request: ArtifactRenameRequest,
    options?: SparkJobDefinitionOperationsRenameSparkJobDefinitionOptionalParams
  ): Promise<PollerLike<PollOperationState<void>, void>> {
    const { span } = createSpan(
      "ArtifactsClient-beginRenameSparkJobDefinition",
      options || {}
    );
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ): Promise<void> => {
      try {
        const result = await this.client.sendOperationRequest(args, spec);
        return result as void;
      } catch (error) {
        span.setStatus({
          code: coreTracing.SpanStatusCode.UNSET,
          message: error.message
        });
        throw error;
      } finally {
        span.end();
      }
    };
    const sendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ) => {
      let currentRawResponse:
        | coreClient.FullOperationResponse
        | undefined = undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback
        }
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON()
        }
      };
    };

    const lro = new LroImpl(
      sendOperation,
      { sparkJobDefinitionName, request, options },
      renameSparkJobDefinitionOperationSpec
    );
    return new LroEngine(lro, {
      resumeFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs
    });
  }

  /**
   * Renames a sparkJobDefinition.
   * @param sparkJobDefinitionName The spark job definition name.
   * @param request proposed new name.
   * @param options The options parameters.
   */
  async beginRenameSparkJobDefinitionAndWait(
    sparkJobDefinitionName: string,
    request: ArtifactRenameRequest,
    options?: SparkJobDefinitionOperationsRenameSparkJobDefinitionOptionalParams
  ): Promise<void> {
    const poller = await this.beginRenameSparkJobDefinition(
      sparkJobDefinitionName,
      request,
      options
    );
    return poller.pollUntilDone();
  }

  /**
   * Debug the spark job definition.
   * @param sparkJobDefinitionAzureResource Spark Job Definition resource definition.
   * @param options The options parameters.
   */
  async beginDebugSparkJobDefinition(
    sparkJobDefinitionAzureResource: SparkJobDefinitionResource,
    options?: SparkJobDefinitionOperationsDebugSparkJobDefinitionOptionalParams
  ): Promise<
    PollerLike<
      PollOperationState<
        SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse
      >,
      SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse
    >
  > {
    const { span } = createSpan(
      "ArtifactsClient-beginDebugSparkJobDefinition",
      options || {}
    );
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ): Promise<SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse> => {
      try {
        const result = await this.client.sendOperationRequest(args, spec);
        return result as SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse;
      } catch (error) {
        span.setStatus({
          code: coreTracing.SpanStatusCode.UNSET,
          message: error.message
        });
        throw error;
      } finally {
        span.end();
      }
    };
    const sendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec
    ) => {
      let currentRawResponse:
        | coreClient.FullOperationResponse
        | undefined = undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback
        }
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON()
        }
      };
    };

    const lro = new LroImpl(
      sendOperation,
      { sparkJobDefinitionAzureResource, options },
      debugSparkJobDefinitionOperationSpec
    );
    return new LroEngine(lro, {
      resumeFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs,
      lroResourceLocationConfig: "location"
    });
  }

  /**
   * Debug the spark job definition.
   * @param sparkJobDefinitionAzureResource Spark Job Definition resource definition.
   * @param options The options parameters.
   */
  async beginDebugSparkJobDefinitionAndWait(
    sparkJobDefinitionAzureResource: SparkJobDefinitionResource,
    options?: SparkJobDefinitionOperationsDebugSparkJobDefinitionOptionalParams
  ): Promise<SparkJobDefinitionOperationsDebugSparkJobDefinitionResponse> {
    const poller = await this.beginDebugSparkJobDefinition(
      sparkJobDefinitionAzureResource,
      options
    );
    return poller.pollUntilDone();
  }

  /**
   * GetSparkJobDefinitionsByWorkspaceNext
   * @param nextLink The nextLink from the previous successful call to the
   *                 GetSparkJobDefinitionsByWorkspace method.
   * @param options The options parameters.
   */
  private async _getSparkJobDefinitionsByWorkspaceNext(
    nextLink: string,
    options?: SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceNextOptionalParams
  ): Promise<
    SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceNextResponse
  > {
    const { span } = createSpan(
      "ArtifactsClient-_getSparkJobDefinitionsByWorkspaceNext",
      options || {}
    );
    try {
      const result = await this.client.sendOperationRequest(
        { nextLink, options },
        getSparkJobDefinitionsByWorkspaceNextOperationSpec
      );
      return result as SparkJobDefinitionOperationsGetSparkJobDefinitionsByWorkspaceNextResponse;
    } catch (error) {
      span.setStatus({
        code: coreTracing.SpanStatusCode.UNSET,
        message: error.message
      });
      throw error;
    } finally {
      span.end();
    }
  }
}
// Operation Specifications
const serializer = coreClient.createSerializer(Mappers, /* isXml */ false);

const getSparkJobDefinitionsByWorkspaceOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.SparkJobDefinitionsListResponse
    },
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint],
  headerParameters: [Parameters.accept],
  serializer
};
const createOrUpdateSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
  httpMethod: "PUT",
  responses: {
    200: {
      bodyMapper: Mappers.SparkJobDefinitionResource
    },
    201: {
      bodyMapper: Mappers.SparkJobDefinitionResource
    },
    202: {
      bodyMapper: Mappers.SparkJobDefinitionResource
    },
    204: {
      bodyMapper: Mappers.SparkJobDefinitionResource
    },
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  requestBody: Parameters.sparkJobDefinition,
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
  headerParameters: [
    Parameters.accept,
    Parameters.contentType,
    Parameters.ifMatch
  ],
  mediaType: "json",
  serializer
};
const getSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.SparkJobDefinitionResource
    },
    304: {},
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
  headerParameters: [Parameters.accept, Parameters.ifNoneMatch],
  serializer
};
const deleteSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions/{sparkJobDefinitionName}",
  httpMethod: "DELETE",
  responses: {
    200: {},
    201: {},
    202: {},
    204: {},
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
  headerParameters: [Parameters.accept],
  serializer
};
const executeSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions/{sparkJobDefinitionName}/execute",
  httpMethod: "POST",
  responses: {
    200: {
      bodyMapper: Mappers.SparkBatchJob
    },
    201: {
      bodyMapper: Mappers.SparkBatchJob
    },
    202: {
      bodyMapper: Mappers.SparkBatchJob
    },
    204: {
      bodyMapper: Mappers.SparkBatchJob
    },
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
  headerParameters: [Parameters.accept],
  serializer
};
const renameSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/sparkJobDefinitions/{sparkJobDefinitionName}/rename",
  httpMethod: "POST",
  responses: {
    200: {},
    201: {},
    202: {},
    204: {},
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  requestBody: Parameters.request,
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.sparkJobDefinitionName],
  headerParameters: [Parameters.accept, Parameters.contentType],
  mediaType: "json",
  serializer
};
const debugSparkJobDefinitionOperationSpec: coreClient.OperationSpec = {
  path: "/debugSparkJobDefinition",
  httpMethod: "POST",
  responses: {
    200: {
      bodyMapper: Mappers.SparkBatchJob
    },
    201: {
      bodyMapper: Mappers.SparkBatchJob
    },
    202: {
      bodyMapper: Mappers.SparkBatchJob
    },
    204: {
      bodyMapper: Mappers.SparkBatchJob
    },
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  requestBody: Parameters.sparkJobDefinitionAzureResource,
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint],
  headerParameters: [Parameters.accept, Parameters.contentType],
  mediaType: "json",
  serializer
};
const getSparkJobDefinitionsByWorkspaceNextOperationSpec: coreClient.OperationSpec = {
  path: "{nextLink}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.SparkJobDefinitionsListResponse
    },
    default: {
      bodyMapper: Mappers.CloudError
    }
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [Parameters.endpoint, Parameters.nextLink],
  headerParameters: [Parameters.accept],
  serializer
};
