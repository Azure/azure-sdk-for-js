## API Report File for "@azure-rest/openai-inference"

> Do not edit this file. It is a report generated by [API Extractor](https://api-extractor.com/).

```ts

import { Client } from '@azure-rest/core-client';
import { ClientOptions } from '@azure-rest/core-client';
import { HttpResponse } from '@azure-rest/core-client';
import { KeyCredential } from '@azure/core-auth';
import { RawHttpHeaders } from '@azure/core-rest-pipeline';
import { RequestParameters } from '@azure-rest/core-client';
import { StreamableMethod } from '@azure-rest/core-client';
import { TokenCredential } from '@azure/core-auth';

// @public
export interface ChoiceOutput {
    finish_reason?: string;
    index?: number;
    logprobs?: CompletionsLogProbsModelOutput;
    text?: string;
}

// @public
export interface CompletionOutput {
    choices?: Array<ChoiceOutput>;
    created?: number;
    id?: string;
    model?: string;
    object: "text_completion";
}

// @public (undocumented)
export interface Completions {
    post(options?: CompletionsParameters): StreamableMethod<Completions200Response | CompletionsDefaultResponse>;
}

// @public (undocumented)
export interface Completions200Headers {
    "apim-request-id": string;
}

// @public
export interface Completions200Response extends HttpResponse {
    // (undocumented)
    body: CompletionOutput;
    // (undocumented)
    headers: RawHttpHeaders & Completions200Headers;
    // (undocumented)
    status: "200";
}

// @public (undocumented)
export interface CompletionsBodyParam {
    // (undocumented)
    body?: CompletionsRequest;
}

// @public (undocumented)
export interface CompletionsDefaultResponse extends HttpResponse {
    // (undocumented)
    body: ErrorResponseOutput;
    // (undocumented)
    status: string;
}

// @public
export interface CompletionsLogProbsModelOutput {
    text_offset?: number[];
    token_logprobs?: number[];
    tokens?: string[];
    top_logprobs?: Record<string, number>[];
}

// @public (undocumented)
export type CompletionsParameters = CompletionsBodyParam & RequestParameters;

// @public
export interface CompletionsRequest {
    best_of?: number;
    cache_level?: number;
    completion_config?: string;
    echo?: boolean;
    frequency_penalty?: number;
    logit_bias?: Record<string, number>;
    logprobs?: number;
    max_tokens?: number;
    model?: string;
    n?: number;
    presence_penalty?: number;
    prompt?: string[];
    stop?: string[];
    stream?: boolean;
    temperature?: number;
    top_p?: number;
    user?: string;
}

// @public
function createClient(endpoint: string, credentials: TokenCredential | KeyCredential, options?: ClientOptions): OpenAIInferenceClient;
export default createClient;

// @public (undocumented)
export interface EmbeddingItemOutput {
    // (undocumented)
    embedding: number[];
    // (undocumented)
    index: number;
    // (undocumented)
    object: "embedding";
}

// @public (undocumented)
export interface Embeddings {
    post(options?: EmbeddingsParameters): StreamableMethod<Embeddings200Response | EmbeddingsDefaultResponse>;
}

// @public
export interface Embeddings200Response extends HttpResponse {
    // (undocumented)
    body: EmbeddingsOutput;
    // (undocumented)
    status: "200";
}

// @public (undocumented)
export interface EmbeddingsBodyParam {
    // (undocumented)
    body?: EmbeddingsRequest;
}

// @public (undocumented)
export interface EmbeddingsDefaultResponse extends HttpResponse {
    // (undocumented)
    body: ErrorResponseOutput;
    // (undocumented)
    status: string;
}

// @public (undocumented)
export interface EmbeddingsOutput {
    // (undocumented)
    data: Array<EmbeddingItemOutput>;
    // (undocumented)
    object: "list";
}

// @public (undocumented)
export type EmbeddingsParameters = EmbeddingsBodyParam & RequestParameters;

// @public (undocumented)
export interface EmbeddingsRequest {
    input: string | string[];
    input_type?: string;
    model?: string;
    user?: string;
}

// @public
export interface ErrorModelOutput {
    code: string;
    details: Array<ErrorModelOutput>;
    innererror?: InnerErrorOutput;
    message: string;
    target?: string;
}

// @public
export interface ErrorResponseOutput {
    error: ErrorModelOutput;
}

// @public
export interface InnerErrorOutput {
    code: string;
    innererror?: InnerErrorOutput;
}

// @public (undocumented)
export function isUnexpected(response: Embeddings200Response | EmbeddingsDefaultResponse): response is EmbeddingsDefaultResponse;

// @public (undocumented)
export function isUnexpected(response: Completions200Response | CompletionsDefaultResponse): response is CompletionsDefaultResponse;

// @public (undocumented)
export type OpenAIInferenceClient = Client & {
    path: Routes;
};

// @public (undocumented)
export interface Routes {
    (path: "/deployments/{deploymentId}/embeddings", deploymentId: string): Embeddings;
    (path: "/deployments/{deploymentId}/completions", deploymentId: string): Completions;
}

// (No @packageDocumentation comment for this package)

```
