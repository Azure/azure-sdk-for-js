/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import * as coreClient from "@azure/core-client";

/** Request body for find similar operation. */
export interface FindSimilarRequest {
  /** FaceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note that this faceId is not persisted and will expire at the time specified by faceIdTimeToLive after the detection call */
  faceId: string;
  /** An existing user-specified unique candidate face list, created in Face List - Create a Face List. Face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  faceListId?: string;
  /** An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  largeFaceListId?: string;
  /** An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire at the time specified by faceIdTimeToLive after the detection call. The number of faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  faceIds?: string[];
  /** The number of top similar faces returned. The valid range is [1, 1000]. */
  maxNumOfCandidatesReturned?: number;
  /** Similar face searching mode. It can be "matchPerson" or "matchFace". */
  mode?: FindSimilarMatchMode;
}

/** Response body for find similar face operation. */
export interface SimilarFace {
  /** FaceId of candidate face when find by faceIds. faceId is created by Face - Detect and will expire at the time specified by faceIdTimeToLive after the detection call */
  faceId?: string;
  /** PersistedFaceId of candidate face when find by faceListId. persistedFaceId in face list is persisted and will not expire. As showed in below response */
  persistedFaceId?: string;
  /** Similarity confidence of the candidate face. The higher confidence, the more similar. Range between [0,1]. */
  confidence: number;
}

/** Error information returned by the API */
export interface APIError {
  /** Error body. */
  error?: ErrorModel;
}

/** Error body. */
export interface ErrorModel {
  code?: string;
  message?: string;
}

/** Request body for group request. */
export interface GroupRequest {
  /** Array of candidate faceId created by Face - Detect. The maximum is 1000 faces */
  faceIds: string[];
}

/** An array of face groups based on face similarity. */
export interface GroupResult {
  /** A partition of the original faces based on face similarity. Groups are ranked by number of faces */
  groups: string[][];
  /** Face ids array of faces that cannot find any similar faces from original faces. */
  messyGroup?: string[];
}

/** Request body for identify face operation. */
export interface IdentifyRequest {
  /** Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified independently. The valid number of faceIds is between [1, 10]. */
  faceIds: string[];
  /** PersonGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  personGroupId?: string;
  /** LargePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  largePersonGroupId?: string;
  /** The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 1). */
  maxNumOfCandidatesReturned?: number;
  /** Confidence threshold of identification, used to judge whether one face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by algorithm). */
  confidenceThreshold?: number;
}

/** Response body for identify face operation. */
export interface IdentifyResult {
  /** FaceId of the query face */
  faceId: string;
  /** Identified person candidates for that face (ranked by confidence). Array size should be no larger than input maxNumOfCandidatesReturned. If no person is identified, will return an empty array. */
  candidates: IdentifyCandidate[];
}

/** All possible faces that may qualify. */
export interface IdentifyCandidate {
  /** Id of candidate */
  personId: string;
  /** Confidence threshold of identification, used to judge whether one face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by algorithm). */
  confidence: number;
}

/** Request body for face to face verification. */
export interface VerifyFaceToFaceRequest {
  /** FaceId of the first face, comes from Face - Detect */
  faceId1: string;
  /** FaceId of the second face, comes from Face - Detect */
  faceId2: string;
}

/** Result of the verify operation. */
export interface VerifyResult {
  /** True if the two faces belong to the same person or the face belongs to the person, otherwise false. */
  isIdentical: boolean;
  /** A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override "isIdentical" and fine-tune the result on their own data. */
  confidence: number;
}

/** A combination of user defined name and user specified data for the person, largePersonGroup/personGroup, and largeFaceList/faceList. */
export interface NameAndUserDataContract {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** PersonFace object. */
export interface PersistedFace {
  /** The persistedFaceId of the target face, which is persisted and will not expire. Different from faceId created by Face - Detect and will expire in at the time specified by faceIdTimeToLive after the detection call. */
  persistedFaceId: string;
  /** User-provided data attached to the face. The size limit is 1KB. */
  userData?: string;
}

/** Request to update face data. */
export interface UpdateFaceRequest {
  /** User-provided data attached to the face. The size limit is 1KB. */
  userData?: string;
}

/** A combination of user defined name and user specified data for the person, largePersonGroup/personGroup, and largeFaceList/faceList. */
export interface NonNullableNameAndNullableUserDataContract {
  /** User defined name, maximum length is 128. */
  name: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Person group object. */
export interface PersonGroup {
  /** PersonGroupId of the target person group. */
  personGroupId: string;
  /** User defined name, maximum length is 128. */
  name: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Training status object. */
export interface TrainingStatus {
  /** Training status: notstarted, running, succeeded, failed. If the training process is waiting to perform, the status is notstarted. If the training is ongoing, the status is running. Status succeed means this person group or large person group is ready for Face - Identify, or this large face list is ready for Face - Find Similar. Status failed is often caused by no person or no persisted face exist in the person group or large person group, or no persisted face exist in the large face list. */
  status: TrainingStatusType;
  /** A combined UTC date and time string that describes the created time of the person group, large person group or large face list. */
  created: Date;
  /** A combined UTC date and time string that describes the last modify time of the person group, large person group or large face list, could be null value when the group is not successfully trained. */
  lastAction?: Date;
  /** A combined UTC date and time string that describes the last successful training time of the person group, large person group or large face list. */
  lastSuccessfulTraining?: Date;
  /** Show failure message when training failed (omitted when training succeed). */
  message?: string;
}

/** Face list object. */
export interface FaceList {
  /** FaceListId of the target face list. */
  faceListId: string;
  /** User defined name, maximum length is 128. */
  name: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
  /** Persisted faces within the face list. */
  persistedFaces?: PersistedFace[];
}

export interface ImageUrl {
  /** Publicly reachable URL of an image */
  url: string;
}

/** Detected Face object. */
export interface DetectedFace {
  faceId?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
  /** A rectangle within which a face can be found */
  faceRectangle: FaceRectangle;
  /** A collection of 27-point face landmarks pointing to the important positions of face components. */
  faceLandmarks?: FaceLandmarks;
  /** Face Attributes */
  faceAttributes?: FaceAttributes;
}

/** A rectangle within which a face can be found */
export interface FaceRectangle {
  /** The width of the rectangle, in pixels. */
  width: number;
  /** The height of the rectangle, in pixels. */
  height: number;
  /** The distance from the left edge if the image to the left edge of the rectangle, in pixels. */
  left: number;
  /** The distance from the top edge if the image to the top edge of the rectangle, in pixels. */
  top: number;
}

/** A collection of 27-point face landmarks pointing to the important positions of face components. */
export interface FaceLandmarks {
  /** Coordinates within an image */
  pupilLeft?: Coordinate;
  /** Coordinates within an image */
  pupilRight?: Coordinate;
  /** Coordinates within an image */
  noseTip?: Coordinate;
  /** Coordinates within an image */
  mouthLeft?: Coordinate;
  /** Coordinates within an image */
  mouthRight?: Coordinate;
  /** Coordinates within an image */
  eyebrowLeftOuter?: Coordinate;
  /** Coordinates within an image */
  eyebrowLeftInner?: Coordinate;
  /** Coordinates within an image */
  eyeLeftOuter?: Coordinate;
  /** Coordinates within an image */
  eyeLeftTop?: Coordinate;
  /** Coordinates within an image */
  eyeLeftBottom?: Coordinate;
  /** Coordinates within an image */
  eyeLeftInner?: Coordinate;
  /** Coordinates within an image */
  eyebrowRightInner?: Coordinate;
  /** Coordinates within an image */
  eyebrowRightOuter?: Coordinate;
  /** Coordinates within an image */
  eyeRightInner?: Coordinate;
  /** Coordinates within an image */
  eyeRightTop?: Coordinate;
  /** Coordinates within an image */
  eyeRightBottom?: Coordinate;
  /** Coordinates within an image */
  eyeRightOuter?: Coordinate;
  /** Coordinates within an image */
  noseRootLeft?: Coordinate;
  /** Coordinates within an image */
  noseRootRight?: Coordinate;
  /** Coordinates within an image */
  noseLeftAlarTop?: Coordinate;
  /** Coordinates within an image */
  noseRightAlarTop?: Coordinate;
  /** Coordinates within an image */
  noseLeftAlarOutTip?: Coordinate;
  /** Coordinates within an image */
  noseRightAlarOutTip?: Coordinate;
  /** Coordinates within an image */
  upperLipTop?: Coordinate;
  /** Coordinates within an image */
  upperLipBottom?: Coordinate;
  /** Coordinates within an image */
  underLipTop?: Coordinate;
  /** Coordinates within an image */
  underLipBottom?: Coordinate;
}

/** Coordinates within an image */
export interface Coordinate {
  /** The horizontal component, in pixels. */
  x: number;
  /** The vertical component, in pixels. */
  y: number;
}

/** Face Attributes */
export interface FaceAttributes {
  /** Age in years */
  age?: number;
  /** Possible gender of the face. */
  gender?: Gender;
  /** Smile intensity, a number between [0,1] */
  smile?: number;
  /** Properties describing facial hair attributes. */
  facialHair?: FacialHair;
  /** Glasses type if any of the face. */
  glasses?: GlassesType;
  /** Properties indicating head pose of the face. */
  headPose?: HeadPose;
  /** Properties describing facial emotion in form of confidence ranging from 0 to 1. */
  emotion?: Emotion;
  /** Properties describing hair attributes. */
  hair?: Hair;
  /** Properties describing the presence of makeup on a given face. */
  makeup?: Makeup;
  /** Properties describing occlusions on a given face. */
  occlusion?: Occlusion;
  /** Properties describing any accessories on a given face. */
  accessories?: Accessory[];
  /** Properties describing any presence of blur within the image. */
  blur?: Blur;
  /** Properties describing exposure level of the image. */
  exposure?: Exposure;
  /** Properties describing noise level of the image. */
  noise?: Noise;
  /** Properties describing the presence of a mask on a given face. */
  mask?: Mask;
  /** Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. */
  qualityForRecognition?: QualityForRecognition;
}

/** Properties describing facial hair attributes. */
export interface FacialHair {
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  moustache?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  beard?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  sideburns?: number;
}

/** Properties indicating head pose of the face. */
export interface HeadPose {
  roll?: number;
  yaw?: number;
  pitch?: number;
}

/** Properties describing facial emotion in form of confidence ranging from 0 to 1. */
export interface Emotion {
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  anger?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  contempt?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  disgust?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  fear?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  happiness?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  neutral?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  sadness?: number;
  /** A number ranging from 0 to 1 indicating a level of confidence associated with a property. */
  surprise?: number;
}

/** Properties describing hair attributes. */
export interface Hair {
  /** A number describing confidence level of whether the person is bald. */
  bald?: number;
  /** A boolean value describing whether the hair is visible in the image. */
  invisible?: boolean;
  /** An array of candidate colors and confidence level in the presence of each. */
  hairColor?: HairColor[];
}

/** Hair color and associated confidence */
export interface HairColor {
  /** Name of the hair color. */
  color?: HairColorType;
  /** Confidence level of the color */
  confidence?: number;
}

/** Properties describing the presence of makeup on a given face. */
export interface Makeup {
  /** A boolean value describing whether eye makeup is present on a face. */
  eyeMakeup?: boolean;
  /** A boolean value describing whether lip makeup is present on a face. */
  lipMakeup?: boolean;
}

/** Properties describing occlusions on a given face. */
export interface Occlusion {
  /** A boolean value indicating whether forehead is occluded. */
  foreheadOccluded?: boolean;
  /** A boolean value indicating whether eyes are occluded. */
  eyeOccluded?: boolean;
  /** A boolean value indicating whether the mouth is occluded. */
  mouthOccluded?: boolean;
}

/** Accessory item and corresponding confidence level. */
export interface Accessory {
  /** Type of an accessory */
  type?: AccessoryType;
  /** Confidence level of an accessory */
  confidence?: number;
}

/** Properties describing any presence of blur within the image. */
export interface Blur {
  /** An enum value indicating level of blurriness. */
  blurLevel?: BlurLevel;
  /** A number indicating level of blurriness ranging from 0 to 1. */
  value?: number;
}

/** Properties describing exposure level of the image. */
export interface Exposure {
  /** An enum value indicating level of exposure. */
  exposureLevel?: ExposureLevel;
  /** A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. */
  value?: number;
}

/** Properties describing noise level of the image. */
export interface Noise {
  /** An enum value indicating level of noise. */
  noiseLevel?: NoiseLevel;
  /** A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. */
  value?: number;
}

/** Properties describing the presence of a mask on a given face. */
export interface Mask {
  /** Mask type if any of the face */
  type?: MaskType;
  /** A boolean value indicating whether nose and mouth are covered. */
  noseAndMouthCovered?: boolean;
}

/** Large person group object. */
export interface LargePersonGroup {
  /** LargePersonGroupId of the target large person groups */
  largePersonGroupId: string;
  /** User defined name, maximum length is 128. */
  name: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Large face list object. */
export interface LargeFaceList {
  /** LargeFaceListId of the target large face list. */
  largeFaceListId: string;
  /** User defined name, maximum length is 128. */
  name: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Request body for taking snapshot operation. */
export interface TakeSnapshotRequest {
  /** User specified type for the source object to take snapshot from. Currently FaceList, PersonGroup, LargeFaceList and LargePersonGroup are supported. */
  type: SnapshotObjectType;
  /** User specified source object id to take snapshot from. */
  objectId: string;
  /** User specified array of target Face subscription ids for the snapshot. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it. */
  applyScope: string[];
  /** User specified data about the snapshot for any purpose. Length should not exceed 16KB. */
  userData?: string;
}

/** Snapshot object. */
export interface Snapshot {
  /** Snapshot id. */
  id: string;
  /** Azure Cognitive Service Face account id of the subscriber who created the snapshot by Snapshot - Take. */
  account: string;
  /** Type of the source object in the snapshot, specified by the subscriber who created the snapshot when calling Snapshot - Take. Currently FaceList, PersonGroup, LargeFaceList and LargePersonGroup are supported. */
  type: SnapshotObjectType;
  /** Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it. */
  applyScope: string[];
  /** User specified data about the snapshot for any purpose. Length should not exceed 16KB. */
  userData?: string;
  /** A combined UTC date and time string that describes the created time of the snapshot. E.g. 2018-12-25T11:41:02.2331413Z. */
  createdTime: Date;
  /** A combined UTC date and time string that describes the last time when the snapshot was created or updated by Snapshot - Update. E.g. 2018-12-25T11:51:27.8705696Z. */
  lastUpdateTime: Date;
}

/** Request body for updating a snapshot, with a combination of user defined apply scope and user specified data. */
export interface UpdateSnapshotRequest {
  /** Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it. */
  applyScope?: string[];
  /** User specified data about the snapshot for any purpose. Length should not exceed 16KB. */
  userData?: string;
}

/** Request body for applying snapshot operation. */
export interface ApplySnapshotRequest {
  /** User specified target object id to be created from the snapshot. */
  objectId: string;
  /** Snapshot applying mode. Currently only CreateNew is supported, which means the apply operation will fail if target subscription already contains an object of same type and using the same objectId. Users can specify the "objectId" in request body to avoid such conflicts. */
  mode?: "CreateNew";
}

/** Operation status object. Operation refers to the asynchronous backend task including taking a snapshot and applying a snapshot. */
export interface OperationStatus {
  /** Operation status: notstarted, running, succeeded, failed. If the operation is requested and waiting to perform, the status is notstarted. If the operation is ongoing in backend, the status is running. Status succeeded means the operation is completed successfully, specifically for snapshot taking operation, it illustrates the snapshot is well taken and ready to apply, and for snapshot applying operation, it presents the target object has finished creating by the snapshot and ready to be used. Status failed is often caused by editing the source object while taking the snapshot or editing the target object while applying the snapshot before completion, see the field "message" to check the failure reason. */
  status: OperationStatusType;
  /** A combined UTC date and time string that describes the time when the operation (take or apply a snapshot) is requested. E.g. 2018-12-25T11:41:02.2331413Z. */
  createdTime: Date;
  /** A combined UTC date and time string that describes the last time the operation (take or apply a snapshot) is actively migrating data. The lastActionTime will keep increasing until the operation finishes. E.g. 2018-12-25T11:51:27.8705696Z. */
  lastActionTime?: Date;
  /** When the operation succeeds successfully, for snapshot taking operation the snapshot id will be included in this field, and for snapshot applying operation, the path to get the target object will be returned in this field. */
  resourceLocation?: string;
  /** Show failure message when operation fails (omitted when operation succeeds). */
  message?: string;
}

/** Request body for face to person verification. */
export interface VerifyFaceToPersonRequest {
  /** FaceId of the face, comes from Face - Detect */
  faceId: string;
  /** Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  personGroupId?: string;
  /** Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  largePersonGroupId?: string;
  /** Specify a certain person in a person group or a large person group. personId is created in PersonGroup Person - Create or LargePersonGroup Person - Create. */
  personId: string;
}

/** Person object. */
export type Person = NameAndUserDataContract & {
  /** PersonId of the target face list. */
  personId: string;
  /** PersistedFaceIds of registered faces in the person. These persistedFaceIds are returned from Person - Add a Person Face, and will not expire. */
  persistedFaceIds?: string[];
};

/** A combination of user defined name and user specified data and recognition model name for largePersonGroup/personGroup, and largeFaceList/faceList. */
export type MetaDataContract = NonNullableNameAndNullableUserDataContract & {
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
};

/** Defines headers for Snapshot_take operation. */
export interface SnapshotTakeHeaders {
  /** Operation location with an operation id used to track the progress of taking snapshot. The returned id is the operation id, rather than snapshot id. Snapshot id can be obtained only when the operation status becomes "succeeded" in OperationStatus - Get. */
  operationLocation?: string;
}

/** Defines headers for Snapshot_apply operation. */
export interface SnapshotApplyHeaders {
  /** Operation location with an operation id used to track the progress of applying the snapshot by OperationStatus - Get. */
  operationLocation?: string;
}

/** Known values of {@link RecognitionModel} that the service accepts. */
export enum KnownRecognitionModel {
  Recognition01 = "recognition_01",
  Recognition02 = "recognition_02",
  Recognition03 = "recognition_03",
  Recognition04 = "recognition_04"
}

/**
 * Defines values for RecognitionModel. \
 * {@link KnownRecognitionModel} can be used interchangeably with RecognitionModel,
 *  this enum contains the known values that the service supports.
 * ### Known values supported by the service
 * **recognition_01** \
 * **recognition_02** \
 * **recognition_03** \
 * **recognition_04**
 */
export type RecognitionModel = string;

/** Known values of {@link DetectionModel} that the service accepts. */
export enum KnownDetectionModel {
  Detection01 = "detection_01",
  Detection02 = "detection_02",
  Detection03 = "detection_03"
}

/**
 * Defines values for DetectionModel. \
 * {@link KnownDetectionModel} can be used interchangeably with DetectionModel,
 *  this enum contains the known values that the service supports.
 * ### Known values supported by the service
 * **detection_01** \
 * **detection_02** \
 * **detection_03**
 */
export type DetectionModel = string;
/** Defines values for FindSimilarMatchMode. */
export type FindSimilarMatchMode = "matchPerson" | "matchFace";
/** Defines values for TrainingStatusType. */
export type TrainingStatusType =
  | "nonstarted"
  | "running"
  | "succeeded"
  | "failed";
/** Defines values for FaceAttributeType. */
export type FaceAttributeType =
  | "age"
  | "gender"
  | "headPose"
  | "smile"
  | "facialHair"
  | "glasses"
  | "emotion"
  | "hair"
  | "makeup"
  | "occlusion"
  | "accessories"
  | "blur"
  | "exposure"
  | "noise"
  | "mask"
  | "qualityForRecognition";
/** Defines values for Gender. */
export type Gender = "male" | "female";
/** Defines values for GlassesType. */
export type GlassesType =
  | "noGlasses"
  | "readingGlasses"
  | "sunglasses"
  | "swimmingGoggles";
/** Defines values for HairColorType. */
export type HairColorType =
  | "unknown"
  | "white"
  | "gray"
  | "blond"
  | "brown"
  | "red"
  | "black"
  | "other";
/** Defines values for AccessoryType. */
export type AccessoryType = "headWear" | "glasses" | "mask";
/** Defines values for BlurLevel. */
export type BlurLevel = "Low" | "Medium" | "High";
/** Defines values for ExposureLevel. */
export type ExposureLevel = "UnderExposure" | "GoodExposure" | "OverExposure";
/** Defines values for NoiseLevel. */
export type NoiseLevel = "Low" | "Medium" | "High";
/** Defines values for MaskType. */
export type MaskType =
  | "noMask"
  | "faceMask"
  | "otherMaskOrOcclusion"
  | "uncertain";
/** Defines values for QualityForRecognition. */
export type QualityForRecognition = "Low" | "Medium" | "High";
/** Defines values for SnapshotObjectType. */
export type SnapshotObjectType =
  | "FaceList"
  | "LargeFaceList"
  | "LargePersonGroup"
  | "PersonGroup";
/** Defines values for OperationStatusType. */
export type OperationStatusType =
  | "notstarted"
  | "running"
  | "succeeded"
  | "failed";

/** Optional parameters. */
export interface FaceFindSimilarOptionalParams
  extends coreClient.OperationOptions {
  /** An existing user-specified unique candidate face list, created in Face List - Create a Face List. Face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  faceListId?: string;
  /** An existing user-specified unique candidate large face list, created in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  largeFaceListId?: string;
  /** An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will expire at the time specified by faceIdTimeToLive after the detection call. The number of faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time. */
  faceIds?: string[];
  /** The number of top similar faces returned. The valid range is [1, 1000]. */
  maxNumOfCandidatesReturned?: number;
  /** Similar face searching mode. It can be "matchPerson" or "matchFace". */
  mode?: FindSimilarMatchMode;
}

/** Contains response data for the findSimilar operation. */
export type FaceFindSimilarResponse = SimilarFace[];

/** Optional parameters. */
export interface FaceGroupOptionalParams extends coreClient.OperationOptions {}

/** Contains response data for the group operation. */
export type FaceGroupResponse = GroupResult;

/** Optional parameters. */
export interface FaceIdentifyOptionalParams
  extends coreClient.OperationOptions {
  /** PersonGroupId of the target person group, created by PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  personGroupId?: string;
  /** LargePersonGroupId of the target large person group, created by LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  largePersonGroupId?: string;
  /** The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 1). */
  maxNumOfCandidatesReturned?: number;
  /** Confidence threshold of identification, used to judge whether one face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by algorithm). */
  confidenceThreshold?: number;
}

/** Contains response data for the identify operation. */
export type FaceIdentifyResponse = IdentifyResult[];

/** Optional parameters. */
export interface FaceVerifyFaceToFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the verifyFaceToFace operation. */
export type FaceVerifyFaceToFaceResponse = VerifyResult;

/** Optional parameters. */
export interface FaceDetectWithUrlOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return faceIds of detected faces. */
  returnFaceId?: boolean;
  /** A value indicating whether the operation should return landmarks of the detected faces. */
  returnFaceLandmarks?: boolean;
  /** Analyze and return the one or more specified face attributes in the comma-separated string like "returnFaceAttributes=age,gender". The available attributes depends on the 'detectionModel' specified. 'detection_01' supports age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, noise, and qualityForRecognition. While 'detection_02' does not support any attributes and 'detection_03' only supports mask and qualityForRecognition. Additionally, qualityForRecognition is only supported when the 'recognitionModel' is specified as 'recognition_03' or 'recognition_04'. Note that each face attribute analysis has additional computational and time cost. */
  returnFaceAttributes?: FaceAttributeType[];
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** The number of seconds for the faceId being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). */
  faceIdTimeToLive?: number;
}

/** Contains response data for the detectWithUrl operation. */
export type FaceDetectWithUrlResponse = DetectedFace[];

/** Optional parameters. */
export interface FaceVerifyFaceToPersonOptionalParams
  extends coreClient.OperationOptions {
  /** Using existing personGroupId and personId for fast loading a specified person. personGroupId is created in PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  personGroupId?: string;
  /** Using existing largePersonGroupId and personId for fast loading a specified person. largePersonGroupId is created in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time. */
  largePersonGroupId?: string;
}

/** Contains response data for the verifyFaceToPerson operation. */
export type FaceVerifyFaceToPersonResponse = VerifyResult;

/** Optional parameters. */
export interface FaceDetectWithStreamOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return faceIds of detected faces. */
  returnFaceId?: boolean;
  /** A value indicating whether the operation should return landmarks of the detected faces. */
  returnFaceLandmarks?: boolean;
  /** Analyze and return the one or more specified face attributes in the comma-separated string like "returnFaceAttributes=age,gender". The available attributes depends on the 'detectionModel' specified. 'detection_01' supports age, gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, noise, and qualityForRecognition. While 'detection_02' does not support any attributes and 'detection_03' only supports mask and qualityForRecognition. Additionally, qualityForRecognition is only supported when the 'recognitionModel' is specified as 'recognition_03' or 'recognition_04'. Note that each face attribute analysis has additional computational and time cost. */
  returnFaceAttributes?: FaceAttributeType[];
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** The number of seconds for the faceId being cached. Supported range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours). */
  faceIdTimeToLive?: number;
}

/** Contains response data for the detectWithStream operation. */
export type FaceDetectWithStreamResponse = DetectedFace[];

/** Optional parameters. */
export interface PersonGroupPersonCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Contains response data for the create operation. */
export type PersonGroupPersonCreateResponse = Person;

/** Optional parameters. */
export interface PersonGroupPersonListOptionalParams
  extends coreClient.OperationOptions {
  /** Starting person id to return (used to list a range of persons). */
  start?: string;
  /** Number of persons to return starting with the person id indicated by the 'start' parameter. */
  top?: number;
}

/** Contains response data for the list operation. */
export type PersonGroupPersonListResponse = Person[];

/** Optional parameters. */
export interface PersonGroupPersonDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface PersonGroupPersonGetOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the get operation. */
export type PersonGroupPersonGetResponse = Person;

/** Optional parameters. */
export interface PersonGroupPersonUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface PersonGroupPersonDeleteFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface PersonGroupPersonGetFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getFace operation. */
export type PersonGroupPersonGetFaceResponse = PersistedFace;

/** Optional parameters. */
export interface PersonGroupPersonUpdateFaceOptionalParams
  extends coreClient.OperationOptions {
  /** User-provided data attached to the face. The size limit is 1KB. */
  userData?: string;
}

/** Optional parameters. */
export interface PersonGroupPersonAddFaceFromUrlOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromUrl operation. */
export type PersonGroupPersonAddFaceFromUrlResponse = PersistedFace;

/** Optional parameters. */
export interface PersonGroupPersonAddFaceFromStreamOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromStream operation. */
export type PersonGroupPersonAddFaceFromStreamResponse = PersistedFace;

/** Optional parameters. */
export interface PersonGroupCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Optional parameters. */
export interface PersonGroupDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface PersonGroupGetOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
}

/** Contains response data for the get operation. */
export type PersonGroupGetResponse = PersonGroup;

/** Optional parameters. */
export interface PersonGroupUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface PersonGroupGetTrainingStatusOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getTrainingStatus operation. */
export type PersonGroupGetTrainingStatusResponse = TrainingStatus;

/** Optional parameters. */
export interface PersonGroupListOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
  /** List person groups from the least personGroupId greater than the "start". */
  start?: string;
  /** The number of person groups to list. */
  top?: number;
}

/** Contains response data for the list operation. */
export type PersonGroupListResponse = PersonGroup[];

/** Optional parameters. */
export interface PersonGroupTrainOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface FaceListCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Optional parameters. */
export interface FaceListGetOptionalParams extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
}

/** Contains response data for the get operation. */
export type FaceListGetResponse = FaceList;

/** Optional parameters. */
export interface FaceListUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface FaceListDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface FaceListListOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
}

/** Contains response data for the list operation. */
export type FaceListListResponse = FaceList[];

/** Optional parameters. */
export interface FaceListDeleteFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface FaceListAddFaceFromUrlOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromUrl operation. */
export type FaceListAddFaceFromUrlResponse = PersistedFace;

/** Optional parameters. */
export interface FaceListAddFaceFromStreamOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromStream operation. */
export type FaceListAddFaceFromStreamResponse = PersistedFace;

/** Optional parameters. */
export interface LargePersonGroupPersonCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Contains response data for the create operation. */
export type LargePersonGroupPersonCreateResponse = Person;

/** Optional parameters. */
export interface LargePersonGroupPersonListOptionalParams
  extends coreClient.OperationOptions {
  /** Starting person id to return (used to list a range of persons). */
  start?: string;
  /** Number of persons to return starting with the person id indicated by the 'start' parameter. */
  top?: number;
}

/** Contains response data for the list operation. */
export type LargePersonGroupPersonListResponse = Person[];

/** Optional parameters. */
export interface LargePersonGroupPersonDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargePersonGroupPersonGetOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the get operation. */
export type LargePersonGroupPersonGetResponse = Person;

/** Optional parameters. */
export interface LargePersonGroupPersonUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface LargePersonGroupPersonDeleteFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargePersonGroupPersonGetFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getFace operation. */
export type LargePersonGroupPersonGetFaceResponse = PersistedFace;

/** Optional parameters. */
export interface LargePersonGroupPersonUpdateFaceOptionalParams
  extends coreClient.OperationOptions {
  /** User-provided data attached to the face. The size limit is 1KB. */
  userData?: string;
}

/** Optional parameters. */
export interface LargePersonGroupPersonAddFaceFromUrlOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromUrl operation. */
export type LargePersonGroupPersonAddFaceFromUrlResponse = PersistedFace;

/** Optional parameters. */
export interface LargePersonGroupPersonAddFaceFromStreamOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromStream operation. */
export type LargePersonGroupPersonAddFaceFromStreamResponse = PersistedFace;

/** Optional parameters. */
export interface LargePersonGroupCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Optional parameters. */
export interface LargePersonGroupDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargePersonGroupGetOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
}

/** Contains response data for the get operation. */
export type LargePersonGroupGetResponse = LargePersonGroup;

/** Optional parameters. */
export interface LargePersonGroupUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface LargePersonGroupGetTrainingStatusOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getTrainingStatus operation. */
export type LargePersonGroupGetTrainingStatusResponse = TrainingStatus;

/** Optional parameters. */
export interface LargePersonGroupListOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
  /** List large person groups from the least largePersonGroupId greater than the "start". */
  start?: string;
  /** The number of large person groups to list. */
  top?: number;
}

/** Contains response data for the list operation. */
export type LargePersonGroupListResponse = LargePersonGroup[];

/** Optional parameters. */
export interface LargePersonGroupTrainOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargeFaceListCreateOptionalParams
  extends coreClient.OperationOptions {
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
  /** Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed, please explicitly specify the model you need. */
  recognitionModel?: RecognitionModel;
}

/** Optional parameters. */
export interface LargeFaceListGetOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
}

/** Contains response data for the get operation. */
export type LargeFaceListGetResponse = LargeFaceList;

/** Optional parameters. */
export interface LargeFaceListUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** User defined name, maximum length is 128. */
  name?: string;
  /** User specified data. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface LargeFaceListDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargeFaceListGetTrainingStatusOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getTrainingStatus operation. */
export type LargeFaceListGetTrainingStatusResponse = TrainingStatus;

/** Optional parameters. */
export interface LargeFaceListListOptionalParams
  extends coreClient.OperationOptions {
  /** A value indicating whether the operation should return 'recognitionModel' in response. */
  returnRecognitionModel?: boolean;
  /** Starting large face list id to return (used to list a range of large face lists). */
  start?: string;
  /** Number of large face lists to return starting with the large face list id indicated by the 'start' parameter. */
  top?: number;
}

/** Contains response data for the list operation. */
export type LargeFaceListListResponse = LargeFaceList[];

/** Optional parameters. */
export interface LargeFaceListTrainOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargeFaceListDeleteFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface LargeFaceListGetFaceOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getFace operation. */
export type LargeFaceListGetFaceResponse = PersistedFace;

/** Optional parameters. */
export interface LargeFaceListUpdateFaceOptionalParams
  extends coreClient.OperationOptions {
  /** User-provided data attached to the face. The size limit is 1KB. */
  userData?: string;
}

/** Optional parameters. */
export interface LargeFaceListAddFaceFromUrlOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromUrl operation. */
export type LargeFaceListAddFaceFromUrlResponse = PersistedFace;

/** Optional parameters. */
export interface LargeFaceListListFacesOptionalParams
  extends coreClient.OperationOptions {
  /** Starting face id to return (used to list a range of faces). */
  start?: string;
  /** Number of faces to return starting with the face id indicated by the 'start' parameter. */
  top?: number;
}

/** Contains response data for the listFaces operation. */
export type LargeFaceListListFacesResponse = PersistedFace[];

/** Optional parameters. */
export interface LargeFaceListAddFaceFromStreamOptionalParams
  extends coreClient.OperationOptions {
  /** Name of detection model. Detection model is used to detect faces in the submitted image. A detection model name can be provided when performing Face - Detect or (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model is needed, please explicitly specify it. */
  detectionModel?: DetectionModel;
  /** User-specified data about the face for any purpose. The maximum length is 1KB. */
  userData?: string;
  /** A face rectangle to specify the target face to be added to a person in the format of "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one face in the image, targetFace is required to specify which face to add. No targetFace means there is only one face detected in the entire image. */
  targetFace?: number[];
}

/** Contains response data for the addFaceFromStream operation. */
export type LargeFaceListAddFaceFromStreamResponse = PersistedFace;

/** Optional parameters. */
export interface SnapshotTakeOptionalParams
  extends coreClient.OperationOptions {
  /** User specified data about the snapshot for any purpose. Length should not exceed 16KB. */
  userData?: string;
}

/** Contains response data for the take operation. */
export type SnapshotTakeResponse = SnapshotTakeHeaders;

/** Optional parameters. */
export interface SnapshotListOptionalParams
  extends coreClient.OperationOptions {
  /** User specified object type as a search filter. */
  typeParam?: SnapshotObjectType;
  /** User specified snapshot apply scopes as a search filter. ApplyScope is an array of the target Azure subscription ids for the snapshot, specified by the user who created the snapshot by Snapshot - Take. */
  applyScope?: string[];
}

/** Contains response data for the list operation. */
export type SnapshotListResponse = Snapshot[];

/** Optional parameters. */
export interface SnapshotGetOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the get operation. */
export type SnapshotGetResponse = Snapshot;

/** Optional parameters. */
export interface SnapshotUpdateOptionalParams
  extends coreClient.OperationOptions {
  /** Array of the target Face subscription ids for the snapshot, specified by the user who created the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in the applyScope of Snapshot - Take can apply it. */
  applyScope?: string[];
  /** User specified data about the snapshot for any purpose. Length should not exceed 16KB. */
  userData?: string;
}

/** Optional parameters. */
export interface SnapshotDeleteOptionalParams
  extends coreClient.OperationOptions {}

/** Optional parameters. */
export interface SnapshotApplyOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the apply operation. */
export type SnapshotApplyResponse = SnapshotApplyHeaders;

/** Optional parameters. */
export interface SnapshotGetOperationStatusOptionalParams
  extends coreClient.OperationOptions {}

/** Contains response data for the getOperationStatus operation. */
export type SnapshotGetOperationStatusResponse = OperationStatus;

/** Optional parameters. */
export interface FaceClientOptionalParams
  extends coreClient.ServiceClientOptions {
  /** Overrides client endpoint. */
  endpoint?: string;
}
