/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */


import * as msRest from "@azure/ms-rest-js";

/**
 * Error body.
 */
export interface ErrorModel {
  code?: string;
  message?: string;
}

/**
 * Error information returned by the API
 */
export interface APIError {
  error?: ErrorModel;
}

/**
 * A rectangle within which a face can be found
 */
export interface FaceRectangle {
  /**
   * The width of the rectangle, in pixels.
   */
  width: number;
  /**
   * The height of the rectangle, in pixels.
   */
  height: number;
  /**
   * The distance from the left edge if the image to the left edge of the rectangle, in pixels.
   */
  left: number;
  /**
   * The distance from the top edge if the image to the top edge of the rectangle, in pixels.
   */
  top: number;
}

/**
 * Coordinates within an image
 */
export interface Coordinate {
  /**
   * The horizontal component, in pixels.
   */
  x: number;
  /**
   * The vertical component, in pixels.
   */
  y: number;
}

/**
 * A collection of 27-point face landmarks pointing to the important positions of face components.
 */
export interface FaceLandmarks {
  pupilLeft?: Coordinate;
  pupilRight?: Coordinate;
  noseTip?: Coordinate;
  mouthLeft?: Coordinate;
  mouthRight?: Coordinate;
  eyebrowLeftOuter?: Coordinate;
  eyebrowLeftInner?: Coordinate;
  eyeLeftOuter?: Coordinate;
  eyeLeftTop?: Coordinate;
  eyeLeftBottom?: Coordinate;
  eyeLeftInner?: Coordinate;
  eyebrowRightInner?: Coordinate;
  eyebrowRightOuter?: Coordinate;
  eyeRightInner?: Coordinate;
  eyeRightTop?: Coordinate;
  eyeRightBottom?: Coordinate;
  eyeRightOuter?: Coordinate;
  noseRootLeft?: Coordinate;
  noseRootRight?: Coordinate;
  noseLeftAlarTop?: Coordinate;
  noseRightAlarTop?: Coordinate;
  noseLeftAlarOutTip?: Coordinate;
  noseRightAlarOutTip?: Coordinate;
  upperLipTop?: Coordinate;
  upperLipBottom?: Coordinate;
  underLipTop?: Coordinate;
  underLipBottom?: Coordinate;
}

/**
 * Properties describing facial hair attributes.
 */
export interface FacialHair {
  moustache?: number;
  beard?: number;
  sideburns?: number;
}

/**
 * Properties indicating head pose of the face.
 */
export interface HeadPose {
  roll?: number;
  yaw?: number;
  pitch?: number;
}

/**
 * Properties describing facial emotion in form of confidence ranging from 0 to 1.
 */
export interface Emotion {
  anger?: number;
  contempt?: number;
  disgust?: number;
  fear?: number;
  happiness?: number;
  neutral?: number;
  sadness?: number;
  surprise?: number;
}

/**
 * Hair color and associated confidence
 */
export interface HairColor {
  /**
   * Name of the hair color. Possible values include: 'unknown', 'white', 'gray', 'blond', 'brown',
   * 'red', 'black', 'other'
   */
  color?: HairColorType;
  /**
   * Confidence level of the color
   */
  confidence?: number;
}

/**
 * Properties describing hair attributes.
 */
export interface Hair {
  /**
   * A number describing confidence level of whether the person is bald.
   */
  bald?: number;
  /**
   * A boolean value describing whether the hair is visible in the image.
   */
  invisible?: boolean;
  /**
   * An array of candidate colors and confidence level in the presence of each.
   */
  hairColor?: HairColor[];
}

/**
 * Properties describing the presence of makeup on a given face.
 */
export interface Makeup {
  /**
   * A boolean value describing whether eye makeup is present on a face.
   */
  eyeMakeup?: boolean;
  /**
   * A boolean value describing whether lip makeup is present on a face.
   */
  lipMakeup?: boolean;
}

/**
 * Properties describing occlusions on a given face.
 */
export interface Occlusion {
  /**
   * A boolean value indicating whether forehead is occluded.
   */
  foreheadOccluded?: boolean;
  /**
   * A boolean value indicating whether eyes are occluded.
   */
  eyeOccluded?: boolean;
  /**
   * A boolean value indicating whether the mouth is occluded.
   */
  mouthOccluded?: boolean;
}

/**
 * Accessory item and corresponding confidence level.
 */
export interface Accessory {
  /**
   * Type of an accessory. Possible values include: 'headWear', 'glasses', 'mask'
   */
  type?: AccessoryType;
  /**
   * Confidence level of an accessory
   */
  confidence?: number;
}

/**
 * Properties describing any presence of blur within the image.
 */
export interface Blur {
  /**
   * An enum value indicating level of blurriness. Possible values include: 'Low', 'Medium', 'High'
   */
  blurLevel?: BlurLevel;
  /**
   * A number indicating level of blurriness ranging from 0 to 1.
   */
  value?: number;
}

/**
 * Properties describing exposure level of the image.
 */
export interface Exposure {
  /**
   * An enum value indicating level of exposure. Possible values include: 'UnderExposure',
   * 'GoodExposure', 'OverExposure'
   */
  exposureLevel?: ExposureLevel;
  /**
   * A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure.
   * [0.25, 0.75) is good exposure. [0.75, 1] is over exposure.
   */
  value?: number;
}

/**
 * Properties describing noise level of the image.
 */
export interface Noise {
  /**
   * An enum value indicating level of noise. Possible values include: 'Low', 'Medium', 'High'
   */
  noiseLevel?: NoiseLevel;
  /**
   * A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure.
   * [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3,
   * 0.7) is medium noise level. [0.7, 1] is high noise level.
   */
  value?: number;
}

/**
 * Properties describing the presence of a mask on a given face.
 */
export interface Mask {
  /**
   * Mask type if any of the face. Possible values include: 'noMask', 'faceMask',
   * 'otherMaskOrOcclusion', 'uncertain'
   */
  type?: MaskType;
  /**
   * A boolean value indicating whether nose and mouth are covered.
   */
  noseAndMouthCovered?: boolean;
}

/**
 * Face Attributes
 */
export interface FaceAttributes {
  /**
   * Age in years
   */
  age?: number;
  /**
   * Possible gender of the face. Possible values include: 'male', 'female'
   */
  gender?: Gender;
  /**
   * Smile intensity, a number between [0,1]
   */
  smile?: number;
  /**
   * Properties describing facial hair attributes.
   */
  facialHair?: FacialHair;
  /**
   * Glasses type if any of the face. Possible values include: 'noGlasses', 'readingGlasses',
   * 'sunglasses', 'swimmingGoggles'
   */
  glasses?: GlassesType;
  /**
   * Properties indicating head pose of the face.
   */
  headPose?: HeadPose;
  /**
   * Properties describing facial emotion in form of confidence ranging from 0 to 1.
   */
  emotion?: Emotion;
  /**
   * Properties describing hair attributes.
   */
  hair?: Hair;
  /**
   * Properties describing the presence of makeup on a given face.
   */
  makeup?: Makeup;
  /**
   * Properties describing occlusions on a given face.
   */
  occlusion?: Occlusion;
  /**
   * Properties describing any accessories on a given face.
   */
  accessories?: Accessory[];
  /**
   * Properties describing any presence of blur within the image.
   */
  blur?: Blur;
  /**
   * Properties describing exposure level of the image.
   */
  exposure?: Exposure;
  /**
   * Properties describing noise level of the image.
   */
  noise?: Noise;
  /**
   * Properties describing the presence of a mask on a given face.
   */
  mask?: Mask;
  /**
   * Properties describing the overall image quality regarding whether the image being used in the
   * detection is of sufficient quality to attempt face recognition on. Possible values include:
   * 'Low', 'Medium', 'High'
   */
  qualityForRecognition?: QualityForRecognition;
}

/**
 * Detected Face object.
 */
export interface DetectedFace {
  faceId?: string;
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
  faceRectangle: FaceRectangle;
  faceLandmarks?: FaceLandmarks;
  faceAttributes?: FaceAttributes;
}

/**
 * Request body for find similar operation.
 */
export interface FindSimilarRequest {
  /**
   * FaceId of the query face. User needs to call Face - Detect first to get a valid faceId. Note
   * that this faceId is not persisted and will expire at the time specified by faceIdTimeToLive
   * after the detection call
   */
  faceId: string;
  /**
   * An existing user-specified unique candidate face list, created in Face List - Create a Face
   * List. Face list contains a set of persistedFaceIds which are persisted and will never expire.
   * Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time.
   */
  faceListId?: string;
  /**
   * An existing user-specified unique candidate large face list, created in LargeFaceList -
   * Create. Large face list contains a set of persistedFaceIds which are persisted and will never
   * expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same
   * time.
   */
  largeFaceListId?: string;
  /**
   * An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will
   * expire at the time specified by faceIdTimeToLive after the detection call. The number of
   * faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should not be
   * provided at the same time.
   */
  faceIds?: string[];
  /**
   * The number of top similar faces returned. The valid range is [1, 1000]. Default value: 20.
   */
  maxNumOfCandidatesReturned?: number;
  /**
   * Similar face searching mode. It can be "matchPerson" or "matchFace". Possible values include:
   * 'matchPerson', 'matchFace'. Default value: 'matchPerson'.
   */
  mode?: FindSimilarMatchMode;
}

/**
 * Response body for find similar face operation.
 */
export interface SimilarFace {
  /**
   * FaceId of candidate face when find by faceIds. faceId is created by Face - Detect and will
   * expire at the time specified by faceIdTimeToLive after the detection call
   */
  faceId?: string;
  /**
   * PersistedFaceId of candidate face when find by faceListId. persistedFaceId in face list is
   * persisted and will not expire. As showed in below response
   */
  persistedFaceId?: string;
  /**
   * Similarity confidence of the candidate face. The higher confidence, the more similar. Range
   * between [0,1].
   */
  confidence: number;
}

/**
 * Request body for group request.
 */
export interface GroupRequest {
  /**
   * Array of candidate faceId created by Face - Detect. The maximum is 1000 faces
   */
  faceIds: string[];
}

/**
 * An array of face groups based on face similarity.
 */
export interface GroupResult {
  /**
   * A partition of the original faces based on face similarity. Groups are ranked by number of
   * faces
   */
  groups: string[][];
  /**
   * Face ids array of faces that cannot find any similar faces from original faces.
   */
  messyGroup?: string[];
}

/**
 * Request body for identify face operation.
 */
export interface IdentifyRequest {
  /**
   * Array of query faces faceIds, created by the Face - Detect. Each of the faces are identified
   * independently. The valid number of faceIds is between [1, 10].
   */
  faceIds: string[];
  /**
   * PersonGroupId of the target person group, created by PersonGroup - Create. Parameter
   * personGroupId and largePersonGroupId should not be provided at the same time.
   */
  personGroupId?: string;
  /**
   * LargePersonGroupId of the target large person group, created by LargePersonGroup - Create.
   * Parameter personGroupId and largePersonGroupId should not be provided at the same time.
   */
  largePersonGroupId?: string;
  /**
   * The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 1). Default value: 1.
   */
  maxNumOfCandidatesReturned?: number;
  /**
   * Confidence threshold of identification, used to judge whether one face belong to one person.
   * The range of confidenceThreshold is [0, 1] (default specified by algorithm).
   */
  confidenceThreshold?: number;
}

/**
 * All possible faces that may qualify.
 */
export interface IdentifyCandidate {
  /**
   * Id of candidate
   */
  personId: string;
  /**
   * Confidence threshold of identification, used to judge whether one face belong to one person.
   * The range of confidenceThreshold is [0, 1] (default specified by algorithm).
   */
  confidence: number;
}

/**
 * Response body for identify face operation.
 */
export interface IdentifyResult {
  /**
   * FaceId of the query face
   */
  faceId: string;
  /**
   * Identified person candidates for that face (ranked by confidence). Array size should be no
   * larger than input maxNumOfCandidatesReturned. If no person is identified, will return an empty
   * array.
   */
  candidates: IdentifyCandidate[];
}

/**
 * Request body for face to person verification.
 */
export interface VerifyFaceToPersonRequest {
  /**
   * FaceId of the face, comes from Face - Detect
   */
  faceId: string;
  /**
   * Using existing personGroupId and personId for fast loading a specified person. personGroupId
   * is created in PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not
   * be provided at the same time.
   */
  personGroupId?: string;
  /**
   * Using existing largePersonGroupId and personId for fast loading a specified person.
   * largePersonGroupId is created in LargePersonGroup - Create. Parameter personGroupId and
   * largePersonGroupId should not be provided at the same time.
   */
  largePersonGroupId?: string;
  /**
   * Specify a certain person in a person group or a large person group. personId is created in
   * PersonGroup Person - Create or LargePersonGroup Person - Create.
   */
  personId: string;
}

/**
 * Request body for face to face verification.
 */
export interface VerifyFaceToFaceRequest {
  /**
   * FaceId of the first face, comes from Face - Detect
   */
  faceId1: string;
  /**
   * FaceId of the second face, comes from Face - Detect
   */
  faceId2: string;
}

/**
 * Result of the verify operation.
 */
export interface VerifyResult {
  /**
   * True if the two faces belong to the same person or the face belongs to the person, otherwise
   * false.
   */
  isIdentical: boolean;
  /**
   * A number indicates the similarity confidence of whether two faces belong to the same person,
   * or whether the face belongs to the person. By default, isIdentical is set to True if
   * similarity confidence is greater than or equal to 0.5. This is useful for advanced users to
   * override "isIdentical" and fine-tune the result on their own data.
   */
  confidence: number;
}

/**
 * PersonFace object.
 */
export interface PersistedFace {
  /**
   * The persistedFaceId of the target face, which is persisted and will not expire. Different from
   * faceId created by Face - Detect and will expire in at the time specified by faceIdTimeToLive
   * after the detection call.
   */
  persistedFaceId: string;
  /**
   * User-provided data attached to the face. The size limit is 1KB.
   */
  userData?: string;
}

/**
 * A combination of user defined name and user specified data for the person,
 * largePersonGroup/personGroup, and largeFaceList/faceList.
 */
export interface NonNullableNameAndNullableUserDataContract {
  /**
   * User defined name, maximum length is 128.
   */
  name: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * A combination of user defined name and user specified data and recognition model name for
 * largePersonGroup/personGroup, and largeFaceList/faceList.
 */
export interface MetaDataContract extends NonNullableNameAndNullableUserDataContract {
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
}

/**
 * Face list object.
 */
export interface FaceList extends MetaDataContract {
  /**
   * FaceListId of the target face list.
   */
  faceListId: string;
  /**
   * Persisted faces within the face list.
   */
  persistedFaces?: PersistedFace[];
}

/**
 * Person group object.
 */
export interface PersonGroup extends MetaDataContract {
  /**
   * PersonGroupId of the target person group.
   */
  personGroupId: string;
}

/**
 * A combination of user defined name and user specified data for the person,
 * largePersonGroup/personGroup, and largeFaceList/faceList.
 */
export interface NameAndUserDataContract {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Person object.
 */
export interface Person extends NameAndUserDataContract {
  /**
   * PersonId of the target face list.
   */
  personId: string;
  /**
   * PersistedFaceIds of registered faces in the person. These persistedFaceIds are returned from
   * Person - Add a Person Face, and will not expire.
   */
  persistedFaceIds?: string[];
}

/**
 * Large face list object.
 */
export interface LargeFaceList extends MetaDataContract {
  /**
   * LargeFaceListId of the target large face list.
   */
  largeFaceListId: string;
}

/**
 * Large person group object.
 */
export interface LargePersonGroup extends MetaDataContract {
  /**
   * LargePersonGroupId of the target large person groups
   */
  largePersonGroupId: string;
}

/**
 * Request to update face data.
 */
export interface UpdateFaceRequest {
  /**
   * User-provided data attached to the face. The size limit is 1KB.
   */
  userData?: string;
}

/**
 * Training status object.
 */
export interface TrainingStatus {
  /**
   * Training status: notstarted, running, succeeded, failed. If the training process is waiting to
   * perform, the status is notstarted. If the training is ongoing, the status is running. Status
   * succeed means this person group or large person group is ready for Face - Identify, or this
   * large face list is ready for Face - Find Similar. Status failed is often caused by no person
   * or no persisted face exist in the person group or large person group, or no persisted face
   * exist in the large face list. Possible values include: 'nonstarted', 'running', 'succeeded',
   * 'failed'
   */
  status: TrainingStatusType;
  /**
   * A combined UTC date and time string that describes the created time of the person group, large
   * person group or large face list.
   */
  created: Date;
  /**
   * A combined UTC date and time string that describes the last modify time of the person group,
   * large person group or large face list, could be null value when the group is not successfully
   * trained.
   */
  lastAction?: Date;
  /**
   * A combined UTC date and time string that describes the last successful training time of the
   * person group, large person group or large face list.
   */
  lastSuccessfulTraining?: Date;
  /**
   * Show failure message when training failed (omitted when training succeed).
   */
  message?: string;
}

/**
 * Request body for applying snapshot operation.
 */
export interface ApplySnapshotRequest {
  /**
   * User specified target object id to be created from the snapshot.
   */
  objectId: string;
  /**
   * Snapshot applying mode. Currently only CreateNew is supported, which means the apply operation
   * will fail if target subscription already contains an object of same type and using the same
   * objectId. Users can specify the "objectId" in request body to avoid such conflicts. Possible
   * values include: 'CreateNew'. Default value: 'CreateNew'.
   */
  mode?: SnapshotApplyMode;
}

/**
 * Snapshot object.
 */
export interface Snapshot {
  /**
   * Snapshot id.
   */
  id: string;
  /**
   * Azure Cognitive Service Face account id of the subscriber who created the snapshot by Snapshot
   * - Take.
   */
  account: string;
  /**
   * Type of the source object in the snapshot, specified by the subscriber who created the
   * snapshot when calling Snapshot - Take. Currently FaceList, PersonGroup, LargeFaceList and
   * LargePersonGroup are supported. Possible values include: 'FaceList', 'LargeFaceList',
   * 'LargePersonGroup', 'PersonGroup'
   */
  type: SnapshotObjectType;
  /**
   * Array of the target Face subscription ids for the snapshot, specified by the user who created
   * the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in
   * the applyScope of Snapshot - Take can apply it.
   */
  applyScope: string[];
  /**
   * User specified data about the snapshot for any purpose. Length should not exceed 16KB.
   */
  userData?: string;
  /**
   * A combined UTC date and time string that describes the created time of the snapshot. E.g.
   * 2018-12-25T11:41:02.2331413Z.
   */
  createdTime: Date;
  /**
   * A combined UTC date and time string that describes the last time when the snapshot was created
   * or updated by Snapshot - Update. E.g. 2018-12-25T11:51:27.8705696Z.
   */
  lastUpdateTime: Date;
}

/**
 * Request body for taking snapshot operation.
 */
export interface TakeSnapshotRequest {
  /**
   * User specified type for the source object to take snapshot from. Currently FaceList,
   * PersonGroup, LargeFaceList and LargePersonGroup are supported. Possible values include:
   * 'FaceList', 'LargeFaceList', 'LargePersonGroup', 'PersonGroup'
   */
  type: SnapshotObjectType;
  /**
   * User specified source object id to take snapshot from.
   */
  objectId: string;
  /**
   * User specified array of target Face subscription ids for the snapshot. For each snapshot, only
   * subscriptions included in the applyScope of Snapshot - Take can apply it.
   */
  applyScope: string[];
  /**
   * User specified data about the snapshot for any purpose. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Request body for updating a snapshot, with a combination of user defined apply scope and user
 * specified data.
 */
export interface UpdateSnapshotRequest {
  /**
   * Array of the target Face subscription ids for the snapshot, specified by the user who created
   * the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in
   * the applyScope of Snapshot - Take can apply it.
   */
  applyScope?: string[];
  /**
   * User specified data about the snapshot for any purpose. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Operation status object. Operation refers to the asynchronous backend task including taking a
 * snapshot and applying a snapshot.
 */
export interface OperationStatus {
  /**
   * Operation status: notstarted, running, succeeded, failed. If the operation is requested and
   * waiting to perform, the status is notstarted. If the operation is ongoing in backend, the
   * status is running. Status succeeded means the operation is completed successfully,
   * specifically for snapshot taking operation, it illustrates the snapshot is well taken and
   * ready to apply, and for snapshot applying operation, it presents the target object has
   * finished creating by the snapshot and ready to be used. Status failed is often caused by
   * editing the source object while taking the snapshot or editing the target object while
   * applying the snapshot before completion, see the field "message" to check the failure reason.
   * Possible values include: 'notstarted', 'running', 'succeeded', 'failed'
   */
  status: OperationStatusType;
  /**
   * A combined UTC date and time string that describes the time when the operation (take or apply
   * a snapshot) is requested. E.g. 2018-12-25T11:41:02.2331413Z.
   */
  createdTime: Date;
  /**
   * A combined UTC date and time string that describes the last time the operation (take or apply
   * a snapshot) is actively migrating data. The lastActionTime will keep increasing until the
   * operation finishes. E.g. 2018-12-25T11:51:27.8705696Z.
   */
  lastActionTime?: Date;
  /**
   * When the operation succeeds successfully, for snapshot taking operation the snapshot id will
   * be included in this field, and for snapshot applying operation, the path to get the target
   * object will be returned in this field.
   */
  resourceLocation?: string;
  /**
   * Show failure message when operation fails (omitted when operation succeeds).
   */
  message?: string;
}

/**
 * An interface representing ImageUrl.
 */
export interface ImageUrl {
  /**
   * Publicly reachable URL of an image
   */
  url: string;
}

/**
 * Optional Parameters.
 */
export interface FaceFindSimilarOptionalParams extends msRest.RequestOptionsBase {
  /**
   * An existing user-specified unique candidate face list, created in Face List - Create a Face
   * List. Face list contains a set of persistedFaceIds which are persisted and will never expire.
   * Parameter faceListId, largeFaceListId and faceIds should not be provided at the same time.
   */
  faceListId?: string;
  /**
   * An existing user-specified unique candidate large face list, created in LargeFaceList -
   * Create. Large face list contains a set of persistedFaceIds which are persisted and will never
   * expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at the same
   * time.
   */
  largeFaceListId?: string;
  /**
   * An array of candidate faceIds. All of them are created by Face - Detect and the faceIds will
   * expire at the time specified by faceIdTimeToLive after the detection call. The number of
   * faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should not be
   * provided at the same time.
   */
  faceIds?: string[];
  /**
   * The number of top similar faces returned. The valid range is [1, 1000]. Default value: 20.
   */
  maxNumOfCandidatesReturned?: number;
  /**
   * Similar face searching mode. It can be "matchPerson" or "matchFace". Possible values include:
   * 'matchPerson', 'matchFace'. Default value: 'matchPerson'.
   */
  mode?: FindSimilarMatchMode;
}

/**
 * Optional Parameters.
 */
export interface FaceIdentifyOptionalParams extends msRest.RequestOptionsBase {
  /**
   * PersonGroupId of the target person group, created by PersonGroup - Create. Parameter
   * personGroupId and largePersonGroupId should not be provided at the same time.
   */
  personGroupId?: string;
  /**
   * LargePersonGroupId of the target large person group, created by LargePersonGroup - Create.
   * Parameter personGroupId and largePersonGroupId should not be provided at the same time.
   */
  largePersonGroupId?: string;
  /**
   * The range of maxNumOfCandidatesReturned is between 1 and 100 (default is 1). Default value: 1.
   */
  maxNumOfCandidatesReturned?: number;
  /**
   * Confidence threshold of identification, used to judge whether one face belong to one person.
   * The range of confidenceThreshold is [0, 1] (default specified by algorithm).
   */
  confidenceThreshold?: number;
}

/**
 * Optional Parameters.
 */
export interface FaceDetectWithUrlOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return faceIds of detected faces. Default
   * value: true.
   */
  returnFaceId?: boolean;
  /**
   * A value indicating whether the operation should return landmarks of the detected faces.
   * Default value: false.
   */
  returnFaceLandmarks?: boolean;
  /**
   * Analyze and return the one or more specified face attributes in the comma-separated string
   * like "returnFaceAttributes=age,gender". The available attributes depends on the
   * 'detectionModel' specified. 'detection_01' supports age, gender, headPose, smile, facialHair,
   * glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, noise, and
   * qualityForRecognition. While 'detection_02' does not support any attributes and 'detection_03'
   * only supports mask and qualityForRecognition. Additionally, qualityForRecognition is only
   * supported when the 'recognitionModel' is specified as 'recognition_03' or 'recognition_04'.
   * Note that each face attribute analysis has additional computational and time cost.
   */
  returnFaceAttributes?: FaceAttributeType[];
  /**
   * Name of recognition model. Recognition model is used when the face features are extracted and
   * associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model
   * name can be provided when performing Face - Detect or (Large)FaceList - Create or
   * (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed,
   * please explicitly specify the model you need. Possible values include: 'recognition_01',
   * 'recognition_02', 'recognition_03', 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
  /**
   * The number of seconds for the faceId being cached. Supported range from 60 seconds up to 86400
   * seconds. The default value is 86400 (24 hours). Default value: 86400.
   */
  faceIdTimeToLive?: number;
}

/**
 * Optional Parameters.
 */
export interface FaceVerifyFaceToPersonOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Using existing personGroupId and personId for fast loading a specified person. personGroupId
   * is created in PersonGroup - Create. Parameter personGroupId and largePersonGroupId should not
   * be provided at the same time.
   */
  personGroupId?: string;
  /**
   * Using existing largePersonGroupId and personId for fast loading a specified person.
   * largePersonGroupId is created in LargePersonGroup - Create. Parameter personGroupId and
   * largePersonGroupId should not be provided at the same time.
   */
  largePersonGroupId?: string;
}

/**
 * Optional Parameters.
 */
export interface FaceDetectWithStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return faceIds of detected faces. Default
   * value: true.
   */
  returnFaceId?: boolean;
  /**
   * A value indicating whether the operation should return landmarks of the detected faces.
   * Default value: false.
   */
  returnFaceLandmarks?: boolean;
  /**
   * Analyze and return the one or more specified face attributes in the comma-separated string
   * like "returnFaceAttributes=age,gender". The available attributes depends on the
   * 'detectionModel' specified. 'detection_01' supports age, gender, headPose, smile, facialHair,
   * glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, noise, and
   * qualityForRecognition. While 'detection_02' does not support any attributes and 'detection_03'
   * only supports mask and qualityForRecognition. Additionally, qualityForRecognition is only
   * supported when the 'recognitionModel' is specified as 'recognition_03' or 'recognition_04'.
   * Note that each face attribute analysis has additional computational and time cost.
   */
  returnFaceAttributes?: FaceAttributeType[];
  /**
   * Name of recognition model. Recognition model is used when the face features are extracted and
   * associated with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition model
   * name can be provided when performing Face - Detect or (Large)FaceList - Create or
   * (Large)PersonGroup - Create. The default value is 'recognition_01', if latest model needed,
   * please explicitly specify the model you need. Possible values include: 'recognition_01',
   * 'recognition_02', 'recognition_03', 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
  /**
   * The number of seconds for the faceId being cached. Supported range from 60 seconds up to 86400
   * seconds. The default value is 86400 (24 hours). Default value: 86400.
   */
  faceIdTimeToLive?: number;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Starting person id to return (used to list a range of persons).
   */
  start?: string;
  /**
   * Number of persons to return starting with the person id indicated by the 'start' parameter.
   */
  top?: number;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonUpdateFaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-provided data attached to the face. The size limit is 1KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonAddFaceFromUrlOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupPersonAddFaceFromStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupGetOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface PersonGroupListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * List person groups from the least personGroupId greater than the "start".
   */
  start?: string;
  /**
   * The number of person groups to list. Default value: 1000.
   */
  top?: number;
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface FaceListCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
}

/**
 * Optional Parameters.
 */
export interface FaceListGetOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface FaceListUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface FaceListListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface FaceListAddFaceFromUrlOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface FaceListAddFaceFromStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Starting person id to return (used to list a range of persons).
   */
  start?: string;
  /**
   * Number of persons to return starting with the person id indicated by the 'start' parameter.
   */
  top?: number;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonUpdateFaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-provided data attached to the face. The size limit is 1KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonAddFaceFromUrlOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupPersonAddFaceFromStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupGetOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargePersonGroupListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * List large person groups from the least largePersonGroupId greater than the "start".
   */
  start?: string;
  /**
   * The number of large person groups to list. Default value: 1000.
   */
  top?: number;
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListCreateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
  /**
   * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03',
   * 'recognition_04'. Default value: 'recognition_01'.
   */
  recognitionModel?: RecognitionModel;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListGetOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User defined name, maximum length is 128.
   */
  name?: string;
  /**
   * User specified data. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A value indicating whether the operation should return 'recognitionModel' in response. Default
   * value: false.
   */
  returnRecognitionModel?: boolean;
  /**
   * Starting large face list id to return (used to list a range of large face lists).
   */
  start?: string;
  /**
   * Number of large face lists to return starting with the large face list id indicated by the
   * 'start' parameter.
   */
  top?: number;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListUpdateFaceOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-provided data attached to the face. The size limit is 1KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListAddFaceFromUrlOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListListFacesOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Starting face id to return (used to list a range of faces).
   */
  start?: string;
  /**
   * Number of faces to return starting with the face id indicated by the 'start' parameter.
   */
  top?: number;
}

/**
 * Optional Parameters.
 */
export interface LargeFaceListAddFaceFromStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User-specified data about the face for any purpose. The maximum length is 1KB.
   */
  userData?: string;
  /**
   * A face rectangle to specify the target face to be added to a person in the format of
   * "targetFace=left,top,width,height". E.g. "targetFace=10,10,100,100". If there is more than one
   * face in the image, targetFace is required to specify which face to add. No targetFace means
   * there is only one face detected in the entire image.
   */
  targetFace?: number[];
  /**
   * Name of detection model. Detection model is used to detect faces in the submitted image. A
   * detection model name can be provided when performing Face - Detect or (Large)FaceList - Add
   * Face or (Large)PersonGroup - Add Face. The default value is 'detection_01', if another model
   * is needed, please explicitly specify it. Possible values include: 'detection_01',
   * 'detection_02', 'detection_03'. Default value: 'detection_01'.
   */
  detectionModel?: DetectionModel;
}

/**
 * Optional Parameters.
 */
export interface SnapshotTakeOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified data about the snapshot for any purpose. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface SnapshotListOptionalParams extends msRest.RequestOptionsBase {
  /**
   * User specified object type as a search filter. Possible values include: 'FaceList',
   * 'LargeFaceList', 'LargePersonGroup', 'PersonGroup'
   */
  type?: SnapshotObjectType;
  /**
   * User specified snapshot apply scopes as a search filter. ApplyScope is an array of the target
   * Azure subscription ids for the snapshot, specified by the user who created the snapshot by
   * Snapshot - Take.
   */
  applyScope?: string[];
}

/**
 * Optional Parameters.
 */
export interface SnapshotUpdateOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Array of the target Face subscription ids for the snapshot, specified by the user who created
   * the snapshot when calling Snapshot - Take. For each snapshot, only subscriptions included in
   * the applyScope of Snapshot - Take can apply it.
   */
  applyScope?: string[];
  /**
   * User specified data about the snapshot for any purpose. Length should not exceed 16KB.
   */
  userData?: string;
}

/**
 * Optional Parameters.
 */
export interface SnapshotApplyOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Snapshot applying mode. Currently only CreateNew is supported, which means the apply operation
   * will fail if target subscription already contains an object of same type and using the same
   * objectId. Users can specify the "objectId" in request body to avoid such conflicts. Possible
   * values include: 'CreateNew'. Default value: 'CreateNew'.
   */
  mode?: SnapshotApplyMode;
}

/**
 * Defines headers for Take operation.
 */
export interface SnapshotTakeHeaders {
  /**
   * Operation location with an operation id used to track the progress of taking snapshot. The
   * returned id is the operation id, rather than snapshot id. Snapshot id can be obtained only
   * when the operation status becomes "succeeded" in OperationStatus - Get.
   */
  operationLocation: string;
}

/**
 * Defines headers for Apply operation.
 */
export interface SnapshotApplyHeaders {
  /**
   * Operation location with an operation id used to track the progress of applying the snapshot by
   * OperationStatus - Get.
   */
  operationLocation: string;
}

/**
 * Defines values for RecognitionModel.
 * Possible values include: 'recognition_01', 'recognition_02', 'recognition_03', 'recognition_04'
 * @readonly
 * @enum {string}
 */
export type RecognitionModel = 'recognition_01' | 'recognition_02' | 'recognition_03' | 'recognition_04';

/**
 * Defines values for Gender.
 * Possible values include: 'male', 'female'
 * @readonly
 * @enum {string}
 */
export type Gender = 'male' | 'female';

/**
 * Defines values for GlassesType.
 * Possible values include: 'noGlasses', 'readingGlasses', 'sunglasses', 'swimmingGoggles'
 * @readonly
 * @enum {string}
 */
export type GlassesType = 'noGlasses' | 'readingGlasses' | 'sunglasses' | 'swimmingGoggles';

/**
 * Defines values for HairColorType.
 * Possible values include: 'unknown', 'white', 'gray', 'blond', 'brown', 'red', 'black', 'other'
 * @readonly
 * @enum {string}
 */
export type HairColorType = 'unknown' | 'white' | 'gray' | 'blond' | 'brown' | 'red' | 'black' | 'other';

/**
 * Defines values for AccessoryType.
 * Possible values include: 'headWear', 'glasses', 'mask'
 * @readonly
 * @enum {string}
 */
export type AccessoryType = 'headWear' | 'glasses' | 'mask';

/**
 * Defines values for BlurLevel.
 * Possible values include: 'Low', 'Medium', 'High'
 * @readonly
 * @enum {string}
 */
export type BlurLevel = 'Low' | 'Medium' | 'High';

/**
 * Defines values for ExposureLevel.
 * Possible values include: 'UnderExposure', 'GoodExposure', 'OverExposure'
 * @readonly
 * @enum {string}
 */
export type ExposureLevel = 'UnderExposure' | 'GoodExposure' | 'OverExposure';

/**
 * Defines values for NoiseLevel.
 * Possible values include: 'Low', 'Medium', 'High'
 * @readonly
 * @enum {string}
 */
export type NoiseLevel = 'Low' | 'Medium' | 'High';

/**
 * Defines values for MaskType.
 * Possible values include: 'noMask', 'faceMask', 'otherMaskOrOcclusion', 'uncertain'
 * @readonly
 * @enum {string}
 */
export type MaskType = 'noMask' | 'faceMask' | 'otherMaskOrOcclusion' | 'uncertain';

/**
 * Defines values for QualityForRecognition.
 * Possible values include: 'Low', 'Medium', 'High'
 * @readonly
 * @enum {string}
 */
export type QualityForRecognition = 'Low' | 'Medium' | 'High';

/**
 * Defines values for FindSimilarMatchMode.
 * Possible values include: 'matchPerson', 'matchFace'
 * @readonly
 * @enum {string}
 */
export type FindSimilarMatchMode = 'matchPerson' | 'matchFace';

/**
 * Defines values for TrainingStatusType.
 * Possible values include: 'nonstarted', 'running', 'succeeded', 'failed'
 * @readonly
 * @enum {string}
 */
export type TrainingStatusType = 'nonstarted' | 'running' | 'succeeded' | 'failed';

/**
 * Defines values for SnapshotApplyMode.
 * Possible values include: 'CreateNew'
 * @readonly
 * @enum {string}
 */
export type SnapshotApplyMode = 'CreateNew';

/**
 * Defines values for SnapshotObjectType.
 * Possible values include: 'FaceList', 'LargeFaceList', 'LargePersonGroup', 'PersonGroup'
 * @readonly
 * @enum {string}
 */
export type SnapshotObjectType = 'FaceList' | 'LargeFaceList' | 'LargePersonGroup' | 'PersonGroup';

/**
 * Defines values for OperationStatusType.
 * Possible values include: 'notstarted', 'running', 'succeeded', 'failed'
 * @readonly
 * @enum {string}
 */
export type OperationStatusType = 'notstarted' | 'running' | 'succeeded' | 'failed';

/**
 * Defines values for FaceAttributeType.
 * Possible values include: 'age', 'gender', 'headPose', 'smile', 'facialHair', 'glasses',
 * 'emotion', 'hair', 'makeup', 'occlusion', 'accessories', 'blur', 'exposure', 'noise', 'mask',
 * 'qualityForRecognition'
 * @readonly
 * @enum {string}
 */
export type FaceAttributeType = 'age' | 'gender' | 'headPose' | 'smile' | 'facialHair' | 'glasses' | 'emotion' | 'hair' | 'makeup' | 'occlusion' | 'accessories' | 'blur' | 'exposure' | 'noise' | 'mask' | 'qualityForRecognition';

/**
 * Defines values for DetectionModel.
 * Possible values include: 'detection_01', 'detection_02', 'detection_03'
 * @readonly
 * @enum {string}
 */
export type DetectionModel = 'detection_01' | 'detection_02' | 'detection_03';

/**
 * Contains response data for the findSimilar operation.
 */
export type FaceFindSimilarResponse = Array<SimilarFace> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: SimilarFace[];
    };
};

/**
 * Contains response data for the group operation.
 */
export type FaceGroupResponse = GroupResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: GroupResult;
    };
};

/**
 * Contains response data for the identify operation.
 */
export type FaceIdentifyResponse = Array<IdentifyResult> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: IdentifyResult[];
    };
};

/**
 * Contains response data for the verifyFaceToFace operation.
 */
export type FaceVerifyFaceToFaceResponse = VerifyResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: VerifyResult;
    };
};

/**
 * Contains response data for the detectWithUrl operation.
 */
export type FaceDetectWithUrlResponse = Array<DetectedFace> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DetectedFace[];
    };
};

/**
 * Contains response data for the verifyFaceToPerson operation.
 */
export type FaceVerifyFaceToPersonResponse = VerifyResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: VerifyResult;
    };
};

/**
 * Contains response data for the detectWithStream operation.
 */
export type FaceDetectWithStreamResponse = Array<DetectedFace> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DetectedFace[];
    };
};

/**
 * Contains response data for the create operation.
 */
export type PersonGroupPersonCreateResponse = Person & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person;
    };
};

/**
 * Contains response data for the list operation.
 */
export type PersonGroupPersonListResponse = Array<Person> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person[];
    };
};

/**
 * Contains response data for the get operation.
 */
export type PersonGroupPersonGetResponse = Person & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person;
    };
};

/**
 * Contains response data for the getFace operation.
 */
export type PersonGroupPersonGetFaceResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromUrl operation.
 */
export type PersonGroupPersonAddFaceFromUrlResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromStream operation.
 */
export type PersonGroupPersonAddFaceFromStreamResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the get operation.
 */
export type PersonGroupGetResponse = PersonGroup & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersonGroup;
    };
};

/**
 * Contains response data for the getTrainingStatus operation.
 */
export type PersonGroupGetTrainingStatusResponse = TrainingStatus & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: TrainingStatus;
    };
};

/**
 * Contains response data for the list operation.
 */
export type PersonGroupListResponse = Array<PersonGroup> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersonGroup[];
    };
};

/**
 * Contains response data for the get operation.
 */
export type FaceListGetResponse = FaceList & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FaceList;
    };
};

/**
 * Contains response data for the list operation.
 */
export type FaceListListResponse = Array<FaceList> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: FaceList[];
    };
};

/**
 * Contains response data for the addFaceFromUrl operation.
 */
export type FaceListAddFaceFromUrlResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromStream operation.
 */
export type FaceListAddFaceFromStreamResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the create operation.
 */
export type LargePersonGroupPersonCreateResponse = Person & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person;
    };
};

/**
 * Contains response data for the list operation.
 */
export type LargePersonGroupPersonListResponse = Array<Person> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person[];
    };
};

/**
 * Contains response data for the get operation.
 */
export type LargePersonGroupPersonGetResponse = Person & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Person;
    };
};

/**
 * Contains response data for the getFace operation.
 */
export type LargePersonGroupPersonGetFaceResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromUrl operation.
 */
export type LargePersonGroupPersonAddFaceFromUrlResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromStream operation.
 */
export type LargePersonGroupPersonAddFaceFromStreamResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the get operation.
 */
export type LargePersonGroupGetResponse = LargePersonGroup & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: LargePersonGroup;
    };
};

/**
 * Contains response data for the getTrainingStatus operation.
 */
export type LargePersonGroupGetTrainingStatusResponse = TrainingStatus & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: TrainingStatus;
    };
};

/**
 * Contains response data for the list operation.
 */
export type LargePersonGroupListResponse = Array<LargePersonGroup> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: LargePersonGroup[];
    };
};

/**
 * Contains response data for the get operation.
 */
export type LargeFaceListGetResponse = LargeFaceList & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: LargeFaceList;
    };
};

/**
 * Contains response data for the getTrainingStatus operation.
 */
export type LargeFaceListGetTrainingStatusResponse = TrainingStatus & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: TrainingStatus;
    };
};

/**
 * Contains response data for the list operation.
 */
export type LargeFaceListListResponse = Array<LargeFaceList> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: LargeFaceList[];
    };
};

/**
 * Contains response data for the getFace operation.
 */
export type LargeFaceListGetFaceResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the addFaceFromUrl operation.
 */
export type LargeFaceListAddFaceFromUrlResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the listFaces operation.
 */
export type LargeFaceListListFacesResponse = Array<PersistedFace> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace[];
    };
};

/**
 * Contains response data for the addFaceFromStream operation.
 */
export type LargeFaceListAddFaceFromStreamResponse = PersistedFace & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: PersistedFace;
    };
};

/**
 * Contains response data for the take operation.
 */
export type SnapshotTakeResponse = SnapshotTakeHeaders & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The parsed HTTP response headers.
       */
      parsedHeaders: SnapshotTakeHeaders;
    };
};

/**
 * Contains response data for the list operation.
 */
export type SnapshotListResponse = Array<Snapshot> & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Snapshot[];
    };
};

/**
 * Contains response data for the get operation.
 */
export type SnapshotGetResponse = Snapshot & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: Snapshot;
    };
};

/**
 * Contains response data for the apply operation.
 */
export type SnapshotApplyResponse = SnapshotApplyHeaders & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The parsed HTTP response headers.
       */
      parsedHeaders: SnapshotApplyHeaders;
    };
};

/**
 * Contains response data for the getOperationStatus operation.
 */
export type SnapshotGetOperationStatusResponse = OperationStatus & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: OperationStatus;
    };
};
