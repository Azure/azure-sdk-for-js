/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */


import * as msRest from "@azure/ms-rest-js";

/**
 * An object describing face rectangle.
 */
export interface FaceRectangle {
  /**
   * X-coordinate of the top left point of the face, in pixels.
   */
  left?: number;
  /**
   * Y-coordinate of the top left point of the face, in pixels.
   */
  top?: number;
  /**
   * Width measured from the top-left point of the face, in pixels.
   */
  width?: number;
  /**
   * Height measured from the top-left point of the face, in pixels.
   */
  height?: number;
}

/**
 * An object describing possible celebrity identification.
 */
export interface CelebritiesModel {
  /**
   * Name of the celebrity.
   */
  name?: string;
  /**
   * Confidence level for the celebrity recognition as a value ranging from 0 to 1.
   */
  confidence?: number;
  /**
   * Location of the identified face in the image.
   */
  faceRectangle?: FaceRectangle;
}

/**
 * A landmark recognized in the image.
 */
export interface LandmarksModel {
  /**
   * Name of the landmark.
   */
  name?: string;
  /**
   * Confidence level for the landmark recognition as a value ranging from 0 to 1.
   */
  confidence?: number;
}

/**
 * An object describing additional category details.
 */
export interface CategoryDetail {
  /**
   * An array of celebrities if any identified.
   */
  celebrities?: CelebritiesModel[];
  /**
   * An array of landmarks if any identified.
   */
  landmarks?: LandmarksModel[];
}

/**
 * An object describing identified category.
 */
export interface Category {
  /**
   * Name of the category.
   */
  name?: string;
  /**
   * Scoring of the category.
   */
  score?: number;
  /**
   * Details of the identified category.
   */
  detail?: CategoryDetail;
}

/**
 * An object describing whether the image contains adult-oriented content and/or is racy.
 */
export interface AdultInfo {
  /**
   * A value indicating if the image contains adult-oriented content.
   */
  isAdultContent?: boolean;
  /**
   * A value indicating if the image is racy.
   */
  isRacyContent?: boolean;
  /**
   * A value indicating if the image is gory.
   */
  isGoryContent?: boolean;
  /**
   * Score from 0 to 1 that indicates how much the content is considered adult-oriented within the
   * image.
   */
  adultScore?: number;
  /**
   * Score from 0 to 1 that indicates how suggestive is the image.
   */
  racyScore?: number;
  /**
   * Score from 0 to 1 that indicates how gory is the image.
   */
  goreScore?: number;
}

/**
 * An object providing additional metadata describing color attributes.
 */
export interface ColorInfo {
  /**
   * Possible dominant foreground color.
   */
  dominantColorForeground?: string;
  /**
   * Possible dominant background color.
   */
  dominantColorBackground?: string;
  /**
   * An array of possible dominant colors.
   */
  dominantColors?: string[];
  /**
   * Possible accent color.
   */
  accentColor?: string;
  /**
   * A value indicating if the image is black and white.
   */
  isBWImg?: boolean;
}

/**
 * An object providing possible image types and matching confidence levels.
 */
export interface ImageType {
  /**
   * Confidence level that the image is a clip art.
   */
  clipArtType?: number;
  /**
   * Confidence level that the image is a line drawing.
   */
  lineDrawingType?: number;
}

/**
 * An entity observation in the image, along with the confidence score.
 */
export interface ImageTag {
  /**
   * Name of the entity.
   */
  name?: string;
  /**
   * The level of confidence that the entity was observed.
   */
  confidence?: number;
  /**
   * Optional hint/details for this tag.
   */
  hint?: string;
}

/**
 * An image caption, i.e. a brief description of what the image depicts.
 */
export interface ImageCaption {
  /**
   * The text of the caption.
   */
  text?: string;
  /**
   * The level of confidence the service has in the caption.
   */
  confidence?: number;
}

/**
 * A collection of content tags, along with a list of captions sorted by confidence level, and
 * image metadata.
 */
export interface ImageDescriptionDetails {
  /**
   * A collection of image tags.
   */
  tags?: string[];
  /**
   * A list of captions, sorted by confidence level.
   */
  captions?: ImageCaption[];
}

/**
 * An object describing a face identified in the image.
 */
export interface FaceDescription {
  /**
   * Possible age of the face.
   */
  age?: number;
  /**
   * Possible gender of the face. Possible values include: 'Male', 'Female'
   */
  gender?: Gender;
  /**
   * Rectangle in the image containing the identified face.
   */
  faceRectangle?: FaceRectangle;
}

/**
 * A bounding box for an area inside an image.
 */
export interface BoundingRect {
  /**
   * X-coordinate of the top left point of the area, in pixels.
   */
  x?: number;
  /**
   * Y-coordinate of the top left point of the area, in pixels.
   */
  y?: number;
  /**
   * Width measured from the top-left point of the area, in pixels.
   */
  w?: number;
  /**
   * Height measured from the top-left point of the area, in pixels.
   */
  h?: number;
}

/**
 * An object detected inside an image.
 */
export interface ObjectHierarchy {
  /**
   * Label for the object.
   */
  object?: string;
  /**
   * Confidence score of having observed the object in the image, as a value ranging from 0 to 1.
   */
  confidence?: number;
  /**
   * The parent object, from a taxonomy perspective.
   * The parent object is a more generic form of this object.  For example, a 'bulldog' would have
   * a parent of 'dog'.
   */
  parent?: ObjectHierarchy;
}

/**
 * An object detected in an image.
 */
export interface DetectedObject {
  /**
   * Approximate location of the detected object.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly rectangle?: BoundingRect;
  /**
   * Label for the object.
   */
  object?: string;
  /**
   * Confidence score of having observed the object in the image, as a value ranging from 0 to 1.
   */
  confidence?: number;
  /**
   * The parent object, from a taxonomy perspective.
   * The parent object is a more generic form of this object.  For example, a 'bulldog' would have
   * a parent of 'dog'.
   */
  parent?: ObjectHierarchy;
}

/**
 * A brand detected in an image.
 */
export interface DetectedBrand {
  /**
   * Label for the brand.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly name?: string;
  /**
   * Confidence score of having observed the brand in the image, as a value ranging from 0 to 1.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly confidence?: number;
  /**
   * Approximate location of the detected brand.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly rectangle?: BoundingRect;
}

/**
 * Image metadata.
 */
export interface ImageMetadata {
  /**
   * Image width, in pixels.
   */
  width?: number;
  /**
   * Image height, in pixels.
   */
  height?: number;
  /**
   * Image format.
   */
  format?: string;
}

/**
 * Result of AnalyzeImage operation.
 */
export interface ImageAnalysis {
  /**
   * An array indicating identified categories.
   */
  categories?: Category[];
  /**
   * An object describing whether the image contains adult-oriented content and/or is racy.
   */
  adult?: AdultInfo;
  /**
   * An object providing additional metadata describing color attributes.
   */
  color?: ColorInfo;
  /**
   * An object providing possible image types and matching confidence levels.
   */
  imageType?: ImageType;
  /**
   * A list of tags with confidence level.
   */
  tags?: ImageTag[];
  /**
   * A collection of content tags, along with a list of captions sorted by confidence level, and
   * image metadata.
   */
  description?: ImageDescriptionDetails;
  /**
   * An array of possible faces within the image.
   */
  faces?: FaceDescription[];
  /**
   * Array of objects describing what was detected in the image.
   */
  objects?: DetectedObject[];
  /**
   * Array of brands detected in the image.
   */
  brands?: DetectedBrand[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * A collection of content tags, along with a list of captions sorted by confidence level, and
 * image metadata.
 */
export interface ImageDescription {
  /**
   * A collection of image tags.
   */
  tags?: string[];
  /**
   * A list of captions, sorted by confidence level.
   */
  captions?: ImageCaption[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * Result of a DetectImage call.
 */
export interface DetectResult {
  /**
   * An array of detected objects.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly objects?: DetectedObject[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * An object describing supported model by name and categories.
 */
export interface ModelDescription {
  /**
   * The name of the model.
   */
  name?: string;
  /**
   * Categories of the model.
   */
  categories?: string[];
}

/**
 * Result of the List Domain Models operation.
 */
export interface ListModelsResult {
  /**
   * An array of supported models.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly modelsProperty?: ModelDescription[];
}

/**
 * Result of image analysis using a specific domain model including additional metadata.
 */
export interface DomainModelResults {
  /**
   * Model-specific response.
   */
  result?: any;
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * Information on a recognized word.
 */
export interface OcrWord {
  /**
   * Bounding box of a recognized word. The four integers represent the x-coordinate of the left
   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the
   * coordinate system of the input image, after it has been rotated around its center according to
   * the detected text angle (see textAngle property), with the origin at the top-left corner, and
   * the y-axis pointing down.
   */
  boundingBox?: string;
  /**
   * String value of a recognized word.
   */
  text?: string;
}

/**
 * An object describing a single recognized line of text.
 */
export interface OcrLine {
  /**
   * Bounding box of a recognized line. The four integers represent the x-coordinate of the left
   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the
   * coordinate system of the input image, after it has been rotated around its center according to
   * the detected text angle (see textAngle property), with the origin at the top-left corner, and
   * the y-axis pointing down.
   */
  boundingBox?: string;
  /**
   * An array of objects, where each object represents a recognized word.
   */
  words?: OcrWord[];
}

/**
 * A region consists of multiple lines (e.g. a column of text in a multi-column document).
 */
export interface OcrRegion {
  /**
   * Bounding box of a recognized region. The four integers represent the x-coordinate of the left
   * edge, the y-coordinate of the top edge, width, and height of the bounding box, in the
   * coordinate system of the input image, after it has been rotated around its center according to
   * the detected text angle (see textAngle property), with the origin at the top-left corner, and
   * the y-axis pointing down.
   */
  boundingBox?: string;
  /**
   * An array of recognized lines of text.
   */
  lines?: OcrLine[];
}

/**
 * An interface representing OcrResult.
 */
export interface OcrResult {
  /**
   * The BCP-47 language code of the text in the image.
   */
  language?: string;
  /**
   * The angle, in radians, of the detected text with respect to the closest horizontal or vertical
   * direction. After rotating the input image clockwise by this angle, the recognized text lines
   * become horizontal or vertical. In combination with the orientation property it can be used to
   * overlay recognition results correctly on the original image, by rotating either the original
   * image or recognition results by a suitable angle around the center of the original image. If
   * the angle cannot be confidently detected, this property is not present. If the image contains
   * text at different angles, only part of the text will be recognized correctly.
   */
  textAngle?: number;
  /**
   * Orientation of the text recognized in the image, if requested. The value (up, down, left, or
   * right) refers to the direction that the top of the recognized text is facing, after the image
   * has been rotated around its center according to the detected text angle (see textAngle
   * property).
   * If detection of the orientation was not requested, or no text is detected, the value is
   * 'NotDetected'.
   */
  orientation?: string;
  /**
   * An array of objects, where each object represents a region of recognized text.
   */
  regions?: OcrRegion[];
}

/**
 * The results of a image tag operation, including any tags and image metadata.
 */
export interface TagResult {
  /**
   * A list of tags with confidence level.
   */
  tags?: ImageTag[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * Result of AreaOfInterest operation.
 */
export interface AreaOfInterestResult {
  /**
   * A bounding box for an area of interest inside an image.
   * **NOTE: This property will not be serialized. It can only be populated by the server.**
   */
  readonly areaOfInterest?: BoundingRect;
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * An interface representing ImageUrl.
 */
export interface ImageUrl {
  /**
   * Publicly reachable URL of an image.
   */
  url: string;
}

/**
 * Details about the API request error.
 */
export interface ComputerVisionError {
  /**
   * The error code.
   */
  code: any;
  /**
   * A message explaining the error reported by the service.
   */
  message: string;
  /**
   * A unique request identifier.
   */
  requestId?: string;
}

/**
 * Result of domain-specific classifications for the domain of landmarks.
 */
export interface LandmarkResults {
  /**
   * List of landmarks recognized in the image.
   */
  landmarks?: LandmarksModel[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * Result of domain-specific classifications for the domain of celebrities.
 */
export interface CelebrityResults {
  /**
   * List of celebrities recognized in the image.
   */
  celebrities?: CelebritiesModel[];
  /**
   * Id of the REST API request.
   */
  requestId?: string;
  metadata?: ImageMetadata;
}

/**
 * An object representing a recognized word.
 */
export interface Word {
  /**
   * Bounding box of a recognized word.
   */
  boundingBox: number[];
  /**
   * The text content of the word.
   */
  text: string;
  /**
   * Qualitative confidence measure.
   */
  confidence: number;
}

/**
 * An object representing a recognized text line.
 */
export interface Line {
  /**
   * The BCP-47 language code of the recognized text line. Only provided where the language of the
   * line differs from the page's.
   */
  language?: string;
  /**
   * Bounding box of a recognized line.
   */
  boundingBox: number[];
  /**
   * The text content of the line.
   */
  text: string;
  /**
   * List of words in the text line.
   */
  words: Word[];
}

/**
 * Text extracted from a page in the input document.
 */
export interface ReadResult {
  /**
   * The 1-based page number of the recognition result.
   */
  page: number;
  /**
   * The BCP-47 language code of the recognized text page.
   */
  language?: string;
  /**
   * The orientation of the image in degrees in the clockwise direction. Range between [-180, 180).
   */
  angle: number;
  /**
   * The width of the image in pixels or the PDF in inches.
   */
  width: number;
  /**
   * The height of the image in pixels or the PDF in inches.
   */
  height: number;
  /**
   * The unit used in the Width, Height and BoundingBox. For images, the unit is 'pixel'. For PDF,
   * the unit is 'inch'. Possible values include: 'pixel', 'inch'
   */
  unit: TextRecognitionResultDimensionUnit;
  /**
   * A list of recognized text lines.
   */
  lines: Line[];
}

/**
 * Analyze batch operation result.
 */
export interface AnalyzeResults {
  /**
   * Version of schema used for this result.
   */
  version: string;
  /**
   * Text extracted from the input.
   */
  readResults: ReadResult[];
}

/**
 * OCR result of the read operation.
 */
export interface ReadOperationResult {
  /**
   * Status of the read operation. Possible values include: 'notStarted', 'running', 'failed',
   * 'succeeded'
   */
  status?: OperationStatusCodes;
  /**
   * Get UTC date time the batch operation was submitted.
   */
  createdDateTime?: string;
  /**
   * Get last updated UTC date time of this batch operation.
   */
  lastUpdatedDateTime?: string;
  /**
   * Analyze batch operation result.
   */
  analyzeResult?: AnalyzeResults;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientAnalyzeImageOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A string indicating what visual feature types to return. Multiple values should be
   * comma-separated. Valid visual feature types include: Categories - categorizes image content
   * according to a taxonomy defined in documentation. Tags - tags the image with a detailed list
   * of words related to the image content. Description - describes the image content with a
   * complete English sentence. Faces - detects if faces are present. If present, generate
   * coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color
   * - determines the accent color, dominant color, and whether an image is black&white. Adult -
   * detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory
   * (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also
   * detected. Objects - detects various objects within an image, including the approximate
   * location. The Objects argument is only available in English. Brands - detects various brands
   * within an image, including the approximate location. The Brands argument is only available in
   * English.
   */
  visualFeatures?: VisualFeatureTypes[];
  /**
   * A string indicating which domain-specific details to return. Multiple values should be
   * comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if
   * detected in the image, Landmarks - identifies notable landmarks in the image.
   */
  details?: Details[];
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language;
  /**
   * Turn off specified domain models when generating the description.
   */
  descriptionExclude?: DescriptionExclude[];
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientDescribeImageOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Maximum number of candidate descriptions to be returned.  The default is 1. Default value: 1.
   */
  maxCandidates?: number;
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language1;
  /**
   * Turn off specified domain models when generating the description.
   */
  descriptionExclude?: DescriptionExclude[];
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientAnalyzeImageByDomainOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language2;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientRecognizePrintedTextOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.
   * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr',
   * 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
   * 'sr-Cyrl', 'sr-Latn', 'sk'. Default value: 'unk'.
   */
  language?: OcrLanguages;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientTagImageOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language3;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientGenerateThumbnailOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Boolean flag for enabling smart cropping. Default value: false.
   */
  smartCropping?: boolean;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientReadOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The BCP-47 language code of the text in the document. Currently, only English ('en'), Dutch
   * (‘nl’), French (‘fr’), German (‘de’), Italian (‘it’), Portuguese (‘pt), and Spanish ('es') are
   * supported. Read supports auto language identification and multi-language documents, so only
   * provide a language code if you would like to force the documented to be processed as that
   * specific language. Possible values include: 'en', 'es', 'fr', 'de', 'it', 'nl', 'pt'. Default
   * value: 'en'.
   */
  language?: OcrDetectionLanguage;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientAnalyzeImageInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * A string indicating what visual feature types to return. Multiple values should be
   * comma-separated. Valid visual feature types include: Categories - categorizes image content
   * according to a taxonomy defined in documentation. Tags - tags the image with a detailed list
   * of words related to the image content. Description - describes the image content with a
   * complete English sentence. Faces - detects if faces are present. If present, generate
   * coordinates, gender and age. ImageType - detects if image is clipart or a line drawing. Color
   * - determines the accent color, dominant color, and whether an image is black&white. Adult -
   * detects if the image is pornographic in nature (depicts nudity or a sex act), or is gory
   * (depicts extreme violence or blood). Sexually suggestive content (aka racy content) is also
   * detected. Objects - detects various objects within an image, including the approximate
   * location. The Objects argument is only available in English. Brands - detects various brands
   * within an image, including the approximate location. The Brands argument is only available in
   * English.
   */
  visualFeatures?: VisualFeatureTypes[];
  /**
   * A string indicating which domain-specific details to return. Multiple values should be
   * comma-separated. Valid visual feature types include: Celebrities - identifies celebrities if
   * detected in the image, Landmarks - identifies notable landmarks in the image.
   */
  details?: Details[];
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language4;
  /**
   * Turn off specified domain models when generating the description.
   */
  descriptionExclude?: DescriptionExclude[];
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientDescribeImageInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Maximum number of candidate descriptions to be returned.  The default is 1. Default value: 1.
   */
  maxCandidates?: number;
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language5;
  /**
   * Turn off specified domain models when generating the description.
   */
  descriptionExclude?: DescriptionExclude[];
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientGenerateThumbnailInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * Boolean flag for enabling smart cropping. Default value: false.
   */
  smartCropping?: boolean;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientAnalyzeImageByDomainInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language6;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientRecognizePrintedTextInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.
   * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr',
   * 'de', 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro',
   * 'sr-Cyrl', 'sr-Latn', 'sk'. Default value: 'unk'.
   */
  language?: OcrLanguages;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientTagImageInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The desired language for output generation. If this parameter is not specified, the default
   * value is &quot;en&quot;.Supported languages:en - English, Default. es - Spanish, ja -
   * Japanese, pt - Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja',
   * 'pt', 'zh'. Default value: 'en'.
   */
  language?: Language7;
}

/**
 * Optional Parameters.
 */
export interface ComputerVisionClientReadInStreamOptionalParams extends msRest.RequestOptionsBase {
  /**
   * The BCP-47 language code of the text in the document. Currently, only English ('en'), Dutch
   * (‘nl’), French (‘fr’), German (‘de’), Italian (‘it’), Portuguese (‘pt), and Spanish ('es') are
   * supported. Read supports auto language identification and multi-language documents, so only
   * provide a language code if you would like to force the documented to be processed as that
   * specific language. Possible values include: 'en', 'es', 'fr', 'de', 'it', 'nl', 'pt'. Default
   * value: 'en'.
   */
  language?: OcrDetectionLanguage;
}

/**
 * Defines headers for Read operation.
 */
export interface ReadHeaders {
  /**
   * URL to query for status of the operation. The operation ID will expire in 48 hours.
   */
  operationLocation: string;
}

/**
 * Defines headers for ReadInStream operation.
 */
export interface ReadInStreamHeaders {
  /**
   * URL to query for status of the operation. The operation ID will expire in 48 hours.
   */
  operationLocation: string;
}

/**
 * Defines values for Gender.
 * Possible values include: 'Male', 'Female'
 * @readonly
 * @enum {string}
 */
export type Gender = 'Male' | 'Female';

/**
 * Defines values for OperationStatusCodes.
 * Possible values include: 'notStarted', 'running', 'failed', 'succeeded'
 * @readonly
 * @enum {string}
 */
export type OperationStatusCodes = 'notStarted' | 'running' | 'failed' | 'succeeded';

/**
 * Defines values for TextRecognitionResultDimensionUnit.
 * Possible values include: 'pixel', 'inch'
 * @readonly
 * @enum {string}
 */
export type TextRecognitionResultDimensionUnit = 'pixel' | 'inch';

/**
 * Defines values for DescriptionExclude.
 * Possible values include: 'Celebrities', 'Landmarks'
 * @readonly
 * @enum {string}
 */
export type DescriptionExclude = 'Celebrities' | 'Landmarks';

/**
 * Defines values for OcrLanguages.
 * Possible values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',
 * 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl',
 * 'sr-Latn', 'sk'
 * @readonly
 * @enum {string}
 */
export type OcrLanguages = 'unk' | 'zh-Hans' | 'zh-Hant' | 'cs' | 'da' | 'nl' | 'en' | 'fi' | 'fr' | 'de' | 'el' | 'hu' | 'it' | 'ja' | 'ko' | 'nb' | 'pl' | 'pt' | 'ru' | 'es' | 'sv' | 'tr' | 'ar' | 'ro' | 'sr-Cyrl' | 'sr-Latn' | 'sk';

/**
 * Defines values for VisualFeatureTypes.
 * Possible values include: 'ImageType', 'Faces', 'Adult', 'Categories', 'Color', 'Tags',
 * 'Description', 'Objects', 'Brands'
 * @readonly
 * @enum {string}
 */
export type VisualFeatureTypes = 'ImageType' | 'Faces' | 'Adult' | 'Categories' | 'Color' | 'Tags' | 'Description' | 'Objects' | 'Brands';

/**
 * Defines values for OcrDetectionLanguage.
 * Possible values include: 'en', 'es', 'fr', 'de', 'it', 'nl', 'pt'
 * @readonly
 * @enum {string}
 */
export type OcrDetectionLanguage = 'en' | 'es' | 'fr' | 'de' | 'it' | 'nl' | 'pt';

/**
 * Defines values for Details.
 * Possible values include: 'Celebrities', 'Landmarks'
 * @readonly
 * @enum {string}
 */
export type Details = 'Celebrities' | 'Landmarks';

/**
 * Defines values for Language.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language1.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language1 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language2.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language2 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language3.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language3 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language4.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language4 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language5.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language5 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language6.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language6 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Defines values for Language7.
 * Possible values include: 'en', 'es', 'ja', 'pt', 'zh'
 * @readonly
 * @enum {string}
 */
export type Language7 = 'en' | 'es' | 'ja' | 'pt' | 'zh';

/**
 * Contains response data for the analyzeImage operation.
 */
export type AnalyzeImageResponse = ImageAnalysis & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ImageAnalysis;
    };
};

/**
 * Contains response data for the describeImage operation.
 */
export type DescribeImageResponse = ImageDescription & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ImageDescription;
    };
};

/**
 * Contains response data for the detectObjects operation.
 */
export type DetectObjectsResponse = DetectResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DetectResult;
    };
};

/**
 * Contains response data for the listModels operation.
 */
export type ListModelsResponse = ListModelsResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ListModelsResult;
    };
};

/**
 * Contains response data for the analyzeImageByDomain operation.
 */
export type AnalyzeImageByDomainResponse = DomainModelResults & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DomainModelResults;
    };
};

/**
 * Contains response data for the recognizePrintedText operation.
 */
export type RecognizePrintedTextResponse = OcrResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: OcrResult;
    };
};

/**
 * Contains response data for the tagImage operation.
 */
export type TagImageResponse = TagResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: TagResult;
    };
};

/**
 * Contains response data for the generateThumbnail operation.
 */
export type GenerateThumbnailResponse = {
  /**
   * BROWSER ONLY
   *
   * The response body as a browser Blob.
   * Always undefined in node.js.
   */
  blobBody?: Promise<Blob>;

  /**
   * NODEJS ONLY
   *
   * The response body as a node.js Readable stream.
   * Always undefined in the browser.
   */
  readableStreamBody?: NodeJS.ReadableStream;

  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse;
};

/**
 * Contains response data for the getAreaOfInterest operation.
 */
export type GetAreaOfInterestResponse = AreaOfInterestResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: AreaOfInterestResult;
    };
};

/**
 * Contains response data for the read operation.
 */
export type ReadResponse = ReadHeaders & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The parsed HTTP response headers.
       */
      parsedHeaders: ReadHeaders;
    };
};

/**
 * Contains response data for the getReadResult operation.
 */
export type GetReadResultResponse = ReadOperationResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ReadOperationResult;
    };
};

/**
 * Contains response data for the analyzeImageInStream operation.
 */
export type AnalyzeImageInStreamResponse = ImageAnalysis & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ImageAnalysis;
    };
};

/**
 * Contains response data for the getAreaOfInterestInStream operation.
 */
export type GetAreaOfInterestInStreamResponse = AreaOfInterestResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: AreaOfInterestResult;
    };
};

/**
 * Contains response data for the describeImageInStream operation.
 */
export type DescribeImageInStreamResponse = ImageDescription & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: ImageDescription;
    };
};

/**
 * Contains response data for the detectObjectsInStream operation.
 */
export type DetectObjectsInStreamResponse = DetectResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DetectResult;
    };
};

/**
 * Contains response data for the generateThumbnailInStream operation.
 */
export type GenerateThumbnailInStreamResponse = {
  /**
   * BROWSER ONLY
   *
   * The response body as a browser Blob.
   * Always undefined in node.js.
   */
  blobBody?: Promise<Blob>;

  /**
   * NODEJS ONLY
   *
   * The response body as a node.js Readable stream.
   * Always undefined in the browser.
   */
  readableStreamBody?: NodeJS.ReadableStream;

  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse;
};

/**
 * Contains response data for the analyzeImageByDomainInStream operation.
 */
export type AnalyzeImageByDomainInStreamResponse = DomainModelResults & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: DomainModelResults;
    };
};

/**
 * Contains response data for the recognizePrintedTextInStream operation.
 */
export type RecognizePrintedTextInStreamResponse = OcrResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: OcrResult;
    };
};

/**
 * Contains response data for the tagImageInStream operation.
 */
export type TagImageInStreamResponse = TagResult & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: TagResult;
    };
};

/**
 * Contains response data for the readInStream operation.
 */
export type ReadInStreamResponse = ReadInStreamHeaders & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The parsed HTTP response headers.
       */
      parsedHeaders: ReadInStreamHeaders;
    };
};
